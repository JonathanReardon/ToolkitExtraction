StudyID,Strand,TypeofTest,TypeofTestHighlightedText,StandardisedTest,StandardisedTestHighlightedText,ResearcherDevelopedTest,ResearcherDevelopedTestHighlightedTest,SchoolDevelopedTest,SchoolDevelopedTestHighlightedTest,NationalTestorExam,NationalTestorExamHighlightedTest,InternationalTests,InternationalTestsHighlightedTest
37116221,Peer Tutoring,NA,NA,"DIBELS Next Oral Reading Fluency (DORF). The researcher used the Dynamic Indicators of Basic Early Literacy Skills Next (DIBELS) Oral Reading Fluency (DORF) measure to assess students’ reading fluency. It is a standardized measure that contains multiple forms to assess students’ progress over time. Moreover, the DORF measure is a highly validated and reliable tool that takes approximately six minutes, per benchmark, to administer (Cummings, Kennedy, Otterstedt, Baker, & Kame’enui, 2011).  DIBELS Next Maze (Daze). The DIBELS Next Maze (Daze), a recently added measure to the DIBELS Next assessments, used by the researcher to assess students’ (N = 164) comprehension.  Scholastic Reading Inventory (SRI). The SRI test is a criterion- and norm referenced test that assesses students’ reading comprehension of literary and expository text based on the Lexile Framework that was developed by Metametrics, Inc with a grant from the National Institute of Child Health and Human Development.  The Elementary Reading Attitude Survey (ERAS). The ERAS measure was used as a qualitative and quantitative measure to provide the researcher with information about participant’s perception toward reading, specifically recreation and academic (Appendix K). The ERAS instrument was norm-referenced in the United States in 1989 with over 18,000 first through sixth grade students from 95 school districts (McKenna & Kear, 1990). The internal-consistency coefficients range from .74 on the Recreational subscale for first grade students to .89 on the Total scale for sixth graders. Validation of the ERAS is evidenced-based on the instrument’s intersubscale correlation of .64 for the two subscales.","['Page 86:\n[¬s]""DIBELS Next Oral Reading Fluency (DORF). The researcher used the Dynamic Indicators of Basic Early Literacy Skills Next (DIBELS) Oral Reading Fluency (DORF) measure to assess students’ reading fluency.[¬e]""', 'Page 87:\n[¬s]"" It is a standardized measure that contains multiple forms to assess students’ progress over time. Moreover, the DORF measure is a highly validated and reliable tool that takes approximately six minutes, per benchmark, to administer (Cummings, Kennedy, Otterstedt, Baker, & Kame’enui, 2011).[¬e]""', 'Page 89:\n[¬s]""DIBELS Next Maze (Daze). The DIBELS Next Maze (Daze), a recently added measure to the DIBELS Next assessments, used by the researcher to assess students’ (N = 164) comprehension.[¬e]""', 'Page 91:\n[¬s]""Scholastic Reading Inventory (SRI). The SRI test is a criterion- and norm referenced test that assesses students’ reading comprehension of literary and expository text based on the Lexile Framework that was developed by Metametrics, Inc with a grant from the National Institute of Child Health and Human Development.[¬e]""', 'Page 93:\n[¬s]""The Elementary Reading Attitude Survey (ERAS). The ERAS measure was used as a qualitative and quantitative measure to provide the researcher with information about participant’s perception toward reading, specifically recreation and academic (Appendix K). The ERAS instrument was norm-referenced in the United States in 1989 with over 18,000 first through sixth grade students from 95 school districts (McKenna & Kear, 1990). The internal-consistency coefficients range from .74 on the Recreational subscale for first grade students to .89 on the Total scale for sixth graders. Validation of the ERAS is evidenced-based on the instrument’s intersubscale correlation of .64 for the two subscales.[¬e]""']","Teacher interview protocol. The researcher conducted individual, semi- structured interviews with treatment teachers at the conclusion of the 13 week study to gather qualitative data about the implementation and effectiveness of PALS reading  KidBlog. In March 2013, the researcher created a free online account through KidBlog. Usernames and passwords for students (n = 84) receiving treatment were created. The researcher used KidBlog, an online posting and commenting platform, to obtain qualitative data about students’ perception of PALS reading.","['Page 94:\n[¬s]""Teacher interview protocol. The researcher conducted individual, semi- structured interviews with treatment teachers at the conclusion of the 13 week study to gather qualitative data about the implementation and effectiveness of PALS reading[¬e]""', 'Page 95:\n[¬s]""KidBlog. In March 2013, the researcher created a free online account through KidBlog. Usernames and passwords for students (n = 84) receiving treatment were created. The researcher used KidBlog, an online posting and commenting platform, to obtain qualitative data about students’ perception of PALS reading.[¬e]""']",NA,NA,NA,NA,NA,NA
37092570,Feedback,NA,NA,NA,NA,NA,"['Page 22:\n[¬s]""The students completed a writing assessment modeled after the Kansas Writing Assessment, which was developed by the University of Kansas for the state of Kansas. The Kansas Writing Assessment is not given to third grade students, so it was modified for this study[¬e]""']",NA,NA,NA,NA,NA,NA
39253274,Summer schools,NA,NA,NA,"['Page 100:\n[¬s]""P A L S 1.[¬e]""', 'Page 101:\n[¬s]""TERA 2, Form s A and B[¬e]""', 'Page 95:\n[¬s]""P A LS K.[¬e]""', 'Page 96:\n[¬s]""P A L S K subtests.[¬e]""']",NA,"['Page 106:\n[¬s]""Retelling Assessment""\n""assess student recall and comprehension o f a complex text.[¬e]""', 'Page 108:\n[¬s]""The 30 students, pair-wise matched from the intervention, control, and regular classroom, participated in a retelling o f grade-appropriate fiction and nonfiction text that w as read to them. Each child was asked to recall orally everything he or she remembered about the story.""\n"" A retelling checklist was used to assess each child’s responses by checking o ff recalled events that the child included in the retelling. The retelling score was determined by the percentage o f total items recalled by the child.[¬e]""']",NA,NA,NA,"['Page 103:\n[¬s]""Alabam a R eading Assessment: Grade 1.[¬e]""']",NA,NA
37133863,Peer Tutoring,NA,NA,"Solving Division Equations Pretest. Posttest, and Maintenance Test The pretest and posttest measures (see Appendices A and B) come directly from those in Solving Division Equations: An Algebra Program for Students with Learning Problems (Mercer, Enright, & Tharin, 1994).  CWPT Implementation Checklist This is a two-category, 38-item checklist of major components of CWPT developed by Carta, Greenwood, Dinwiddie, Kohler, and Delquadri (1987) which was modified to accommodate use with the algebra curriculum  Peer Tutoring Evaluation Inventory  This questionnaire is a slightly modified version of one that has been used in several CWPT studies (Harper et al., 1993; Maheady & Harper, 1987; Mallette et al., 1991). Modifications were made which adapted the questionnaire for use with algebra problem solving.","['Page 100:\n[¬s]""Peer Tutoring Evaluation Inventory[¬e]""', 'Page 101:\n[¬s]"" This questionnaire is a slightly modified version of one that has been used in several CWPT studies (Harper et al., 1993; Maheady & Harper, 1987; Mallette et al., 1991). Modifications were made which adapted the questionnaire for use with algebra problem solving.[¬e]""', 'Page 101:\n[¬s]""CWPT Teacher Informal Interview Teachers were interviewed b y the researcher to assess their perceptions of using CWPT. General questions about using CWPT were developed before the interviews, and these served as structure for each interview[¬e]""', 'Page 99:\n[¬s]""Solving Division Equations Pretest. Posttest, and Maintenance Test The pretest and posttest measures (see Appendices A and B) come directly from those in Solving Division Equations: An Algebra Program for Students with Learning Problems (Mercer, Enright, & Tharin, 1994).[¬e]""']","Solving Division Equations  The maintenance test (see Appendix C) was developed by the researcher and included items which assessed the same skills as those assessed in the pretest and maintenance test.  CWPT Teacher Informal Interview Teachers were interviewed b y the researcher to assess their perceptions of using CWPT. General questions about using CWPT were developed before the interviews, and these served as structure for each interview","['Page 99:\n[¬s]"" The maintenance test (see Appendix C) was developed by the researcher and included items which assessed the same skills as those assessed in the pretest and maintenance test.[¬e]""']",NA,NA,NA,NA,NA,NA
37092749,Feedback,NA,NA,NA,"['Page 55:\n[¬s]""Various cognitive achievement measures were used. An achievement (formative) test was given at the end of each task. A final summative examination was given at the end of the series of learning tasks. The same examination was given as the pre-test. All of these cognitive tests were based on the content and objectives of the learning units. (See Block, 1970,[¬e]""', 'Page 56:\n[¬s]"" Appendix B, for copies of all of the examinations.)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092571,Feedback,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]""Essays Each class was asked to do a writing as- signment. See Appendix A for each as- signment. Six classes wrote persuasive essays. Four of the six classes wrote per- suasive essays about year-round school- ing, and two of the sixÑone treatment, one comparisonÑwrote about the im- pact of the European settlers on the Na- tive Americans. One third grade treat- ment class wrote stories about their families. Writing about topics related to the curriculum was a condition of participation in the study imposed by the teachers of those classes. Six researchers in three pairs scored the essays. The scorers were blind to treatment condition. The rubrics used in the treatment classrooms were adapted for use as scoring rubrics. Two scoring rubrics were developed: One for the third grade stories, and one for the third and fourth grade persuasive es- says. The rubrics (Appendix B) were very similar but varied in terms of one criterion; the ideas and content of the writing to be assessed. In order to in- crease discrimination between levels and more precisely measure quality, the scoring rubrics included six levels of quality rather than the four levels in the rubrics used in the classrooms.[¬e]""', 'Page 4:\n[¬s]""Rubrics The rubrics given to the treatment group classes referred to seven com- monly assessed criteria for writing (e.g., the 6 + 1 Trait\x02 Writing Method; see Culham, 2003; Spandel & Stiggins, 1997): ideas and content, organization, voice and tone, word choice, sentence ßuency, and conventions (see Appendix B). We treated the essay score data as interval-level data for analysis.[¬e]""']",NA,NA,NA,NA,NA,NA
37093532,Peer Tutoring,NA,NA,Burt Word reading test (Vernon 1969),"['Page 3:\n[¬s]""Both groups were tested at the beginning and the end of the academic year 1988-9 using the Burt (rearranged) Word Reading Test (Vernon, 1969).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092572,Feedback,NA,NA,NA,NA,NA,"['Page 5:\n[¬s]"" three 45-minute periods to write an essay on an assigned topic. Students had time to prewrite, create a rough draft, read over the rough draft and revise, edit, and produce a final copy. Students were allowed to use dictionaries or other written references during testing, but could not confer with the teacher or with each other. Two prompts were used-expository (to elicit informational writing) and narrative (to elicit stories). [¬e]""', 'Page 6:\n[¬s]"" posttest essays[¬e]""']",NA,NA,NA,NA,NA,NA
37093533,Peer Tutoring,NA,NA,"Primary Reading Test, France 1979",NA,NA,NA,NA,NA,NA,NA,NA,NA
37061105,Feedback,NA,NA,NA,NA,NA,"['Page 9:\n[¬s]""The f\'irst test of one hundred words vas selected at random .from the nu-sELF-Tin\'ORING MOOEJll ElliL.ISH: Sftl.LIBG program.. The second hundred words, the posttest, were selected by attempting to parallel these words in structure, vord for word, Vi th the pretest.[¬e]""']",NA,NA,NA,NA,NA,NA
37092622,Feedback,NA,NA,NA,NA,NA,"['Page 1:\n[¬s]""The metaphor story, illustra\xad tion, and multiple choices included in Figure 1 are based on Gardner\'s (1974) definition of a metaphor as a figure of speech in which a descriptive term is ap\xad plied to a referent for which it is not literally appropriate, but to which it bears certain analogies.[¬e]""']",NA,NA,NA,NA,NA,NA
40117187,Extending school time,NA,NA,NA,NA,NA,NA,NA,"['Page 11:\n[¬s]""Grades were obtained for the first grading period at the beginning of the school year (six weeks at School A and nine weeks at School B), at the end of the Fall semester in December, and at the end of the Spring semester.[¬e]""']",NA,"['Page 11:\n[¬s]""Data from AISD Central Records. Scores on two components of the Texas Assessment ofAcademic Skills (TAAS) exam were obtained from the AISD central administrative records: math and reading.[¬e]""']",NA,NA
37133865,Peer Tutoring,NA,NA,"Dynamic Indicators o f Basic Early Literacy Skills (DIBELS) The DIBELS subscale used in this study was Phoneme Segmentation Fluency (PSF). DIBELS Phoneme Segmentation Fluency (PSF) is a standardized, individually administered test o f phonological awareness (Good, Kaminski, & Smith, 2002). This measure assesses a student’s ability to segment three- and four- letter words into their individual phoneme sounds smoothly.","['Page 37:\n[¬s]""Dynamic Indicators o f Basic Early Literacy Skills (DIBELS)""\n""The DIBELS subscale used in this study was Phoneme Segmentation Fluency (PSF). DIBELS Phoneme Segmentation Fluency (PSF) is a standardized, individually administered test o f phonological awareness (Good, Kaminski, & Smith, 2002). This measure assesses a student’s ability to segment three- and four- letter words into their individual phoneme sounds smoothly.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253276,Summer schools,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 16:\n[¬s]""Northwest Evaluation Association (NWEA) Measures of Academic Progress (MAP)[¬e]""', 'Page 17:\n[¬s]"" NWEA MAP test (post-test) in each of three subject areas (language usage, reading, and math[¬e]""']",NA,NA
37093467,Peer Tutoring,NA,NA,NA,NA,NA,NA,"Grade 2 - Teacher assigned grade (between a, b or c)",NA,Standard Arithmetic test by Ministry of Education ,NA,NA,NA
40117110,NA,NA,NA,NA,"['Page 57:\n[¬s]"" Comprehensive Tests of Basic Skills (CTBS), Form U (CTB/M cGraw-Hill, 1984)""\n""Spanish Assessment o f Basic Education (SABE) was used (CTB/M cGraw-Hill, 1988) ([¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117111,NA,NA,NA,NA,"['Page 12:\n[¬s]""Com prehensive Test o f Basic Skills, Form -U[¬e]""', 'Page 49:\n[¬s]""The pretest was the total reading subtest, Level D that is given in the Spring to students in the second grade. The post-test was the total reading subtest, Level E given to third grade students the following Spring. Level D has 117 multiple choice items and Level E has 127 multiple choice items (See Table 2).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671594,Teaching assistants,NA,NA,NA,"['Page 4:\n[¬s]""Automated Working Memory Assessment (AWMA; Alloway, 2007). The AWMA is a computerized test battery that assesses four different aspects of WM and has been standard- ized for use with typically developing children aged four and above[¬e]""']",NA,"['Page 6:\n[¬s]""The Cogmed Index of Improvement (CII), which is calculated by the software automatically, provides a measure of overall improvement on the trained tasks.[¬e]""']",NA,NA,NA,NA,NA,NA
37092573,Feedback,NA,NA,NA,NA,NA,"['Page 7:\n[¬s]""Following the experiment, a posttest writing assignment was administered over a two-day period. [¬e]""']",NA,NA,NA,NA,NA,NA
40294885,Feedback,NA,NA,NA,NA,NA,"['Page 7:\n[¬s]""Following the experiment, a posttest writing assignment was administered over a two-day period. Both pens and pencils were used to distinguish revision behavior. The attitude measure used initially was administered again. Each pretest and posttest essay was scored holistically by trained raters.[¬e]""']",NA,NA,NA,NA,NA,NA
40117190,NA,NA,NA,NA,"['Page 7:\n[¬s]""Metropolitan Readiness Test (MR""\n""Metropolitan Achievement Test (MA[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117239,Extending school time,NA,NA,WISC-III  WRMT-R Word Attack subtest (phonological decoding) WRMT-R Word Identification (real word reading accuracy out of context),"['Page 12:\n[¬s]""The WRMT-R Word Attack subtest was used as a measure of phonological de- coding, as in Study 1. Similarly, the WRMT-R Word Identification subtest was used as a measure of real-word reading accuracy out of context.[¬e]""']","Reading comprehension. The Gates-MacGinitie Reading Comprehension Test (GMG; MacGinitie & MacGinitie, 1989)",NA,NA,NA,"Developmental Reading Assessment (Beaver, 1997) for screening children at risk","['Page 10:\n[¬s]""Developmental Reading Assess- ment (Beaver, 1997) [¬e]""']",NA,NA
40117240,Extending school time,NA,NA,"Woodcock Johnson Psychoeducational Battery (WJ-R, Woodcock & Johnson, 1990)  - Writing Samples subtest evaluating writing quality ",NA,NA,NA,"3rd grade screen to identify at-risk composers (Berninger & Rutberg, 1992; Berninger et al., 1992) 4th grade high stakes test in writing",NA,4th grade high stakes test in writing,NA,NA,NA
37092626,Feedback,NA,NA,NA,"['Page 2:\n[¬s]""ure. The instrument used for assessing cognitive func- tioning was the Raven Coloured Progressive Matrices Test (Raven, 196[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38296603,Teaching assistants,NA,NA,NA,"['Page 11:\n[¬s]"" GL Assessment New Group Reading Test (NGRT) digital edition.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092628,Feedback,NA,NA,NA,NA,NA,"['Page 4:\n[¬s]"" Half of the posttest items, 1 from each category, were presented in each of the two format[¬e]""']",NA,NA,NA,NA,NA,NA
40294886,Small Group Tuition,NA,NA,NA,"['Page 7:\n[¬s]""Phonological Awareness Literacy Screening (PALS-K; Invernizzi, Sullivan, & Meier, 2001)""\n""Roswell-Chall Auditory Blending Test (Roswell & Chall, 1963/1997).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671632,Teaching assistants,NA,NA,NA,"['Page 6:\n[¬s]""Qualifications and Curriculum Authority (QCA) designed tests for the end of Year 4 and 5 (optional but conducted in almost all the study schools),[¬e]""']",NA,NA,NA,NA,NA,"['Page 6:\n[¬s]""6. Assessments of pupils in mathematics and literacy: these were test scores from KS1, including end of KS1 SATs results, ""\n"" and end of Year 6 KS2 SATs scores (in terms of raw scores in mathematics, English and science sent to us by schools, once marked and returned to them by the QCA).[¬e]""']",NA,NA
37092755,Feedback,NA,NA,NA,NA,NA,"['Page 55:\n[¬s]"" Guided by the content-behavior descriptions of the three learning units, two parallel forms of a summative achievement test were drafted. The first form was bo serve as both a pre- and post-test measure of achievement. The Other form was eventually to serve as the retention measure. These tests were designed to test the student\'s knowledge of the basic types and terminology of matrices and his ability to apply Important rules. To test these behaviors, content was sampled from each learning unit. Each test contained 25 items, none of Which were drawn from the formative tests.[¬e]""']",NA,NA,NA,NA,NA,NA
40294887,NA,NA,NA,NA,NA,NA,"['Page 4:\n[¬s]""In order to assess problem-solving effective- ness after exposure to condition, performance on the anagram task (i.e., number of anagrams correctly solved during the 3-min trial) was examined b y a 3 x 2 X 2 X 2 (Condition X Motivational Orientation X Sex X Experi- menter) analysis of variance (ANOVA).""\n""A second major question was the amount of time children would approach the target task or a similar task during the 5 min free-choice session.[¬e]""', 'Page 5:\n[¬s]"" the weights used were iden- tical to those used to test the performance measure.""\n""subjects were asked to recall the number of incomplete pictures they performed correctly, other children performed correctly, and then to evaluate how good subjects thought they and others were at this type of activity. A 3X2X2 (Condition X Motivational Orien- tation X Sex) ANOVA was conducted""\n""Immediately before leaving the experimen- tal setting, subjects were asked questions re- garding attributions about ability, effort, task difficulty, and luck on the incomplete pictures task on which they had worked earlier. A 3 X 2 X 2 (Condition X Motivational Orienta- tion X Sex) ANOVA[¬e]""']",NA,NA,NA,NA,NA,NA
37091022,Feedback,NA,NA,NA,NA,NA,"['Page 19:\n[¬s]""Care, equal to that given in the preparation of stimulus materials, was taken in the construction of recording devices. Record sheets matching the stimulus materials were constructed to facilitate accurate marking.[¬e]""', 'Page 20:\n[¬s]"" Teachers were instructed to make no mark on the record sheet if the child made a correct response and to slash the appropriate cell if the child made an error.[¬e]""']",NA,NA,NA,NA,NA,NA
39253250,Summer schools,NA,NA,NA,"['Page 7:\n[¬s]""Comprehensive Test of Basic Skills, 4th Edition (CTBS/4)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253387,Summer schools,NA,NA,DIBELS (letter naming fluency and phoneme segmentation fluency)  Developmental Reading Assessment (DRA)   Word List A assessment  dictation,NA,NA,NA,NA,NA,NA,NA,NA,NA
37092604,Feedback,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]""e formulation of the questions. The construction of a facet test and of analysis charts to compile the results may be done in three distinct steps. The first step involves an in-depth analysis of the subject to be taught, the second step is the formulation of the test itself, and the third step is the construction of the tool used for correction[¬e]""']",NA,NA,NA,NA,NA,NA
40294889,Feedback,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]""The construction of a facet test and of analysis charts to compile the results may be done in three distinct steps. The first step involves an in-depth analysis of the subject to be taught, the second step is the formulation of the test itself, and the third step is the construction of the tool used for correctio[¬e]""']",NA,NA,NA,NA,NA,NA
37093538,Peer Tutoring,NA,NA,"Achievement.   The reading-dependent measures in this study were standard scores of the reading subtests of the California Achievement Tests .  The subtests were (1) Reading Vocabulary, (2) Reading Comprehension, (3) Total Reading, and (4) Word Analysis.","['Page 10:\n[¬s]""Achievement. The reading-dependent measures in this study were standard scores of the reading subtests of the California Achievement Tests (Form E). These measures were used in order to compare these results with previous studies of CIRC. The subtests were (1) Reading Vocabulary, (2) Reading Comprehension, (3) Total Reading, and (4) Word Analysis.[¬e]""']","Treatment Integrity Survey.   In addition to the ongoing observations and consultative assistance, the teachers themselves completed a survey at midyear to determine how well they were implementing the components of CIRC.  Teachers  Ratings ofAcceptability.   In order to determine how acceptable the teachers found CIRC, a rating form was distributed to the CIRC teachers","['Page 10:\n[¬s]""Teachers\x92 Ratings ofAcceptability. In order to determine how acceptable the teachers found CIRC, a rating form was distributed to the CIRC teachers in the spring of 1991. The form allowed the teachers to rate each component and to list the strengths and weaknesses of CIRC.[¬e]""', 'Page 10:\n[¬s]""Teachers\x92 Ratings ofAcceptability. In order to determine how acceptable the teachers found CIRC, a rating form was distributed to the CIRC teachers[¬e]""', 'Page 10:\n[¬s]""Treatment Integrity Survey. In addition to the ongoing observations and consultative assistance, the teachers themselves completed a survey at midyear to determine how well they were implementing the components of CIRC.[¬e]""']",NA,NA,NA,NA,NA,NA
37091024,Feedback,NA,NA,NA,NA,NA,"['Page 2:\n[¬s]""SRA series Crocking the Code (Ras\xad mussen & Coldberg, 19GB)[¬e]""']",NA,NA,NA,NA,NA,NA
40294890,Feedback,NA,NA,NA,NA,NA,"['Page 1:\n[¬s]"" As a relatively new technique, precision teaching is practiced in a variety of ways but is generally characterized by (a) sys\xad tematic arrangement of instructional cues largely taken from programmed learning, (b) continuous measurement of frequency of cor\xad rect response for evaluation, and (c) careful management of reinforcement contingencies (Haring, 1971).[¬e]""', 'Page 2:\n[¬s]""measures frequency of response and views increased frequency as au indication of learning.""\n""The children received 1 minute timings twice each day on rate sheets of vocabulary from the SRA series Crocking the Code (Ras\xad mussen & Coldberg, 19GB).[¬e]""']",NA,NA,NA,NA,NA,NA
37092631,Feedback,NA,NA,"The Lorge-Thorndike Intelligence Tests, Multi-Level Edition, Form 1, nonverbal battery were used in both the pretest and criterion test. This was used as it is a widely used group intelligence test.  ","['Page 2:\n[¬s]""All test items on both the pretest and the cri- terion test were taken from the Lorge-Thorndike Intelligence Tests, Multi-Level Edition, Form 1, nonverbal battery. 3 This test was chosen because it is a widely used, well-constructed group intel- ligence test (Cronbach, 1960).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40294891,Feedback,NA,NA,NA,"['Page 2:\n[¬s]"" Lorge-Thorndike Intelligence Tests, Multi-Level Edition, Form 1, nonverbal battery. 3 [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253196,Summer schools,NA,NA,NA,"['Page 76:\n[¬s]""Scholastic Aptitude Test (SAT)[¬e]""', 'Page 78:\n[¬s]""Test of Standard W ritten English (TSWE)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092605,Feedback,NA,NA,DIBELS Test - six standardised measures of early literacy development ,"['Page 6:\n[¬s]"" The district used a set of measures called the Dynamic Indicators of Basic Early Literacy Skills (DIBELS)""\n""as a universal screening for all primary-aged students and for progress monitoring of at- risk students. [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671541,Teaching assistants,NA,NA,NA,"['Page 14:\n[¬s]""Pseudoword decoding (standardized). To provide a measure of decoding ability, the child attempted to read (or decode) pseudowords (e.g., ap, raff, raff, raff bim, roo, bufty, bufty, bufty tadding) in the word attack subtest of the Woodcock Reading Mastery Tests (Woodcock, 1987). (Scores could range from 0 to 37.)[¬e]""', 'Page 15:\n[¬s]""Passage comprehension (standardized). The child attempted items in the passage comprehension subtest of the Woodcock Reading Mastery Tests. This subtest used a cloze procedure to assess comprehension. (Scores could range from 0 to 36.)[¬e]""']",NA,"['Page 14:\n[¬s]""Word recognition (informal). The child read a list of 40 words, graded in difficulty from early first grade to fourth grade (7 to 10 words at each level) (see Appendix A). The words were selected from the graded lists in Basic Reading Vocabularies (Harris & Jacobson, 1982). Using Cronbach’s alpha, reliability was .83 on the pretest administration of the word recogni- tion list and .78 on the posttest administration.""\n""Passage reading (informal). The child read aloud up to five passages (four narrative, one informational) that progressed in difficulty from prep- rimer to late-second grade (see Appendix B). These passages, whose read- ability was checked with the Dale-Chall formula, had been field-tested for graded difficulty in previous studies (e.g., Morris et al., 2000; Santa & Hoien, 1999). Thus, the passages represented a continuous variable as- signed a value on an interval scale.[¬e]""']",NA,NA,NA,NA,NA,NA
37133869,Peer Tutoring,NA,NA,"This will be measured (pre and post program) by three subscales o f The Writer Self- Perception Scale (WSPS) (Bottomly, Henk, 8c Melnick , 1998).   The WSPS explores five aspects o f self-efficacy including General progress (GPR), Specific progress (SPR), Observational comparison (OC), Social feedback (SF), and Physiological states (PS) (Bottomly, Henk, & Melnick, 1998)   Pennsylvania State School Assessment (PSSA) Writing samples for all fifth graders were scored using the rubric for the writing portion o f the Pennsylvania State School Assessment (PSSA)","['Page 73:\n[¬s]""Writing samples for all fifth graders were scored using the rubric for the writing portion o f the Pennsylvania State School Assessment (PSSA)[¬e]""', 'Page 81:\n[¬s]"" The WSPS explores five aspects o f self-efficacy including General progress (GPR), Specific progress (SPR), Observational comparison (OC), Social feedback (SF), and Physiological states (PS) (Bottomly, Henk, & Melnick, 1998)[¬e]""']",A standardized open-ended interview was conducted (pre and post program) by an interviewer.  Writing samples  Journals and Observations,NA,NA,NA,NA,NA,NA,NA
37093539,Peer Tutoring,NA,NA,"Achievement test. The California Achievement Test, Fifth Edition (CAT/5), was used as both the pretest and posttest for mathematics achieve- men","['Page 6:\n[¬s]""Achievement test. The California Achievement Test, Fifth Edition (CAT/5), was used as both the pretest and posttest for mathematics achieve- men[¬e]""']","Student exit questionnaire. A student exit ques- tionnaire was developed by the researcher and administered to participating students during the last week of the study. There were eight questions on the survey, asking students about their attitudes regarding math, the computer math lessons, and group activities","['Page 6:\n[¬s]""Achievement test. The California Achievement Test, Fifth Edition (CAT/5), was used as both the pretest and posttest for mathematics achieve- ment.[¬e]""', 'Page 7:\n[¬s]""Student exit questionnaire. A student exit ques- tionnaire was developed by the researcher and administered to participating students during the last week of the study. There were eight questions on the survey, asking students about their attitudes regarding math, the computer math lessons, and group activit[¬e]""']",NA,NA,NA,NA,NA,NA
38296605,Small Group Tuition,NA,NA,NA,"['Page 13:\n[¬s]""GL Assessment""\n""Progress in English 12""\n""Progress in Maths 12[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38296604,Small Group Tuition,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 5:\n[¬s]""English and mathematics GCSE[¬e]""']",NA,NA
37061108,Feedback,NA,NA,NA,NA,Multiplication tests typically used to assess this area of mathematics in elementary schools were adapated to develop a pretest and four posttests for this study. ,NA,NA,NA,NA,NA,NA,NA
37671596,Teaching assistants,NA,NA,NA,"['Page 3:\n[¬s]""QCA end of year tests[¬e]""']",NA,NA,NA,NA,NA,"['Page 3:\n[¬s]""national SATS tests[¬e]""']",NA,NA
37671542,Teaching assistants,NA,NA,NA,"['Page 3:\n[¬s]""Single-word reading (screening; t1Ðt3). All children completed the Early Word Recognition (EWR) test (a = 0.98) from the York Assessment of Reading (YARC) Early Reading battery (Hulme et al., 2009). Children reading over 25 words were given an additional set of words from the Test of Single-Word Reading, from the YARC.""\n""Letter-sound knowledge (screening; t1Ðt3): This extended test of alphabetic knowledge from the YARC (Hulme et al., 2009) asks the child to provide the sound for 32 individual letters and digraphs (a = 0.98).""\n""Expressive and Receptive One-Word Picture Vocabulary Tests (EO- WPVT; ROWPVT; Brownell, 2000).[¬e]""', 'Page 4:\n[¬s]""Expressive grammar and information (t1Ðt3): Assessed using the Action Picture Test (APT; Renfrew, 1997). Basic concept knowledge (t1): From the Clinical Evaluation of Language Fundamentals (CELF) Pre- school 2nd Edition (Wiig, Secord, & Semel, 2006) assessed knowledge of 18 basic linguistic concepts (internal consistency = 0.85). Receptive grammar (t1): Measured by the Test for Reception of Grammar 2 (TROG-2; Bishop, 2003). Eight grammatical constructs were tested in blocks of four items; each correct item was awarded a score of 1 (internal consistency = 0.87).[¬e]""']",NA,"['Page 3:\n[¬s]""Phoneme blending (t1Ðt3): The child was asked to select which of three pictures represented a word spo- ken by the experimenter in ÔrobotÕ talk.""\n""Nonword reading (t1Ðt3): Children were asked to read the names of six cartoon monsters: ÔetÕ, ÔomÕ, ÔipÕ, ÔnegÕ, ÔsabÕ and ÔhicÕ. ""\n""Spelling (t1Ðt3): Ten words were presented as pictures to be named and spelled (see also Bowyer-Crane et al., 2008).""\n""Taught vocabulary knowledge (t1Ðt3): Tests were created to measure expressive and receptive knowledge of words explicitly taught in each phase of the inter- vention programme (i.e. weeks 1Ð20, tested t1Ðt3; weeks 21Ð40, tested t2Ðt3).[¬e]""']",NA,NA,NA,NA,NA,NA
37092634,Feedback,NA,NA,NA,"['Page 2:\n[¬s]"" Task B consisted of two examples from""\n""the divergent thinking “uses” test (Torrance & Templeton. 1963). The tasks for Session 2 were slightly different in order to reduce boredom and practice effects. In one task children were asked to construct a word tree using the first and last letters of each pre\xad ceding word, and the other task consisted of the “circles” test (Torrance & Templeton, 1963). A pilot study established that sixth-grade children found the experimental tasks interesting and that the tasks given at Sessions 1 and 3 yielded equivalent levels of performance.[¬e]""', 'Page 3:\n[¬s]""Task B. Scoring was according to the categories defined by Torrance and Templeton (1963). One point was given for each response (fluency), category (flexibility), and elaborated response, and 2 points were given for each original response, defined as a response appearing in no more than 10% of protocols.[¬e]""']",NA,"['Page 1:\n[¬s]""Experimental measures consisted of Session 3 performance scores and of the results of a questionnaire, given after Session 3, which tapped interest and patterns of attribution of success and effort.[¬e]""', 'Page 2:\n[¬s]"" a questionnaire designed to measure overt motivational attitudes was administered at the end of Session 3. Each booklet contained two tasks, A and B. In Task A of Booklets I and 3 (for Sessions 1 and 3, respectively) children were requested to construct as many words as they could from the letters of a longer word. ""\n""The first two questions on the motivation questionnaire (see Table 2) tested expressed interest in the experimental tasks; further questions tapped attribution of effort to various factors and per\xad ceptions of the factors determining success in the tasks. Finally, pupils were asked to express a preference for one of the three modes of evaluation employed in the study. Most questions were answered on a continuous 7-point scale (1 = low agreement and 7 = high agreement with the item in question). Other questions were presented in multiple choice form.[¬e]""', 'Page 3:\n[¬s]""Task A. Scoring was according to the criteria for successful performance given in the instructions.""\n""Two-letter words were given 2 points: three-letter words, 3 points; four-letter words, 5 points; and words of five or more letters, 6 points. Note was also made of the number of short (two- or three-letter) and long (four- or more letter) words produced.[¬e]""']",NA,NA,NA,NA,NA,NA
40294895,Feedback,NA,NA,NA,"['Page 2:\n[¬s]"". Task B consisted of two examples from the divergent thinking “uses” test (Torrance & Templeton. 1963). The tasks for Session 2 were slightly different in order to reduce boredom and practice effects. In one task children were asked to construct a word tree using the first and last letters of each pre\xad ceding word, and the other task consisted of the “circles” test (Torrance & Templeton, 1963). A pilot study established that sixth-grade children found the experimental tasks interesting and that the tasks given at Sessions 1 and 3 yielded equivalent levels of performance. The first two questions on the motivation questionnaire (see Table 2) tested expressed interest in the experimental tasks; further questions tapped attribution of effort to various factors and per\xad ceptions of the factors determining success in the tasks. Finally, pupils were asked to express a preference for one of the three modes of evaluation employed in the study. Most questions were answered on a continuous 7-point scale (1 = low agreement and 7 = high agreement with the item in question). Other questions were presented in multiple choice form. Procedure The experiment consisted of three sessions. Session I was con\xad ducted in I day, and Sessions 2 and 3 were conducted 2 days later, with an interval of 2 hr between them. The experiment was conducted in each class during regular school hours by one of two female graduate students in psychol ogy. In Session 1 instructions were identical for each group and were printed in Booklet 1. It was explained that the experimenters had constructed some tasks and needed to see howr different chil\xad dren answered them; they hoped that the children would enjoy doing them. Instructions for Task A were then read out loud. These included rules regarding acceptable words and criteria for successful performance (according to the number and length of words). Children were asked to begin, and after 5 min they were asked to stop and turn to Task B. Instructions for Task B, adapted from Torrance and Templeton (1963)[¬e]""', 'Page 3:\n[¬s]"" Scoring was according to the categories defined by Torrance and Templeton (1963). One point was given for each response (fluency), category (flexibility), and elaborated response, and 2 points were given for each original response, defined as a response appearing in no more than 10% of protocols[¬e]""']",NA,"['Page 2:\n[¬s]""a questionnaire designed to measure overt motivational attitudes was administered at the end of Session 3. ""\n""In Task A of Booklets I and 3 (for Sessions 1 and 3, respectively) children were requested to construct as many words as they could from the letters of a longer word""\n""The first two questions on the motivation questionnaire (see Table 2) tested expressed interest in the experimental tasks; further questions tapped attribution of effort to various factors and per\xad ceptions of the factors determining success in the tasks. Finally, pupils were asked to express a preference for one of the three modes of evaluation employed in the study. Most questions were answered on a continuous 7-point scale (1 = low agreement and 7 = high agreement with the item in question). Other questions were presented in multiple choice form[¬e]""', 'Page 3:\n[¬s]""Task A. Scoring was according to the criteria for successful performance given in the instructions. Two-letter words were given 2 points: three-letter words, 3 points; four-letter words, 5 points; and words of five or more letters, 6 points. Note was also made of the number of short (two- or three-letter) and long (four- or more letter) words produced.[¬e]""']",NA,NA,NA,NA,NA,NA
37092633,Feedback,NA,NA,NA,"['Page 3:\n[¬s]""Experimental tasks. The experimental task for both Session 1and Session 3consisted of two tasks taken from the divergent thinking uses test (Torrance & Templeto[¬e]""']",NA,"['Page 3:\n[¬s]""Interest Questionnaire After Session 1, pupils were given ashort questionnaire and asked to rate their interest in and enjoyment of the tasks and the degree to which other pupils would find them interesting on 7-point scales anchored with very, very interesting (7) and not at all interesting (l )""\n""Attributions questionnaire. After Session 3, pupils were asked to rate the degree to which various ego- and task-involved factors, which are presented in Table 1, affected effort, outcomes, and responses to the evaluation received. All ratings were made on 7-point scales, with 7indicating higher rat[¬e]""']",Class grades used to determine participation from the total sample (p.475),NA,NA,NA,NA,NA
40294893,Feedback,NA,NA,NA,"['Page 3:\n[¬s]""Experimental tasks. The experimental task for both Session 1and Session 3consisted of two tasks taken from the divergent thinking uses test (Torrance & Templeto[¬e]""']",NA,"['Page 3:\n[¬s]""Interest Questionnaire After Session 1, pupils were given ashort questionnaire and asked to rate their interest in and enjoyment of the tasks and the degree to which other pupils would find them interesting on 7-point scales anchored with very, very interesting (7) and not at all interesting (l ""\n""Attributions questionnaire. After Session 3, pupils were asked to rate the degree to which various ego- and task-involved factors, which are presented in Table 1, affected effort, outcomes, and responses to the evaluation received. All ratings were made on 7-point scales, with 7indicating higher rat[¬e]""']",NA,NA,NA,NA,NA,NA
40294894,Feedback,NA,NA,NA,"['Page 3:\n[¬s]""Experimental tasks. The experimental task for both Session 1and Session 3consisted of two tasks taken from the divergent thinking uses test (Torrance & Templeto[¬e]""']",NA,"['Page 3:\n[¬s]""Interest Questionnaire After Session 1, pupils were given ashort questionnaire and asked to rate their interest in and enjoyment of the tasks and the degree to which other pupils would find them interesting on 7-point scales anchored with very, very interesting (7) and not at all interesting (l )""\n""Attributions questionnaire. After Session 3, pupils were asked to rate the degree to which various ego- and task-involved factors, which are presented in Table 1, affected effort, outcomes, and responses to the evaluation received. All ratings were made on 7-point scales, with 7indicating higher rat[¬e]""']",NA,NA,NA,NA,NA,NA
37092575,Feedback,NA,NA,"Students undertook a stanardised comprehension pre-test and post-test, which required summarising one or two randomised texts ""Dust Bowl"" and ""Influenza"". These were completed as pencil and paper tests, without the use of technology and occured during a 45-minute classroom session.   During the intervention period, the experimental groups completed a mean of 4.9 texts using Summarise Street. The software was used to test the performance of each submitted summary, including the post-test results which the control group also undertook. ","['Page 10:\n[¬s]""summary .passed the content requirement for this section.[¬e]""', 'Page 9:\n[¬s]"" For these pre and post exercises, students read orte of two texts (“Dust Bowl” or “Influenza”); which are simi? lar in length (954 and 1,175 words, respectively) and reading level (12th grade).""\n""Reading and summary writing, using pencil and paper, took place during a single, 45-minute class period; Half of the students of each class received one text for the pretest, and the other Half the other text in.,a randomized assignment. For the posttest, each student received the text he or she had not summarized during the pre-assessment;""\n""To analyze the data, the tran\xad scribed summaries were submitted to Summary Street to obtain LSA cosines for content coverage of the source text.2 These cosines were then compared to the threshold for each section of the source text-to determine whether the[¬e]""']",NA,"['Page 8:\n[¬s]"" spe\xad cific quizzes that assess students’ learning from text,""\n""independently written summaries[¬e]""', 'Page 9:\n[¬s]""As pail of the overall evaluation of Summary Street, all the students in the experimental and control classes wrote a summary at the beginning and end of the school\'term.""\n""Half of the students of each class received one text for the pretest, and the other Half the other text in.,a randomized assignment. For the posttest, each student received the text he or she had not summarized during the pre-assessment;""\n""To analyze the data, the tran\xad scribed summaries were submitted to Summary Street to obtain LSA cosines for content coverage of the source text.2""\n""These cosines were then compared to the threshold for each section of the source text[¬e]""']",NA,NA,NA,NA,NA,NA
40294896,Feedback,NA,NA,NA,"['Page 13:\n[¬s]"" test battery of comprehension items from retired CSAP (Colorado State Assessment Program)""\n"" students’ CSAP and Scholastic Reading Inventory (Scholastic, 1999) test scores [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093518,Peer Tutoring,NA,NA,"Mathematics Achievement The Math Operations TestÐRevised (MOT-R; Fuchs et al., 1991) assesses first- through sixth-grade math operations skills. The test comprises 50 problems requiring addition, subtraction, multiplication, and division using whole numbers, decimals, and fractions.  The Math Concepts and Applications Test (MCAT; Fuchs et al., 1991) assesses first- through sixth-grade knowl- edge of number concepts, numeration, applied computation, geometry, measurement, chart and graphs, and word prob- lems.  scores from the mathematics portion of the Tennessee Comprehensive Achievement Test (TCAP), a high- stakes assessment needed for graduation, were gathered. ","['Page 3:\n[¬s]""Mathematics Achievement. The Math Operations TestÐRevised (MOT-R; Fuchs et al., 1991) assesses first- through sixth-grade math operations skills. The test comprises 50 problems requiring addition, subtraction, multiplication, and division using whole numbers, decimals, and fractions. Students have 10 minutes to answer questions. Responses are scored by number of problems correct. The correlation between the MOT-R and the Math Computation subtest of the Stanford Achievement Test (Fuchs et al., 1994) was .78, and internal consistency reliability was .87. The Math Concepts and Applications Test (MCAT; Fuchs et al., 1991) assesses first- through sixth-grade knowl- edge of number concepts, numeration, applied computation, geometry, measurement, chart and graphs, and word prob- lems. Students have 15 minutes to construct responses to 50 problems spanning Grades 1 through 6. Performance is scored by number of problems correct. Criterion validity with the Concepts of Number subtest of the Stanford Achievement Test was .80, and internal consistency reliability was .92 (Fuchs et al., 1994). In addition, scores from the mathematics portion of the Tennessee Comprehensive Achievement Test (TCAP), a high- stakes assessment needed for graduation, were gathered.[¬e]""']",Questionnaires A student questionnaire was adminis- tered to explore student beliefs and perceptions of the bene- fits of PALS and CBM -A teacher questionnaire was administered to explore teacher perceptions of the benefits of PALS and CBM.,"['Page 5:\n[¬s]""Questionnaires. A student questionnaire was adminis- tered to explore student beliefs and perceptions of the bene- fits of PALS and CBM.""\n""In addition, a teacher questionnaire was administered to explore teacher perceptions of the benefits of PALS and CBM.[¬e]""']",NA,NA,NA,NA,NA,NA
40117116,NA,NA,NA,"Gates­MacGinitie Reading Test, Form K   ",NA,NA,NA,school absences promotion rate number of library books read reading levels completed,"['Page 3:\n[¬s]"" Other stu\xad dent outcome data were collected during the regular school year for both the year-round and the traditional-schedule students and reported in June 1991 and June 1992 as part of the required federal Chapter 1 performance reports. These data included: absences, promotion rate, number of library books read, and reading levels com\xad pleted.[¬e]""']",NA,NA,NA,NA
37116223,Peer Tutoring,NA,NA,NA,"['Page 110:\n[¬s]""The children were assessed for Reading Comprehension, Word Attack skills and Reading Vocabulary via sub tests from the Woodcock-Johnson Psvcho Educational Battery Form A (Woodcock & Johnson, 1989,1990). ""\n""heir fluency, measured in words per minute, was assessed using grade level readings, “First and Second Grade Fluency Measures” (Appendix C). Reading attitudes were pretested using The Reading Attitude Survey (Leland & Fitzpatrick, 1994; Appendix G)""\n""Tutees and Tutee Controls were post tested on these same measures. Tutees and Tutee Controls engaged in “cold” readings in determining fluency. They took Form A of the Woodcock-Johnson as a pretest and were post tested using Form B. Tutees and Tutee Controls took the identical form of their reading attitude survey as a post test.[¬e]""', 'Page 111:\n[¬s]""Tutors, Metacognitively-Trained Tutors, and Tutor Controls were pretested and post tested on the Comprehension and Vocabulary sub-tests of The Stanford Achievement Test (Gardner et al., 1990). The Stanford is a group administered test.""\n""The older students’ fluency, measured in words per minute, was assessed using a grade level readings in like manner to the younger children. Reading attitudes were assessed via The Reader Self-Perception Scale (Henk & Melnick, 1995).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093351,Peer Tutoring,NA,NA,"Scott-Foresman basal series  Word Recognition subtest of the Brigance Inventory of Basic Skills, (Brigance, 1977).  Gates-MacGinitie Reading Test, Form 1 (MacGinitie, 1978) All subjects were administered appropriate levels of the Gates-MacGinitie Reading Test, Form 1 (MacGinitie, 1978) at the beginning of the tutoring program to function as a pretest. The post-test was done using Form 2 of the same instrument.","['Page 3:\n[¬s]""Reading levels of the students had been previ\xad ously determined by reading tests which accom\xad pany the Scott-Foresman basal series used in the classrooms.""\n""Within the experimental group, selection of the tutor-tutee dyad was made on the basis of the number of sight words recognized on the Word Recognition subtest of the Brigance Inventory of Basic Skills, (Brigance, 1977).""\n""All subjects were administered appropriate levels of the Gates-MacGinitie Reading Test, Form 1 (MacGinitie, 1978) at the beginning of the tutoring program to function as a pretest. The post-test was done using Form 2 of the same instrument.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117117,Extending school time,NA,NA,Stanford Achievement Test,NA,NA,NA,NA,NA,NA,NA,NA,NA
39253388,NA,NA,NA,NA,"['Page 16:\n[¬s]"" Gates-MacGinitie reading tests[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117193,Extending school time,NA,NA,NA,"['Page 15:\n[¬s]"" the Woodcock- Johnson Tests of Reading and Mathematics Achievement[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117118,NA,NA,NA,CTBS (McGraw-Hill)   Scholastic Aptitude (College Entrance Examination Board)  CAP (California Assessment Program Results)  Stanford Achievement Test (Psychological Corporation),NA,NA,NA,NA,NA,NA,NA,NA,NA
37116229,Peer Tutoring,NA,NA,NA,NA,NA,NA,NA,"['Page 8:\n[¬s]"" two post-tests were developed by one experienced teacher who had 15 years of experience in mathematics education in an elementary school.""\n"" The post-test consisted of 10 \x93Working with fractions and whole numbers\x94 items for assessing the students\x92 fraction calculation ability.[¬e]""']",NA,NA,NA,NA
37671546,Teaching assistants,NA,NA,NA,"['Page 5:\n[¬s]""New Group Reading Test Digital (NGRT; GL Assessment, 2010)""\n""This is an adaptive, multiple-choice test that begins with a sentence completion task and then, depending upon the accuracy of responses, either drops down in difficulty to phonics tasks or becomes harder and assesses passage comprehension. The comprehension questions target a range of skills including inferencing and vocabulary. [¬e]""', 'Page 6:\n[¬s]"" Test of Word Reading Efficiency 2 (TOWRE-2; Wagner, Torgesen, & Rashotte, 2011), which includes two subtests: Sight Word Efficiency and Phonemic Decoding Efficiency (nonword reading). In each of these, participants are required to read aloud as many items as possible in 45 s. Errors are noted by the examiner but not corrected.[¬e]""', 'Page 7:\n[¬s]""Single Word Reading Test In addition to being used for screening, the SWRT (Foster & National Foundation for Educational Research, 2008) was also used at each time point to assess word reading accuracy.[¬e]""', 'Page 8:\n[¬s]""York Assessment of Reading for Comprehension (Stothard, Snowling, Clarke, Barnby, & Hulme, 2012)""\n""Wechsler Individual Achievement Test 2nd edition UK for Teachers ""\n"" reading comprehension""\n"" WIAT II UK for Teachers (Wechsler, 2006)""\n""Wechsler Abbreviated Scale of Intelligence II \x96 Vocabulary""\n""vocabulary measures""\n""WASI II (Wechsler, 2011)[¬e]""']",NA,"['Page 8:\n[¬s]""The bespoke test consisted of 16 words, eight taught words (e.g., prevent) and eight comparable nontaught words (e.g., claim) pairwise matched on Thorndike and Lorge (1944) written frequency. The test assessed Tier 2 vocabulary (Beck et al., 2002)[¬e]""']",NA,NA,NA,NA,NA,NA
39253281,Summer schools,NA,NA,NA,"['Page 37:\n[¬s]""The Marie Clay Observational Surveys[¬e]""', 'Page 38:\n[¬s]""The Harcourt Brace Skills Tests [¬e]""']",NA,NA,NA,"['Page 37:\n[¬s]""The Phonemic Aw areness Interview (PAI)""\n""The Literacy Curriculum Scale (LCS)[¬e]""']",NA,NA,NA,NA
37092576,Feedback,NA,NA,NA,NA,"Pretest and posttests were designed for the purposes of the experiment. Details on the content of these tests was not provided, apart from stating that these tests were in essay format. ","['Page 36:\n[¬s]""Pr e t es tphas e .""\n""Schools forwarded pretests directly to Chesapeake Research Associates, which relabeled the student essays with coded identification numbers and sent them to the essay rating team at Education Northwest.[¬e]""', 'Page 37:\n[¬s]""Pos t t e s tphas e[¬e]""']",NA,NA,NA,NA,NA,NA
37671598,Teaching assistants,NA,NA,NA,NA,NA,"['Page 113:\n[¬s]""Multiple Skills Basic Math Probes (M-CBM)""\n""Math WPS probes[¬e]""', 'Page 5:\n[¬s]""Outcomes were measured using brief timed assessments of basic math calculation and word problem solving[¬e]""']",NA,NA,NA,NA,NA,NA
40117120,Extending school time,NA,NA,NA,"['Page 38:\n[¬s]"" Iowa Test o f Basic Skills.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
43090135,Extending school time,NA,NA,NA,"['Page 90:\n[¬s]""The Basic Number Screening Test (BNST) (New Edition)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671620,Teaching assistants,NA,NA,NA,"['Page 90:\n[¬s]""Maths attainment: Basic Number Screening Test""\n""The Basic Number Screening Test (BNST) (New Edition), [¬e]""', 'Page 93:\n[¬s]""Measuring self-esteem""\n""The Burnett Self-Scale (BSS, Burnett, 1994) which looks at self-reports[¬e]""', 'Page 94:\n[¬s]""The Behavioural Indicators of Self-EsteemScale (BIOS, Burnett, 1998) which looks at teacher-reports.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117121,Teaching assistants,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 90:\n[¬s]""he Stanford Achievement Test, 1982 Edition""\n""Clark County School D is t r ic t Reading and Mathematics CRTs[¬e]""']",NA,NA
37093542,Peer Tutoring,NA,NA,The Gap Test (McLeod 1977): a standardised reading comprehension test that uses the cloze technique.  Miscue Analysis Comprehending Score: a score gained by analysing oral reading performances and balancing good miscues against total miscues and expressing this balance as a percentage (Goodman 1973).  Speed of Reading Score: a words-per-minute count made on the oral reading performance.,"['Page 3:\n[¬s]"" The Gap Test (McLeod 1977): a standardised reading comprehension test that uses the cloze technique.""\n""Miscue Analysis Comprehending Score: a score gained by analysing oral reading performances and balancing good miscues against total miscues and expressing this balance as a percentage (Goodman 1973).""\n""Speed of Reading Score: a words-per-minute count made on the oral reading performance.[¬e]""']",Non Standardised Cloze Test: a lest designed for this investigation to evaluate readers’ use of context in reading comprehension.,"['Page 3:\n[¬s]""Non Standardised Cloze Test: a lest designed for this investigation to evaluate readers’ use of context in reading comprehension.[¬e]""']",NA,NA,NA,NA,NA,NA
37091026,Feedback,NA,NA,NA,"['Page 2:\n[¬s]""Wide Range Achieve\xad ment Test and a criterion test[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253200,NA,NA,NA,NA,"['Page 20:\n[¬s]"" Stanford Achievement T e s t, Prim ary II B a tte ry , Form X, subtests on A rith m e tic Reasoning, A rith m e tic Computa\xad tio n , Word Meaning and Paragraph Meaning[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253314,Summer schools,NA,NA,NA,"['Page 7:\n[¬s]""1992 and 1993 ITBS Reading Comprehension and Math Total scores[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093543,Peer Tutoring,NA,NA,NA,NA,"The material for the pre and post-test comprised of booklets consisting of single and multiple-answer story format problems of addition and subtraction  Topics covered were money, time, weight, distance. Problems were craeted to conform in detail with the curriculum for Primary 6    ","['Page 5:\n[¬s]""The addition and subtraction problems. The materials for the pre- and post-test comprised small booklets consisting of single- and multiple-answer story format problems. The multiple-answer problems were an amalgamation of two or more single-answer problems giving longer and more complex problems (Appendix 1). The problems were all addition and subtraction, but they varied in topic area and structure.[¬e]""']",NA,NA,NA,NA,NA,NA
39253203,Summer schools,NA,NA,NA,"['Page 98:\n[¬s]"" Wide- Range Achievement Test (WRAT[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
43090138,Summer schools,NA,NA,"Wide Range Achievement Test (WRAT, Jastak and Jastak, 1965)","['Page 98:\n[¬s]"" Wide- Range Achievement Test (WRAT) (Jastak and Jastak, 1965)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117246,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
40117123,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
37093616,Peer Tutoring,NA,NA,"1.RLN   was used to select students for assessments. It also serves as a pretest variable. RLN assesses the number of letter names a student identifies in 1 min  2. Teacher-Rated Inattention  Teachers rated students' pretest classroom behavior on the short version French adaptation of the Conners' Teachers Rating Scale (Conners 2000)  3.Progress Assessments  From October through April, recognition of grapheme-phoneme correspondence was assessed every other week.   4.End-of-Year Assessments  At the end of April, word recognition skills were assessed with the Échelles de compétences en lecture (Desrochers 2008).  5. Reading comprehension was assessed with Lire pour comprendre, a test modeled after the Comprehensive Reading Assessment Battery (Fuchs et al. 1988).","['Page 4:\n[¬s]""End-of-Year Assessments At the end of April, word recognition skills were assessed with the Échelles de compétences en lecture (Desrochers 2008).[¬e]""', 'Page 4:\n[¬s]""Progress Assessments From October through April, recog- nition of grapheme-phoneme correspondence was assessed every other week.[¬e]""', 'Page 4:\n[¬s]""RLN was used to select students for assessments. It also serves as a pretest variable. RLN assesses the number of letter names a student identifies in 1 min""\n""Teacher-Rated Inattention Teachers rated students \x92 pretest classroom behavior on the short version French adaptation of the Conners \x92 Teachers Rating Scale (Conners 2000)""\n""Progress Assessments From October through April, recog- nition of grapheme-phoneme correspondence was assessed every other week.""\n""End-of-Year Assessments At the end of April, word recognition skills were assessed with the Échelles de compétences en lecture (Desrochers 2008)""\n"" Reading comprehension was assessed with Lire pour comprendre, a test modeled after the Comprehensive Reading Assessment Battery (Fuchs et al. 1988).[¬e]""', 'Page 4:\n[¬s]""Teacher-Rated Inattention Teachers rated students \x92 pretest classroom behavior on the short version French adaptation of the Conners \x92 Teachers Rating Scale[¬e]""']",Observed Classroom Attention Observations were conducted to provide a measure sensitive to intervention effect on attention   Each student was observed during a single whole-class reading lesson,"['Page 4:\n[¬s]""Observed Classroom Attention Observations were conducted to provide a measure sensitive to intervention effect on attention (see Stoolmiller et al. 2000). Each student was observed during a single whole-class reading lesson.[¬e]""']",NA,NA,NA,NA,NA,NA
37671548,Teaching assistants,NA,NA,NA,"['Page 19:\n[¬s]"" four subtests (handwriting fluency, word generation, sentence combining and paragraph writing) from the Weschler Individual Attainment Test II (WIAT-11, 2005) were used in all target and comparison classes.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
43090143,NA,NA,NA,"Comprehensive Tests of Basic Skills (CTBS, 1973, 1974): - total prereading battery - reading achievement  Spache Diagnostic Reading Scales (Spache 1972) - The Word Recognition  - Reading Passages ","['Page 3:\n[¬s]""entile on the national norms for the CTBS ""total prereading"" battery, l[¬e]""', 'Page 4:\n[¬s]""(Comprehensive Tests of Basic Skills 1973, 1974[¬e]""', 'Page 5:\n[¬s]""ully completed. CTBS reading achievemen[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37091027,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
37093544,Peer Tutoring,NA,NA,"Standardized achievement tests (Metropolitan Achievement Tests. Form F, Form H) and the More Like Me Scale for Young Children and the Children's Self Descriptive Scale were used to measure reading achievement and self concept gains among the students.  Metropolitan Achievement Tests Primary Level, Form F and Form H; Metropolitan Achieve­ ment Tests, Elementary Level, Form F and Form H; More Like Me Scale for Young Children: and Children's Self- Descriptive Scale.","['Page 3:\n[¬s]""Pre and posttest data relative to the variables under investigation were gath\xad ered through the use of: Metropolitan Achievement Tests Primary Level, Form F and Form H; Metropolitan Achieve\xad ment Tests, Elementary Level, Form F and Form H; More Like Me Scale for Young Children: and Children\'s Self- Descriptive Scale.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671600,Teaching assistants,NA,NA,NA,"['Page 2:\n[¬s]""hildren were assessed on two tests of word reading from the York Assessment of Reading for Comprehension (YARC): Early Word Reading (EWR, Hulme et al., 2009) and Single Word Reading[¬e]""', 'Page 3:\n[¬s]""following standardised tests""\n""Letter \x96 Sound Knowledge, Sound Deletion, Early Word Reading (also at t0), Single Word Reading (also at t0) and Passage Reading (yielding measures of Prose Reading Accuracy and Reading Comprehension) from the YARC (Hulme et al., 2009; Snowling et al., 2009); the Graded Nonword Reading Test (Snowling, Stothard, & McLean, 1996); and Expressive Vocabulary (picture naming) from the Clinical Evaluation of Language Fundamentals IV (Semel, Wiig, & Secord, 2003).""\n""Sound Linkage Test of Phono- logical Awareness (Hatcher, 2000""\n""Orthographic Spelling score""\n""Phonetic Spelling score[¬e]""']",NA,"['Page 3:\n[¬s]""Taught vocabulary. To assess knowledge of words taught in the intervention, children gave de\x1enitions of 24 words (12 targeted in weeks 1 \x96 9 of intervention, 12 in weeks 10 \x96 18).""\n""Listening comprehension. Children listened to and answered questions about two short stories.[¬e]""']",NA,NA,NA,NA,NA,NA
40117126,NA,NA,NA,NA,NA,NA,NA,NA,NA,The Texas Assessment of Academic Skills (TAAS),NA,NA,NA
39253282,Summer schools,NA,NA,"The TAAS (TEA 1998) reading subject test was used at a pretest/posttest assessment  The Iowa Tests of Basic Skills (Vocabulary and Reading Comprehension only)  The Phonemic Awareness and Phonics Inventory was administered to determine phonemic awareness, letter recognition, letter-sound relationships, and word recognition ","['Page 66:\n[¬s]""T he T A S S read in g s u b je c t te st w a s used at a p re te s t/p o s tte s t a s se s s m e n t to d e te rm in e the m a s te ry o f th e reading skills te s te d . T h e Io w a T ests o f B a sic S kills ( V o c a b u la ry an d R eading C o m p re h e n s io n o n ly )""\n""T he P h o n e m ic A w a re n e ss an d P honics In v e n to ry w as a d m in is te r e d to d eterm in e p h o n e m ic a w a re n e ss, letter re c o g n itio n , letter- s o u n d re la tio n sh ip s, and w o rd re c o g n itio n [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253283,Summer schools,NA,NA,NA,"['Page 23:\n[¬s]"" 4-Sight Benchmark Tests and the Pennsylvania System of School Assessment (PSSA) tests in reading and math [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117194,NA,NA,NA,NA,NA,NA,NA,School records,NA,NA,NA,NA,NA
37133886,Peer Tutoring,NA,NA,"The Student Self-Concept Scale ( S S C S ) , Level 2, was used on b ot h testing occasions and mea s u r e d self-concept base d u p o n the student's own perceptions rather than on the observations of parents or teachers,composed of 72 items covering three subscales: social, academic, and self-awareness  Texas Assessment of Academic Skills -skills in reading, mathematics,and writing.","['Page 38:\n[¬s]""Texas Assessment of Academic Skills ( T A A S ) ; A state-wide standardized test that students in Grades 3, 4, 5, 6, 7, 8, and 10 must take. The T AAS has tests in reading, mathematics, writing, science, and social studies. Reading and mathematics tests are given at Grades 3, 4, 5, 6, 7, 8, and 10. The w r i t i n g test is given at Grades 4, 8, and 10 only. Science and social studies tests are given at Grade 8 only. TAAS results show the performance of non-sp eci al- edu cation students who were in the district as of late O c t o b e r in each school year. The TAAS standards for the school a c c o u n t \xad ability rating are as follows: Ex em p l a r y - - a t least 90% passing; Reco g n i z e d - -70% to 89.9% passing; Acceptable-- 25% to 69.9% passing; and Lo w-p e r f o r m i n g — less than 25% passing (TEA, 1996).[¬e]""', 'Page 79:\n[¬s]"" The Student Self-Concept Scale ( S S C S ) , Level 2, was used on b ot h testing occasions and mea s u r e d self-concept base d u p o n the student\'s own perceptions rather than on the observations of parents or teachers. The inventory assesses self-concept in students 10 t[¬e]""', 'Page 80:\n[¬s]""18 years of age and is composed of 72 items covering three subscales: social, academic, and self-awareness. For this study, the academic score and the composite score for social, academic, and self-awareness w e r e the two used for the statistical analysis.[¬e]""', 'Page 83:\n[¬s]""Texas Assessment of Academic Skills""\n""According to the TEA (1997), the goal of the assess\xad ment p r ogram in Texas is to measu re student progress toward achieving academic excellence""\n""n the fall of 1990, state law began to require the implementation of a n e w criterion-referenced testing program, the Texas Assessment of Academic Skills (TAAS) to be used as a measure of institutional accountability.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092761,Feedback,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]""ests A table of specifications was employed to design a post test covering each of the dimensions of the content in the textual material. The result of this analysis was a posttest of 42 items consisting of three sub tests, which were: Recognition (16 items)?measuring subjects\' ability to identify examples of each set of numbers in the number system they had encountered in the text; Production (8 items)?measuring subjects\' ability to produce a hierarchy of the number system when the concepts were provided in random order; Comprehension (18 items)?measuring sub jects\' ability to identify relationships among concepts in the number system (e.g., of the numbers 2, 3/4, and -2, which two are most closely related?). Reliability was established using the Kuder-Richardson 21. The results for each subtest and the total test are as follows: Recognition.84 Production.75 Comprehension.60 Total test.78 Differences we[¬e]""']",NA,NA,NA,NA,NA,NA
40294902,Feedback,NA,NA,NA,NA,NA,"['Page 94:\n[¬s]""Comprehension Assessment Oral Retelling Scoring Procedure A scoring procedure for passage 3 oral retellings was modified from a procedure by Smith and Jackson (1985).[¬e]""', 'Page 97:\n[¬s]""Sentence Verification Technique Comprehension assessment questions for the passages were developed following the ""sentence verification technique"" (Royer, Greene, and Sinatra, 1987).[¬e]""']",NA,NA,NA,NA,NA,NA
38878251,Small Group Tuition,NA,NA,"Pretests  GMRT4 Level Beginning reading (BR), MacGinitie et al., 2000; 2002 The Ekwall/Shanker Reading Inventory, 2003  Posttests  WRMT-R Word Identification Test Form G and Word Attack test (Woodcock, 1987; 1998) The Ekwall/Shanker Reading Inventory, 2003 GMRT4, Level 1, MacGinitie et al., 2000; 2002","['Page 13:\n[¬s]"" WRMT-R Word Identification Test Form G of the WRMT-R required students to read a list of real words that increased in difficulty. The median split-half reliabil\xad ity of this measure is reported to be 0.98 (Woodcock, 1987, 1998). 2. WRMT-R Word Attack Test. Students read a list of decodable nonwords. The median split-half reliability of this measure is reported to b[¬e]""', 'Page 14:\n[¬s]"" the Ekwall/Shanker Reading Inventory (4th ed.; Shanker & Ekwall, 2003)[¬e]""', 'Page 14:\n[¬s]""The GMRT4, Level 1[¬e]""', 'Page 8:\n[¬s]""he GMRT4 Level BR (Beginning Reading; MacGinitie et al., 2000; MacGinitie, MacGinitie, Maria, & Dreyer, 2002) was administered to classrooms of first graders in all eight schools in November. This multiple-choice test mea\xad sured students’ knowledge of letter-sound correspondences and their ability to read high-frequency words.[¬e]""', 'Page 9:\n[¬s]"" Informal reading inventory. The Ekwall/Shanker Reading Inventory (4th ed.; Shanker & Ekwall, 2003)[¬e]""']","Pretests  Adapted tests from Clay (Reading Recovery) RES Individual Pretests, seven subtests  Posttests  RES Individual Posttests, seven subtests ","['Page 14:\n[¬s]"" RES individual posttests. The seven subtests of the RES individual pretest[¬e]""', 'Page 8:\n[¬s]""RES Classwide Screening Assessments. The RES screen consisted of four group- administered tests adapted from Clay (1993a, 2002[¬e]""', 'Page 9:\n[¬s]"" RES Individual Pretests.[¬e]""']",NA,NA,"Iowa Tests of Basic Skills (ITBS) Level 6 Vocabulary subtest. Hoover et al., 2001;2003","['Page 8:\n[¬s]"" Iowa Tests of Basic Skills (ITBS; H. Hoover et al., 2001, 2003) vocabulary test. The ITBS Level 6 vocabulary subtes[¬e]""']",NA,NA
39253253,Summer schools,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 88:\n[¬s]""he annual state SBA tests were used as both the pretest and the posttest.[¬e]""', 'Page 90:\n[¬s]""The Alaska SBA is a criterion-referenced assessment. The SBA is content-based and aligned directly to the Alaska statewide content standards.[¬e]""']",NA,NA
37061114,Feedback,NA,NA,NA,NA,NA,"['Page 76:\n[¬s]""The cloze tests of the two passages were constructed so that every fifth word was deleted (""the typical procedure"") resulting In fifty deletions per passage\x97the minimum needed for ""high reliability"" (Harris and Sipay, 1980). Only exact word responses were scored as correct; synonyms were not accepted.[¬e]""', 'Page 77:\n[¬s]"" 10 multiple-choice questions on each comprehension question posttest.[¬e]""']",NA,NA,NA,NA,NA,NA
40117128,Extending school time,NA,NA,Texas Assessment of Academic Skills (TAAS),NA,NA,NA,student achievement and attendance,NA,NA,NA,NA,NA
37093353,Peer Tutoring,NA,NA,"Gates-MacGinitie Reading Tests, 1965",NA,NA,NA,NA,NA,NA,NA,NA,NA
40117129,NA,NA,NA,IOWA Test of Basic Skills (ITBS) - maths - Reading,NA,NA,NA,NA,NA,NA,NA,NA,NA
37093472,Peer Tutoring,NA,NA,"Self-Perception Profile (Harter 1985), a 36-item pencil-and-paper instrument",NA,"Student satisfaction was assessed with an eight-item, 3-point Likert-type scale: did not like (1), like a little (2), like a lot (3).   Teacher satisfaction. Individual, structured interviews Teacher feedback was sought regarding the following: (a) acceptability of the methods, (b) collateral effects observed in the classroom (i.e., changes in student mathematics achievement, conduct, and social skills), (c) student self-reports about program activities, and (d) interest in continuing involvement in the program the following year.",NA,teachers helped design the math computation test and administered the test to students during a regular mathematics lesson.  both in the beginning and at the end of the study,NA,NA,NA,NA,NA
37093471,Peer Tutoring,NA,NA,"Curriculum-based computation test, Stanford Diagnostic Mathematics Test, andt the Self-Perception Profile for Children ",NA,NA,NA,NA,NA,NA,NA,NA,NA
38878265,Small Group Tuition,NA,NA,"pretest  TOLD-P-3, Relational vocabulary subtest (in Table 1, this is called: Oral language proficiency)   posttest  Narrative Assessment Procedure (Strong, 1998), retelling a narrative text, expository retell","['Page 7:\n[¬s]""The Relational Vocabulary subtest of the TOLD-P-3 was individually administered to all students before the intervention and was used to identify students at risk for language difÞculties, and to match and assign students to conditions[¬e]""', 'Page 9:\n[¬s]""Oral language proÞciency Control""\n""Narrative retell Control""\n""Expository retell[¬e]""']","Depth of Vocabulary knowledge  (in Table 1, this is shown to have been measured both before and after the intervention)","['Page 7:\n[¬s]""The Depth of Vocab- ulary Knowledge[¬e]""', 'Page 9:\n[¬s]""Vocabulary knowledge[¬e]""', 'Page 9:\n[¬s]""Vocabulary knowledge[¬e]""']",NA,NA,NA,NA,NA,NA
40117274,Small Group Tuition,NA,NA,NA,"['Page 11:\n[¬s]"" California Achievement Test (Spring, CAT 16E)[¬e]""']",NA,NA,NA,NA,NA,"['Page 11:\n[¬s]""Michigan Educational Assessment Program (Fall, MEAP)[¬e]""']",NA,NA
37093506,Peer Tutoring,NA,NA,"Gates-MacGinitie Reading Tests (GMRT), Fourth Edition, a standardized reading assessment that focuses on vocabu­ lary and reading comprehension skills.  Stanford Achievement Test (SAT-9)","['Page 3:\n[¬s]""Gates-MacGinitie Reading Tests (GMRT), Fourth Edition, a standardized reading assessment that focuses on vocabu\xad lary and reading comprehension skills.""\n""Second, the statewide assessment system Stanford""\n""Achievement Test (SAT-9)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092577,Feedback,NA,NA,NA,NA,NA,"['Page 10:\n[¬s]""D o w n l o a d e d b y [ D u r h a m U n i v e r s i t y L i b r a r y ] a t 0 8 : 4 1 1 7 S e p t e m b e r 2 0 1 7 TEACHING CHILDREN REVISION IN WRITING 11 variables for revisions made (all per 100 words) at each stage were formed from the writing/revision task""\n""Two trained doctoral students scored the typed stories (previously arranged in a random order) using an analytic scale based on the work of Diederich (1974) and Beach (1979).[¬e]""', 'Page 9:\n[¬s]"" Using Faigley and Witte’s (1981, 1984) classification scheme for revision, one lead variable and five follow-up[¬e]""']",NA,NA,NA,NA,NA,NA
37133895,Peer Tutoring,NA,NA,NA,NA,NA,"['Page 12:\n[¬s]""A fractions test was constructed, with five items per objective and this was administered in the primary and secondary classrooms two or three weeks before the project started.""\n""Due to the danger of a ceiling effect on the fractions test, (some had scored as high[¬e]""', 'Page 13:\n[¬s]"" as 70/72 ie 97%), a more difficult test was constructed for the post-test[¬e]""']",NA,NA,NA,NA,NA,NA
39253205,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 58:\n[¬s]""Stanford Achievement Test (SAT)""\n""State Student Assessment Test (SSAT)[¬e]""']",NA,NA
37092578,Feedback,NA,NA,NA,NA,NA,"['Page 8:\n[¬s]""We constructed a comprehension test similar to the one the students would be tested with later that spring, one consisting of both open-ended as well as multiple-choice test items. For this purpose we selected retired, published com- prehension items from the Colorado Student Assessment Program (CSAP) to test comprehension performance of the students prior to and following the summary practice sessions. [¬e]""']",NA,NA,NA,NA,NA,NA
37671552,Teaching assistants,NA,NA,NA,"['Page 3:\n[¬s]""The verbal composite was based on z-scores on screening measures (CELF Preschool II UK Recalling Sentences and Expressive Vocabulary subtests""\n""and the Early Repetition Battery Word- and Nonword Repetition subtests""\n""the lowest scores on a composite measure derived from the following CELF Preschool II UK subtests (Recalling Sentences, Expressive Vocabulary,""\n""Sentence Structure, and Word Structure)[¬e]""', 'Page 4:\n[¬s]"" CELF Preschool II UK Word Structure""\n""Narrative skills were measured using a story retelling task (Squirrel Story; Carey, Leitao, & Allan, 2006; t1, t2, t4, t5, t6). Narratives were transcribed verbatim and analysed to derive three scores: mean length of utter- ance in words (MLUw), the number of words used (NW) and the number of different words used (NDW) retelling the story.""\n""Expressive Picture Naming and Receptive Picture Selection""\n""Picture Naming (t5, t6) and DeÞnitions task""\n""Alliteration Matching task""\n""Phoneme awareness: Measured using YARC Sound Isolation""\n""and Sound Linkage Segmen- tation, Blending and Deletion tasks[¬e]""']",NA,"['Page 4:\n[¬s]""Listening comprehension was assessed by children listening to two short stories and answering questions about them[¬e]""']",NA,NA,NA,NA,NA,NA
37671553,Teaching assistants,NA,NA,NA,"['Page 3:\n[¬s]""three standardized tests administered at screening and pretest (BPVS, CELF Expressive Vocabulary, CELF Sentence Structure).""\n""York Assessment of Reading for Comprehension[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37091029,Feedback,NA,NA,NA,"['Page 4:\n[¬s]""Passage Reading Test (PRT). The PRT (Fuchs, Deno, & Mirkin, 1982a), comprising three passages from a third grade book of the Ginn 720 series (1976), was employed.""\n""Stanford Diagnostic Reading Test, Two subtests, Structural Analysis (SA) and Reading Comprehension (RC), of the Stanford Diagnostic Read\xad ing Test (Karlsen, Madden, & Gardner, 1976), Green Level, Form A, were employed.""\n""Structure of Instruction Rating Scale (SIRS). The SIRS (Deno, King, Skiba, Sevcik, & Wesson, 1983) was employed[¬e]""']",NA,"['Page 4:\n[¬s]""Teacher questionnaire. A teacher questionnaire (see Fuchs, Deno, & Mirkin, 1982b) designed for the study""\n""Student interview. An interview schedule, designed for the stu[¬e]""']",NA,NA,NA,NA,NA,NA
37092579,Feedback,NA,NA,NA,NA,"The Word Spelling Test (WST) (Deno, Mirkin, Tindal & Lowry, 1980)",NA,"Teacher developed spelling tests at least twice weekly, which lasted 2 minutes using randomly selected words in a form of the standard CBM test.",NA,NA,NA,NA,NA
37092580,Feedback,NA,NA,"The Word Spelling Test-Revised (WST; Deno, Mirkin, Kuehnle, & Lowry, 1980) comprises 60 words randomly selected from Grades 1-6 of Basic ElementaryReading Vocab­ ularies (Harris & Jacobson, 1972).   Spelling Modified Accuracy of Implementation Rating Scale-Revised (S-MAIRS;Fuchs, 1988), which comprises three subscales: Structure,' Measurement, and Data Utilization.","['Page 2:\n[¬s]"" Spelling Modified Accuracy of Imple-[¬e]""', 'Page 3:\n[¬s]""mentation Rating Scale-Revised (S-MAIRS; Fuchs, 1988), which comprises three subscales: Structure,\' Measurement, and Data Utilization. Items are rated on a 5-point Likert-type scale (0 =""low""; 4 = ""high""), in accordance with detailed scoring guidelines.[¬e]""', 'Page 3:\n[¬s]""The WST was selected because it is one offew spelling achievement tests requiring a production rather than a recognition task. Criterion validity with the Test of Written Spelling, the Peabody Individual Achievement Test-Spelling, and the Stanford Achievement Test-Spelling was be\xad tween .73 and .99 (Deno et al., 1980). Test-retest reliability was .92 or higher (Fuchs, Deno, & Marston, 1983), and interscorer agreement (see Coulter formula), assessed on 28% of the proto\xad cols, was 97%. The highest possible score was 395. No ceiling effect was observed.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092581,Feedback,NA,NA,NA,"['Page 4:\n[¬s]""The accuracy with which teachers imple\xad mented treatments was assessed using the Spelling-Modified Accuracy of Implemen\xad tation Rating Scale-Revised (S-MAIRS; Fuchs, 1988), which comprises..three subscales: Structure (taking baseline, graphing data, writing goals, and drawing goal lines), Measurement (task adminis\xad tration, reliability of scoring, and\'fre\xad quency of measurement), and Evaluation (describing instructional procedures and timing instructional adjustments).""\n""Student accuracy during measurement was in\xad dexed through the Student Computer Observation, which assesses student accuracy in (a) date entry, (b) name entry, (c) test number and password entry, (d) word dictation sequence, (e) word dicta\xad tion timing, (f) response entry, and (g) test duration.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40294904,Feedback,NA,NA,"The Math Operations Test-Revised (Fuchs, Fuchs, Hamlett, & Stecker, 1991)' (p.529)",NA,NA,NA,NA,NA,NA,NA,NA,NA
37093553,Peer Tutoring,NA,NA,"Teacher planning. Instructional plan­ ning was measured in two ways. First, teachers maintained instructional plan sheets Second, we used the Teacher Planning Scale  Acquisition and transfer learning The acquisition measure was the Math Operations Test-Revised (Fuchs, Fuchs, Hamlett, & Stecker, 1991)  The transfer measure was the Mathe­ matics Concepts and Applications Test (Stecker, Fuchs, & Hamlett, 1992),","['Page 11:\n[¬s]""Measures Teacher planning. Instructional plan\xad ning was measured in two ways. First, teachers maintained instructional plan sheets (Wesson & Deno, 1989), on which they wrote descriptions of their instruc\xad tional plans each week for 3 weeks.""\n""Second, we used the Teacher Planning Scale (Fuchs, Fuchs, & Bishop, 1992a), ask\xad ing teachers to indicate, using a 5-point Lik\xad ert scale, the extent to which they agree with each of five statements (strongly dis\xad agree to strongly agree).""\n""The transfer measure was the Mathe\xad matics Concepts and Applications Test (Stecker, Fuchs, & Hamlett, 1992), which systematically samples problems across Grades 1 through 6 from the concepts/appli- cations portions of the Tennessee curricu\xad lum (i.e., numeration, concepts, geometry, measurement, charts and graphs, money, word problems)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093549,Peer Tutoring,NA,NA," Comprehensive Reading Assessment Battery (CRAB). The CRAB (L. S. Fuchs, Fuchs, & Maxwell, 1988) makes use of four 400-word traditional folktales, used in previous studies of reading comprehension (e.g., Brown & Smiley, 1977; Jenkins, Heliotis,","['Page 17:\n[¬s]""d prediction relay were 94, 88, 87, 88, and 90, respectively. Comprehensive Reading Assessment Battery (CRAB). The CRAB (L. S. Fuchs, Fuchs, & Maxwell, 1988) makes use of four 400-word traditional folktales, used in previous studies of reading comprehension (e.g., Brown & Smiley, 1977; Jenkins, Heliotis, Haynes, & Beck, 1986). The folktales were rewritten by Jenkins et al. (1986) to approximate a second- to third-grade readability level (Fry, 1968), while preserving their meaning. The CRAB requires students first to read aloud from one folktale for 3 minutes and then to answer 10 comprehension questions. On a second story, they (a) have 2 minutes to complete a cloze, or maze; (b) read aloud for 3 minutes; and (c) answer 10 comprehension questions. The comprehension questions, devel- oped by Jenkins et al. (1986), require short answers reflecting recall of information contained in idea units of high thematic importance. The maze activity was prepared by leaving the first sentence intact; thereafter, every 7th word was replaced with a 3-item multiple choice, where only one item provides a semantically correct replace[¬e]""']","Teacher questionnaires and student interviews. Between Weeks 13 and 15 of the treatment, PALS teachers independently completed a questionnaire  Instructional plan sheet","['Page 18:\n[¬s]""retreatment; 99.9%, 95.5%, and 99.0% at posttreatment. Teacher questionnaires and student interviews. Between Weeks 13 and 15 of the treatment, PALS teachers independently completed a questionnaire with two parts. The first part asks teachers to express their views of the academic and social benefits of PALS-both overall benefits and those associated with more specific components of the treatment-for LD, LP, and AA students, using a 5-point Likert-type scale. The second part asks open- ended questions, encouraging teachers to suggest how PALS may be improved.[¬e]""']",NA,NA,NA,NA,NA,NA
37093550,Peer Tutoring,NA,NA,"Achievement. We employed the Com­ prehensive Mathematics Test.  which systemati­ cally samples problems to represent the Tennessee mathematics curriculum in grades 1-6. The operations subtest includes 50 mathematical operations problems in­ volving addition, subtraction, multiplica­ tion, and division of whole numbers, deci­ mals, and fractions.","['Page 13:\n[¬s]""Achievement. We employed the Com\xad prehensive Mathematics Test""\n"" which systemati\xad cally samples problems to represent the Tennessee mathematics curriculum in grades 1-6. The operations subtest includes 50 mathematical operations problems in\xad volving addition, subtraction, multiplica\xad tion, and division of whole numbers, deci\xad mals, and fractions.[¬e]""']","Quality of student interactions. For both PMI conditions, we assessed the qual­ ity of student interactions with in situ ob­ servations, which occurred in the students' classrooms during regularly scheduled PMI sessions, and with structured tutoring gen­ eralization sessions, which occurred outside the students' classrooms and were video­ taped.  In the structured, videotaped generalization sessions, each dyad worked on two types of problems: one operations and one applica­ tions skill.","['Page 14:\n[¬s]""Quality of student interactions. For both PMI conditions, we assessed the qual\xad ity of student interactions with in situ ob\xad servations, which occurred in the students\' classrooms during regularly scheduled PMI sessions, and with structured tutoring gen\xad eralization sessions, which occurred outside the students\' classrooms and were video\xad taped.[¬e]""']",NA,NA,NA,NA,NA,NA
37093524,Peer Tutoring,NA,NA,"Comprehensive Mathematics Test (Fuchs, Fuchs, Hamlett, Phillips, & Karns, 1995)","['Page 12:\n[¬s]""CBM. These teachers employed CBM for 23 weeks to track improve- ment on the grade-level mathematics curriculum. Each week, teachers administered a classwide assessment.[¬e]""']"," PALS topics. Two RAs reviewed the master set of topics incorporated within the CBM/PALS system and developed a scheme for coding the difficulty level of those topics (1 = most easy, 5 = most difficult; more than one skill could receive the same code).  Effort : Teachers rated student effort  Intrinsic motivation: Teachers rated the student   Student feelings about the TFG treatment. A questionnaire tapped stu- dents' insights into and feelings about the TFG treatment","['Page 17:\n[¬s]""ributed evenly across administrations and treatments, was 99.1%. PALS topics. Two RAs reviewed the master set of topics incorporated within the CBM/PALS system and developed a scheme for coding the difficulty level of those topics (1 = most easy, 5 = most difficult; more than one skill could receive the same code)""\n""ch were identified for them on the basis of assessment profiles. Effort. Following methods described by Mac Iver, Stipek, and Daniels (1991), we asked teachers to rate student effort in the following way.""\n""ess to their initial ratings when they completed their final ratings. Intrinsic motivation. Following methods described by Gottfried (199[¬e]""']",NA,NA,NA,NA,NA,NA
37133902,Peer Tutoring,NA,NA," Traditional achievement measure. We employed the Comprehensive Test of Basic Skills, fourth edition (CTBS; Macmillan/ McGraw-Hill, 1989) Mathematics Total Bat­ tery, which comprises the Mathematics Computation Test and the Mathematics Concepts and Applications Test.  CBM. We employed three alternate forms of the mathematics computation and the mathematics concepts/applications CBM system (Fuchs, Fuchs, Hamlett, Thompson, Roberts, Kubek, & Stecker, 1994). Computations includes addition, subtraction, multiplication, and division of whole numbers, fractions, and decimals. Concepts and applications includes number concepts, numeration, applied computa­ tion, geometry, measurement, charts and graphs, and word problems.  PA. The PA designed for this study was adapted from Sammons, Kobett, Heiss, and Fennell (1992). It incorporated nine “core"" skills from the Tennessee statewide fourth- grade curriculum: multiplication with whole numbers and regrouping, concrete representation of decimals, additive com­ binations of decimals, multiplication with decimals and money with regrouping, rounding, drawing perimeter, drawing area with appropriate conventions, computing area, and labeling dimensions","['Page 8:\n[¬s]""Traditional achievement measure. We employed the Comprehensive Test of Basic Skills, fourth edition (CTBS; Macmillan/ McGraw-Hill, 1989) Mathematics Total Bat\xad tery, which comprises the Mathematics Computation Test and the Mathematics Concepts and Applications Test.""\n""CBM. We employed three alternate forms of the mathematics computation and the mathematics concepts/applications CBM system (Fuchs, Fuchs, Hamlett, Thompson, Roberts, Kubek, & Stecker, 1994).""\n""Computations includes addition, subtraction, multiplication, and division of whole numbers, fractions, and decimals. Concepts and applications includes number concepts, numeration, applied computa\xad tion, geometry, measurement, charts and graphs, and word problems.""\n""PA. The PA designed for this study was adapted from Sammons, Kobett, Heiss, and Fennell (1992). It incorporated nine “core"" skills from the Tennessee statewide fourth- grade curriculum: multiplication with whole numbers and regrouping, concrete representation of decimals, additive com\xad binations of decimals, multiplication with decimals and money with regrouping, rounding, drawing perimeter, drawing area with appropriate conventions, computing area, and labeling dimensions[¬e]""']",Teacher questionnaire. The question­ naire posed four questions with Likert-scale response formats and three questions with open-ended response formats.,"['Page 9:\n[¬s]""Teacher questionnaire. The question\xad naire posed four questions with Likert-scale response formats and three questions with open-ended response formats.[¬e]""']",NA,NA,NA,NA,NA,NA
37093618,Peer Tutoring,NA,NA,"Literacy Development. To assess literacy development, we used the Comprehensive Reading Assessment Battery","['Page 5:\n[¬s]""Literacy Development. To assess literacy development, we used the Comprehensive Reading Assessment Battery (CRAB; L. S. Fuchs, Fuchs, & Hamlett, 1989).[¬e]""']","Student Beliefs. We used a questionnaire to sample students beliefs along three dimensions: attitude toward read- ing, working hard to become a better reader, and working with other students.","['Page 6:\n[¬s]""Student Beliefs. We used a questionnaire to sample students\x92 beliefs along three dimensions: attitude toward read- ing, working hard to become a better reader, and working with other students.[¬e]""']",NA,NA,NA,NA,NA,NA
37093551,Peer Tutoring,NA,NA,"Learning. To assess student learning, we used the reading comprehension subtest of the third edition of the Stanford Diagnostic Reading Test (Karlsen & Gardner, 1986).  Student help. For PALS and PALS-HG conditions, we assessed the nature of the help students provided with in situ obser­ vations that occurred in classrooms during regularly scheduled PALS and PALS-HG sessions.","['Page 11:\n[¬s]""Learning. To assess student learning, we used the reading comprehension subtest of the third edition of the Stanford Diagnostic Reading Test ""\n""Student help. For PALS and PALS-HG conditions, we assessed the nature of the help students provided with in situ obser\xad vations that occurred in classrooms during regularly scheduled PALS and PALS-HG sessions.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093523,Peer Tutoring,NA,NA,Children were tested on the mathematics portion of the SESAT standardised maths test (primary outcome). Children were also posttested on the mathematics portion of the Primary level 1 of the Stanford Achievement Test. ,"['Page 8:\n[¬s]"" Children were pre- and posttested in groups on the mathemat-[¬e]""', 'Page 9:\n[¬s]""ics portion of the SESAT (Madden, Gardner, & Collins, 1987), a standardized test of mathematics readiness. This instrument uses 40 items to assess number identifica\xad tion, number concepts, number relations, mathematical vocabulary, and adding and subtracting concepts. The SESAT is de\xad signed to span mathematical knowledge and skills expected from the beginning to the end of kindergarten.""\n""Children were also posttested in groups on the mathematics portion of the Primary 1 level of the Stanford Achievement Test (Gardner, Rudman, Karlsen, & Merwin, 1987).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37116212,Peer Tutoring,NA,NA,NA,"['Page 7:\n[¬s]"" mathematics portion of the Primary 1 level and the Primary 2 level of the Stanford Achievement Test (Gardner, Rudman, Karlsen, & Merwin, 1987).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117132,NA,NA,NA,NA,"['Page 7:\n[¬s]"" the Comprehensive Test of Basic Skills (CTBS) at Lark, the Stanford Achieve\xad ment Test (SAT) at Brady, and the 3R\'s Test at Palm Avenue[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37133906,Peer Tutoring,NA,NA,"1. California Reading Test - to ascertain reading achievement  2. Index of Adjustment Values (Bills, 1951) self-concept measure 3. Iowa Tests of Basic Skills - reading scores section used to determine the ""low achievers"" in the participating grade classes",NA,"1. Attitude Test: Eight-scale demantic differential test was developed by the investigator to measures changes in attitudes towards the school pre-test and post-test.   2. Cultural Disadvantage Test: While not explicitly stated as a researcher-developed test, it is noted that ""cultural disadvantage"" was determined using multiple student indicators, such as housing adequacy, parental education, and other related measures. (NoteL There are questions around this indicator regarding its reliability, especially considering the subjectivity of the main researcher as school principal but also the situatedness of this knowledge in local region.) ",NA,1. Teacher evaluation forms were used to measure behavioural changes in students before and after the test,NA,NA,NA,NA,NA
37093555,Peer Tutoring,NA,NA,The California Reading Test Upper Primary Forms W and Xwere used to measure the reading achievement of the third and fourth grade subjects   Bills' Elementary School Index of Adjustment and Values (ESIAV) was used to measure the self-concept  The teacher evaluation form was used to measure behavior of the subjects in the project,"['Page 4:\n[¬s]""The California Reading Test Upper Primary Forms W and Xwere used to measure the reading achievement of the third and fourth grade subjects. The test has two major sections, reading vocabulary and reading comprehension. The test yietds agrade placement score and an anticipated achievement grade placement score for each of the two major sections and the total reading profile. (9) Bills\' Elementary School Index of Adjustment and Values (ESIAV) was used to measure the self-concepts of subjects in grades three and four. The examiner reads the instructions while the subjects mark their ratings by circling the appropriate alternatives on athree-point scale. The form consists of nineteen questions related to traits describing human behavi""\n""The teacher evaluation form was used to measure behavior of the sub- jects in the project. The instrument is comprised of 15 scales arranged on abipolar conti[¬e]""']",A semantic differential was developed by the researcher and used to assess the third and fourth grade subjects' attitudes toward school   Ashort informal questionnaire was developed by the researcher to gather parent reactions to the total tutorial project,"['Page 4:\n[¬s]""Asemantic differential was developed by the researcher and used to assess the third and fourth grade subjects\' attitudes toward school. The assessment instrument contains eight bipolar scales with adjectives of opposite meanings placed at each end of the scale. The subjects react to each scale separately on a1--7 point c[¬e]""', 'Page 5:\n[¬s]""Ashort informal questionnaire was developed by the researcher to gather parent reactions to the total tutoria[¬e]""']",NA,NA,NA,NA,NA,NA
40117276,Extending school time,NA,NA,California Achievement Test (CAT): Reading and Language,NA,NA,NA,NA,NA,English Language Arts pre-test (New York State Board oF Regents) used for identifying students scoring at Level 1 and 2 who are considered at risk of failing Regents Examinations.   Post test: 8th grade NYS ELA Assessment,NA,NA,NA
37061127,Feedback,NA,NA,NA,NA,NA,"['Page 49:\n[¬s]""The criterion post test was developed following the principles of (c.R.T) (Criterion Referenced Testing!.. construction as outlined in W. J. Popham; Criterion Reference Measurement, 1978. The test was validated before it was put into use.[¬e]""']",NA,NA,NA,NA,NA,NA
37671623,Teaching assistants,NA,NA,"1. Letter-Word Identification subtest (from Woodcock-Johnson Psychoeducational Battery - Revised)   2. Test of Phonemic Awareness (Torgeson & Bryant, 1994)   3. Word Attach subtest (from Woodcock-Johnson Psychoeducational Battery - Revised)","['Page 88:\n[¬s]"" 1) W J-R Letter-Word Identification Subtest (Woodcock & Johnson, 1989), 2) Test o f Phonemic Awareness (TOPA) (Torgeson & Bryant, 1994), and 3) W oodcock- Johnson Psychoeducational-Revised (WJ-R) Word A ttack Subtest (Woodcock & Johnson, 1989).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093477,Peer Tutoring,NA,NA,The Stanford Diagnostic Mathematics Test (SDMT) was used to measure mathematics concepts and computation   Self-perception profile for children designed to measure children's perceptions,"['Page 5:\n[¬s]""Stanford Diagnostic Mathematics Test, Third Edition (SDMT). The SDMT (Beatty, Madden, Gardner, & Karlsen, 1986) is a standardized measure ofachievement for basic mathematics concepts and computation. [¬e]""']",The peer tutoring interaction coding system was developed by the authors and was used to record student behaviour during peer tutoring.,"['Page 4:\n[¬s]"" Student behavior recorded during the peer tutoring Generalization Probe was coded using an interval recording system developed by the authors[¬e]""']",The curriculum-based computation test was designed specifically for 4th and 5th grade students in collaboration with teachers from participating elementary schools. ,"['Page 5:\n[¬s]""Curriculum-Based Computation Test. This curriculum-based measure of chil- dren\'s performance on mathematical computation items was designed specifically for fourth- and fifth-grade students in collaboration with teachers from the partici- pating elementary school[¬e]""', 'Page 6:\n[¬s]""Self-Perception Profilefor Children (Harter, 1985)[¬e]""']",NA,NA,NA,NA
37093478,Peer Tutoring,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]""The curriculum-based computation test (CBCT), a measure of children\'s performance on mathematical computation items, was designed specifically for the third and fourth graders in this study through collaboration with their teachers and the school mathemat- ics specialist (Tucker, 1985). Two tests were constructed to assess the skill level of students in the third and fourth grades. The tests each consisted of 50 mathematics computation problems that were taken from the Grade 3 and Grade 4 teacher\'s editions of The Mathematics Experience (1992). This series was the current curriculum used in the school and was described by its authors as being based on the NCTM standards (1989). Fifty computation problems were randomly selected from each textbook to assess addition, subtraction, multiplication, and division skills. Students were instructed to complete as many problems as they could in a 20-min period. Test scores were based on the number of correct computations. Each individual computation on the test was scored. The number of computations involved in each of the 50 problems ranged from 1 to 5 per problem for the third-grade test and from 1 to 11 for the fourth-grade test. The total number of computations for the third- and fourth-grade tests were 97 and 193, respectively.""\n""The curriculum-based word problem test (CBWPT), a measure of children\'s performance on word problems, was designed and administered in a comparable manner to the CBCT, described previously. Again, two tests were constructed to assess the skill level of the third and fourth graders. The tests each consisted of 10 mathematics computation word problems, randomly selected from each textbook to assess addition, subtraction, multiplication, and division skills in the context of word problems. During a 15-min period, the test questions were read aloud to students at 1.5-min intervals to reduce the impact of students\' language skills on their performance. After all items were read, students were given the remaining 5 min to complete their tests. Test scores were based on the number of correct computations solved for each item. For example, on the Grade 3 test, the following 3-point question required three computations: ""Akeem played 2 games of bowling. His scores were 125 and 109. What was his total score for the 2 games?"" The number of computations involved in each of the 10 problems ranged from 1 to 5 per problem for the third-grade test and 1 to 6 for the fourth-grade test. The total number of computations for the third- and fourth-grade tests was 16 and 34, respectively.[¬e]""']",NA,NA,NA,NA,NA,NA
37092650,Feedback,NA,NA,NA,"['Page 6:\n[¬s]""The Tukey HSD procedure was used to follow-up this result (alpha = .05). The results of the Tukey comparisons revealed that the students in the[¬e]""']",NA,"['Page 5:\n[¬s]""A pool of 60 knowledge level multiple choice items was constructed by the experimenter. These items were then rated by two judges on the basis of the Bloom et al. (1956) taxonomy in order to further verify the level of learning they required.[¬e]""']",NA,NA,NA,NA,NA,NA
37133911,Peer Tutoring,NA,NA,Computational skill achievement was measured through the Standford Achievement Test--Mathematics.,NA,Researcher developed pre-test and post-test quasi-experiment design.   Computational skills achievement was also measured using a microcomputer-genereated Maths Facts Sheet (as well as the standardised Stanford Mathematics test).  ,NA,NA,NA,NA,NA,NA,NA
37671603,Teaching assistants,NA,NA,NA,"['Page 14:\n[¬s]""Wilcoxon Matched-Pairs Signed-Ranks test[¬e]""', 'Page 9:\n[¬s]""Early Word Recognition test and the BAS II Word Reading""\n""letter-sound knowledge, Early Word Recognition, BAS II word reading, and Nonword Reading[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38296617,Teaching assistants,NA,NA,These were the primary outcome measures.,"['Page 12:\n[¬s]""GL New Group Reading Test A""\n""GL New Group Reading Test B.[¬e]""']",NA,NA,NA,NA,NA,"['Page 12:\n[¬s]""In addition, the prior KS2 assessment results in literacy can be used as a secondary pre-test score.[¬e]""']",NA,NA
38296615,Feedback,NA,NA,NA,"['Page 10:\n[¬s]""The New Group Reading Test (NGRT) is the third edition of Group Reading Test (GRT) developed by GL Assessment and the National Foundation for Education Research. [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38296616,Feedback,NA,NA,NA,"['Page 5:\n[¬s]""pre-test (GL Assessment’s New Group Reading Test A) and a post-test (New[¬e]""', 'Page 6:\n[¬s]""Group Reading Test B).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117250,Extending school time,NA,NA,NA,"['Page 15:\n[¬s]""outh Experiences Survey 2.0 (YES). Students completed the YES (D. M. Hansen & Larson, 2005) [¬e]""']",NA,"['Page 14:\n[¬s]""Youth Surveys. Participating youths completed pretest and posttest youth sur- veys measuring primarily the outcomes targeted by the ASP.[¬e]""', 'Page 15:\n[¬s]""Teacher Ratings. During the spring of 2007, science, math, social studies, and English teachers were asked to rate 427 study participant""\n""These surveys measured student classroom behavior, social adjustment, and academic competence.[¬e]""']","Not enough detail about original source of this info, but research team got it from school","['Page 15:\n[¬s]""School Records. School records were collected to measure student academic performance, attendance, and school suspensions for the year prior to the implementation of the program (2005\x962006) as well as the year the program was implemented (2006\x962007). [¬e]""']",NA,NA,NA,NA
38878252,Small Group Tuition,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
37093559,Peer Tutoring,NA,NA,"Revised Neale Analysis of Reading Ability (Neale, 1988).","['Page 6:\n[¬s]""Those who obtained stanines of 4 or less on this test were followed up on the revised Neale Analysis of Reading Ability (Neale, 1988), an individually administered test of prose reading ability.[¬e]""', 'Page 7:\n[¬s]""revised Neale Analysis of Reading Ability (Neale, 1988).[¬e]""']",NA,NA,NA,NA,"Primary Reading Survey Test (Australian Council for Educational Research, 1984), a group test of reading comprehension which is widely used in Australian schools","['Page 6:\n[¬s]""In order to identify the low progress readers, all students in grades 4 and 6 were given the appropriate level of the Primary Reading Survey Test (Australian Council for Educational Research, 1984), a group test of reading comprehension which is widely used in Australian schools.[¬e]""']",NA,NA
37671634,Teaching assistants,NA,NA,NA,"['Page 4:\n[¬s]""Progressive Achievement Tests (PAT; Aus- tralian Council for Educational Re- search, 2001) for mathematics and comprehension, as well as a bank of reading or mathematics tasks from the Cognitive Aptitude Assessment System (CAAS) computer assessment package (Royer, 1996; Royer & Tronsky, 1998).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671557,Teaching assistants,NA,NA,NA,"['Page 74:\n[¬s]""The study used the DIBELS (Good & Kaminski, 2003) kindergarten instrument[¬e]""', 'Page 75:\n[¬s]""66 which consists of four subtests.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671558,One to one tuition,NA,NA,NA,"['Page 6:\n[¬s]""the Word Recognition and Phonics Skills test (WraPS). This whole group test was selected on the basis that: it can be administered by the class teachers during lesson time Ð thus minimizing disruption; it provides a standardized score and word recognition age for each child.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093560,Peer Tutoring,NA,NA,NA,"['Page 3:\n[¬s]""Otis-Lennon School Abilities Test-Primary I, Form R[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37133917,Peer Tutoring,NA,NA,Stanford Diagnostic Reading Test ,NA,Researcher developed a pre-test and post-test to measure the outcomes of the study. ,NA,NA,NA,A standardised national literacy test was used to identify students performing below ninth-grade level reading. ,NA,NA,NA
40117251,Extending school time,NA,NA,Science grade average (see Table 3) compared pre and post intervention. ,NA,NA,NA,NA,NA,NA,NA,NA,NA
37092582,Parental engagement,NA,NA,NA,NA,NA,"['Page 299:\n[¬s]""The scoring rubric was developed by the Reading Department of St. John’s University and was consistent with the new English Language Arts Standards.[¬e]""']",NA,NA,NA,NA,NA,NA
37133918,Peer Tutoring,NA,NA,"Gates-MacGinitie Reading Tests (GMRT) 4th Edition. Please note: Students did not receive the same sub-tests within the GMRT. Some lower performing students and those with perceived disabilities were given different sub-tests than their classmates.   STAR Reading Assessment - computer-based assessment  The Reading Strategies Usage Survey (RSU) - to measure metacognitive and cognitive strategy knowledge   Think Along Passages (TAP) - assess metastrategic knowledge and strategy use, including prediction, inferencing and determining word meanings.   Words Per Minute (WPM) and Maze   The Elementary Reading Attitude Survey (ERAS) ",NA,NA,NA,NA,NA,NA,NA,NA,NA
37671515,Teaching assistants,NA,NA,NA,"['Page 57:\n[¬s]"" L2 oral reading fluency from Dynamic Indicators of Basic Early Literacy Skills, DIBELS, (Kaminski & Good, 1996), and a measures of L2 broad reading from the Woodcock Language Proficiency Battery-Revised ,WLPB-R, (Woodcock, 1991).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38878253,Small Group Tuition,NA,NA,NA,"['Page 6:\n[¬s]""e 25-item Aggression scale of the Teacher Rat- ing Form (TRF) of the Child Behavior Checklist (CBCL; Achenbach, 1991).""\n"" We used four subtests of the Woodcock- Johnson Revised Tests of Achievement (WJ-R; Woodcock & Mather, 1989)[¬e]""']",NA,"['Page 8:\n[¬s]""The conversations, which focused on familiar topics, such as the childÕs everyday activities and interests, helped the assessors to confirm the teachersÕ information and to determine the childÕs proficiency with Spanish and English.""\n"" The information was recorded on the childÕs baseline reading test profile and entered into the data- base.[¬e]""']",NA,NA,NA,NA,NA,NA
37671559,Teaching assistants,NA,NA,NA,"['Page 5:\n[¬s]""iThe British Abilities Scale \x96 II (BAS-II). The BAS-II was used to assess single word reading in an untimed context.""\n""iiTest of Word Recognition Ef ﬁ ciency (TOWRE-2). The TOWRE-2 timed word and non-word reading tests were used to assess ﬂ uency of single word recognition and pho- nic decoding""\n""iiiLUCID Rapid. LUCID Rapid tests phonic knowledge, phonological awareness and auditory working memory. These skills have been demonstrated to be important in the process of reading acquisition.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117134,Teaching assistants,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 9:\n[¬s]""North Carolina End-of-Grade (EOG) tests.[¬e]""']",NA,NA
37671520,Teaching assistants,NA,NA,NA,"['Page 3:\n[¬s]""The Clinical Evaluation of Language Fundamentals\x97 Preschool 2 UK (CELF-Preschool 2 UK ; Wiig et al. 2006) Sentence Structure subtest measured receptive grammar. During this task children point to pictures out of four possible choices representing spoken sentences.""\n""The CELF-Preschool 2 UK (Wiig et al. 2006) Expressive Vocabulary subtest measured referential naming skills. Children either named objects in pictures or described what was happening in the picture.""\n""The Action Picture Test (APT 4th edn; Renfrew 2003) assessed the informational content and grammatical us- age in children\x92s spoken language. The assessor showed the child 10 small coloured picture cards and asked what was happening in each picture. The child\x92s response was transcribed online and digitally recorded.""\n""Children listened to two passages through headphones, adapted from the York Assessment of Reading Com- prehension (YARC; Snowling et al. 2009). After each[¬e]""', 'Page 4:\n[¬s]""passage, they answered eight literal and inferential questions.""\n""The YARC Core Letter Knowledge subtest (Snowling et al. 2009) comprises 11 single letters and six digraphs. Children were shown each letter and were asked to pro- duce the sound.""\n""To assess phoneme (onset) awareness, children were pre- sented with a target word depicted pictorially and asked to identify which picture (out of two possibilities) started with the same sound (after Carroll and Snowling 2004). There were two practice items and 10 test items.""\n""The YARC Early Word Reading subtest (Snowling et al. 2009) requires children to read 30 high-frequency words.[¬e]""']",NA,"['Page 4:\n[¬s]""This test was created to assess children\x92s knowledge of the words directly taught in the nursery intervention programme. Children were shown a picture and asked to name the object or describe what was happening. All 45 taught words were included as test items.[¬e]""', 'Page 5:\n[¬s]""children were asked to give a verbal description of each. A set of scoring guidelines (four points per item) was designed taking account of preschool children\x92s level of ability.[¬e]""']",NA,NA,NA,NA,NA,NA
37092655,Feedback,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]""Three 18-item tests were developed to reflect the science, arithmetic, and social studies data interpretation content of upper elementary level standardized tests. Each test consisted of interpretive exercises based on picture and numeric tables, bar graphs, and line graphs. Designed to be similar in content balance, length, and difficulty, one test was written in multiple-choice format while the other two were cast in completion format.[¬e]""']",NA,NA,NA,NA,NA,NA
37133919,Peer Tutoring,NA,NA,NA,NA,NA,NA,Students grades were assessed in pre-test stage using school-based grading from classroom tests (i.e. school records). ,NA,NA,NA,Mathematical Disposition Survey (MSD) and Graduation Test (post-test),NA
37116213,Peer Tutoring,NA,NA,NA,NA,NA,NA,NA,"['Page 75:\n[¬s]""The interim assessment or benchmarking test is a summative pre and post- test aligned to the End of Course Test content weights.""\n""aligned to the school system’s Academic Knowledge and Skills and instructional calendars""\n""erve as a tool to assist in finding gaps in students’ conceptual knowledge as related to the End of Course Test, Gateway and Georgia High School Graduation Test""\n"" analyze classroom data, and use it for instructional planning in order to maximize teaching and learning.""\n""developed by the school system’s office of student accountability in collaboration with core curriculum directors to ensure alignment, validity, and reliability of the assessed standards to the school system’s instructional calendars.""\n""post-test will consist of 100 multiple choice questions, and will be graded departmentally on a scale of 0-100. The formative pre and post assessments are developed collaboratively among content area teachers and content literacy coaches within the school system.[¬e]""', 'Page 76:\n[¬s]"" The grades will be delineated utilizing the school system’s grading scale listed prior. The raw score on the interim assessment post-test will be used by the researcher in data analysis.[¬e]""']",NA,NA,NA,NA
37091033,Feedback,NA,NA,NA,"['Page 1:\n[¬s]"" Wide Range Achievement Test [WRAT] )[¬e]""', 'Page 2:\n[¬s]"" Suppes Math Pro gram (Suppes & Suppes, Note 4)[¬e]""', 'Page 3:\n[¬s]""WRAT""\n""Gilmore Oral Reading Test[¬e]""']",NA,"['Page 2:\n[¬s]""The reading program was built around the Distar (Osborne, Engelmann, Camie, Bruner, & Engelmann, Note 3) and Sullivan Programmed Reading Series (Buchanan, Note 2).[¬e]""', 'Page 3:\n[¬s]"" Basic Math Facts Program[¬e]""']",NA,NA,NA,NA,NA,NA
39253318,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 2:\n[¬s]""End-of-grade test scores from 5 th grade (pre-test) and 8 th grade (post-test)""\n""Grade Point Average (GPA)""\n""End-of-course test scores from five core courses required for graduation[¬e]""']",NA,NA
40117135,Feedback,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 8:\n[¬s]""T.A.A.S. (Texas A ssessm ent o f A cademic Skills)[¬e]""']",NA,NA
37671562,Teaching assistants,NA,NA,NA,"['Page 3:\n[¬s]"" Phoneme aware- ness was measured using the Phoneme completion subtest from the Phonological Abilities Test (Muter, Hulme, & Snowling, 1997). In this test a child is shown a picture of a one-syllable word and told, for example, ÔHere is a gate. IÕll say the Þrst part and you say the second part. Gay-.Õ Children are expected to produce the Þnal phoneme,/t/.""\n""ChildrenÕs ability to manipulate phonemes was measured using three subscales from the Sound Linkage Test of Phono- logical Awareness (Hatcher, 2000). The subscales require children to blend phonemes to form words and to segment and delete phonemes from words. Each subtest consists of six items preceded by two practice items. Testing is discontinued after eight consecutive errors.[¬e]""', 'Page 4:\n[¬s]""Progress in reading was assessed by two tests of single word reading ability; the Early Word Recognition Test (Hatcher et al., 1994) and The British Ability Scales (BAS II) Word Reading Test (Elliott, Smith, & McCulloch, 1997).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117175,NA,NA,NA,NA,"['Page 18:\n[¬s]""The Observatio n Survey by M. Clay (1993)[¬e]""', 'Page 8:\n[¬s]""owa Test of Basic Skills""\n""Cognitive Ability Test.[¬e]""']",NA,"['Page 50:\n[¬s]""Parent Survey[¬e]""']",NA,NA,NA,NA,NA,NA
39253285,Summer schools,NA,NA,NA,"['Page 6:\n[¬s]""Terra Nova Complete Test Battery (CTB[¬e]""']",NA,NA,NA,NA,NA,"['Page 6:\n[¬s]"" Missouri Assessment Program[¬e]""']",NA,NA
40117136,NA,NA,NA,NA,NA,NA,NA,NA,NA,Iowa Test of Basic Skills (ITBS): Total Reading and Total Math scores,NA,NA,NA
37093480,Peer Tutoring,NA,NA,NA,"['Page 56:\n[¬s]""Stanford Diagnostic Mathematics Test. 3rd Edition (Beatty, Madden, Gardner, & Karlsen, 1984)[¬e]""']",NA,"['Page 55:\n[¬s]""Curriculum-based Computation Test.""\n""The diagnostic test was comprised of 45 computation problems taken from the Enright Diagnostic Inventory of Basic Arithmetic Skills (Enright, 1983)[¬e]""']",NA,NA,NA,NA,NA,NA
37133921,Peer Tutoring,NA,NA,Standardized Test for Assessment of Reading (S.T.A.R.) was used to measure prior achievement for all students.  ,"['Page 51:\n[¬s]""S.T .A .R . is a stu dent-adaptive, norm -referenced, com puterized re a d in g test. T he test provides stu d en ts w ith a series o f item s fo r w hich they choose the b e st w ord to com plete a sentence. T h e prog ram weighs each a n sw e r and determ ines the a ppropriate difficulty o f the next q u e stio n . T he test typically takes less than 10 m inutes to com plete. S.T.A .R. tests have b een norm ed w ith a referen ce g roup o f more than 4 0 ,0 0 0 stu dents.""\n""Due to the sig n ific a n t am ount o f unavailable M A T 7 data, p retest CBM scores w ere substituted as the p rio r a chiev em en t m easure for all students.[¬e]""']",Reading: Curriculum-based measurement (CBM) was used for all students.  ,"['Page 51:\n[¬s]""C urricu lu m -b ased m easurem ent (C B M ) w as a lso used to assess readin g achievem ent. C B M p rocedures m easure oral re a d in g fluency. T he m edian n u m b er o f words read c o rre ctly in three one-m inute sam ples w as record ed as the s tu d e n t’s score (Deno, M irkin, & C hian g, 1982; M arston & M ag n u sso n , 1988).[¬e]""']","Third grade students reading skill and their attitudes to reading were measured with teacher assigned scales, along with other measures.","['Page 51:\n[¬s]""T e a ch e r percep tio n s o f third-grade stu d e n ts ’ read ing achiev em ent w ere assessed using a five-point ratin g scale (1 = poor. 5 = e x c e lle n t).[¬e]""', 'Page 52:\n[¬s]""T e a c h e r perceptions o f th ird -g ra d e students’ attitu des to w a rd reading and school w ere a sse sse d using a fiv e -p o in t ra tin g scale (1 = p o o r. 5 = e x c e lle n t).[¬e]""']",NA,NA,NA,NA
39253320,Summer schools,NA,NA,"Comprehensive Tests of Basic Skills (CTBS, McGraw-Hill 1980) change scores in both reading and math were obtained by comparing the 1980 CTBS obtained grade equivalents (OGE) to the 1981 OGE for each summer school student and for a comparable child who did not attend summer school.","['Page 59:\n[¬s]""Comprehensive Tests of Basic Skills[¬e]""']",NA,NA,"Math and Reading Report Card Grades 1980 and 1981     During the summer school: To place each child in the proper level in reading and math, a teacher-made test was administered by each teacher. The test was used solely as a tool by the teacher for planning the material to be covered in each class and was not repeated at the end of summer school to show student gain.","['Page 63:\n[¬s]""Math and Reading Report Card Grades,[¬e]""']",NA,NA,NA,NA
40117252,Extending school time,NA,NA,Academic ability: Maths and reading from the two most recent test scores from data records (7th and 8th grade scores),"['Page 37:\n[¬s]""From archival data, we obtained the two most recent standardized achievement test scores (for most youth, their 7 th and 8 th grade scores)[¬e]""']",7-item survey to assess apprenticeships/extracurricular activities,NA,NA,NA,NA,NA,NA,NA
40117253,Extending school time,NA,NA,NA,"['Page 4:\n[¬s]"" Georgia Criterion Referenced Competency Test (CRCT) [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40398941,Teaching assistants,NA,NA,NA,"['Page 5:\n[¬s]""Progress Test in Maths by GL Assessment[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092584,Feedback,NA,NA,NA,NA,NA,"['Page 64:\n[¬s]""Participants at both School A and School B were administered a pre-test using the same writing prompt with the My Access! program. This test was administered at both schools on the same day in late September of 2010. Both the pre-test essay data and the post-test essay data were scored using the same 1-6 rubric.[¬e]""']",NA,NA,NA,"['Page 10:\n[¬s]""Tennessee Comprehensive Assessment Program (TCAP) writing achievement scores from the 2010 administration were utilized for this study.[¬e]""']",NA,NA
37671521,Teaching assistants,NA,NA,NA,"['Page 10:\n[¬s]"" Basic Number Screening Test (Gillham & Hesse, 2001) immediately before the intervention and immediately after the intervention had been completed, from which mathematics ages were calculated[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253321,Summer schools,NA,NA,"Vocabulary, Comprehension and Total reading scores of the Gates MacGinitie Reading Test (MacGinitie et al., 1978).","['Page 58:\n[¬s]"" V o c a b u la ry , C om preh en sion and T o ta l[¬e]""', 'Page 59:\n[¬s]""r e a d in g s c o re o f th e G a te s M a c G in itie R ead in g T e s ts , P rim a ry A, Form 2 (M a c G in itie e t a l . , 1 9 7 8 ).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092768,Feedback,NA,NA,NA,"['Page 5:\n[¬s]""(vii) Progressive Achievement Tests\x97Reading Vocabulary and Reading Comprehension (EUey & Reid, 1969)-a standardized reading test providing vocabulary and comprehension scores used throughout New Zealand schools. (Ill)[¬e]""']",NA,"['Page 5:\n[¬s]""(i) Pretest of achievement\x97a 30 item five-choice multiple-choice test""\n""(iv) Academic Promise Tests: Abstract Reasoning Sub-test""\n""(v) Vocabulary (Keeling, in press)\x97a 50 item five-choice multiple-choice test of vocabulary. (I and II)""\n""(vi) Verbal Aptitude Test (Keeling, in press)-a 50 item five-choice multiple-choice test giving vocabulary and verbal analogies scores.""\n""(viii) Question expectation\x97similar to the posttest questioning scale described above. The pupils indicated the frequency with which they were normally questioned in class. (I^ and II)""\n""(ix) Desired question frequency\x97[¬e]""']",NA,NA,NA,NA,NA,NA
37671626,Teaching assistants,NA,NA,NA,"['Page 58:\n[¬s]""This study included 6 dependent measures. The DIBELS Initial Sound Fluency, Phonemic Segmentation Fluency, Letter Naming Fluency, and Nonsense Word Fluency measures were administered 7 times during the study. The Phonological Awareness and the Print Knowledge subtests of the TOPEL were administered at pre- intervention and post-intervention.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671605,Teaching assistants,NA,"['Page 8:\n[¬s]""DIBELS[¬e]""']",NA,"['Page 7:\n[¬s]"" K-BIT = Kaufman Brief Intelligence Test; CELF-P2 = Clinical Evaluation of Language Fundamentals – Preschool, 2nd Ed.; TOPEL = Test of Early Preschool Literacy; DIBELS = Dynamic Indicators of Basic Early Literacy Skills. [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37061117,NA,NA,NA,NA,NA,1. 46-item Objective summative test on History Unit material 2. Four formative tests throughout the year ,NA,NA,NA,NA,NA,NA,NA
37133923,Peer Tutoring,NA,NA,NA,NA,Measure 3 was coding discussions by tutees during independent in-class math seatwork using Task-Directive Speech guidelines by Meichenbaum and Biemiller (1992) and Biemiller et al. (1993; 1998).,"['Page 79:\n[¬s]""Task-Directive Speech: In-class observations o f Task-Directive Speech were gathered. ""\n""Task-Directive Speech was coded for two features: (1) Task-Directive Speech to Self —spontaneous statements uttered by a target child related to the child\'s own math work; and (2) Task-Directive Speech to Others —statements made in response to another\'s request for help, or spontaneous statements made about another\'s math work. Task-Directive Speech indicates that a child can and will verbalize goals and plans, and can verbally monitor and regulate task progress for herself and others.[¬e]""']",NA,NA,The Canadian Test of Basic Skills (CTBS) was modified and used for Measure 1 (Problem Solving / Word Problems) and Measure 2 (Computational Subtests). ,"['Page 102:\n[¬s]""The same modified version o f the 1982 Canadian Test o f Basic Skills (CTBS) used in Year One was used to assess computation and problem-solving skills pre-, and post\xad program for Year Two.[¬e]""', 'Page 78:\n[¬s]""Mathematics Computation and Problem-solving: The first two measures were modified versions o f the 1982 CTBS math problem-solving (word problems) and computational subtests (Appendix B).""\n""The modified tests eliminated the multiple-choice format and time limits o f the original. The test was administered to small groups o f two to six students at a time. Research assistants, blind to children\'s group assignment, were allowed to read word problem test items to children (no re-wording allowed).[¬e]""']",NA,NA
37116224,Peer Tutoring,NA,NA,NA,"['Page 50:\n[¬s]""STAR Progress Monitoring (STAR PM) Tool. The Renaissance learning (2016) website states that the STAR PM reading assessment measures reading skills for students through grade 12. STAR PM testing targets: a) word knowledge, b) fluency, c) comprehension strategies, d) analyzation of literary texts, e) understanding author’s craft, and f) analyzing[¬e]""', 'Page 51:\n[¬s]"" argument and evaluation text. The estimated fluency is only available for students through the Grade 4.""\n""STAR PM is a computer-adaptive test. Thus, the computer program continually adjusts the difficulty based on the response of the previous response.""\n""Testing takes approximately fifteen minutes to complete. Scores for the test are reported as scaled scores between zero and 1400. Reports can compare student’s scores to specific criteria or to a standard score.""\n""Gray Oral Reading Test, Fifth Edition. A subset of participants were given a baseline Gray Oral Reading Test-5 (GORT-5) before the intervention began, as well as after treatment as a post-intervention assessment.""\n"" used in the study as a criteria measure to establish concurrent validity of the STAR PM. [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253390,Summer schools,NA,NA,Iowa Test of Basic Skills (ITBS),"['Page 7:\n[¬s]"" For example, third graders must obtain a minimum score of 2.8 grade equivalents in both reading and math achievement on the Iowa Test of Basic Skills (ITBS) in order to advance. 5 In 1997, the promotion standards for third, sixth and eighth grade were 2.8, 5.3, and 7.0 respectively, which roughly corresponded to the 20 th percentile in the national achievement distribution.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37061115,Feedback,NA,NA,NA,NA,Junior High School students were assessed for Mathematics and High School students (from High School A) were assessed for Science. ,"['Page 4:\n[¬s]""For each program there was a pretest and posttest. The Solving Equations pretest consisted of 22 items, one for each of the ""learning sets"" or sub\xad tasks in the program. A description of these sub-tasks is presented by Gagne and Paradise (l96l), from whose Appendix A the pretest items were taken.[¬e]""', 'Page 5:\n[¬s]""The 22-item posttest contained four items identical to those in the pretest, and 18 items intended to cover the same sub-tasks as the corresponding items in the pretest, but with some changes in the terms used or in format.""\n""The Gas Laws pretest consisted of three completion items, while the posttest consisted of 36 multiple-choice items and four completion items.[¬e]""']",NA,NA,NA,NA,NA,NA
37093509,Peer Tutoring,NA,NA, Stanford Diagnostic Reading Test (SDRT)   Metacomprehension Strategy Index,"['Page 6:\n[¬s]""Second, we used the data on reading compre- hension provided by the schoolwide assessment system, the Stanford Diagnostic Reading Test (SDRT), a standardized grade-level reading com- prehension test consisting of 40 multiple-choice items. All students in the school participated in this assessment at the beginning and end of the school year. Thus, we were able to compare the tutor\'s scores on the SDRT to scores from students at com""\n""Third, we used the Metacomprehension Strategy Index (Schmitt, 1990) to clarify what the seventh- grade struggling readers knew about the applica- tion of specific reading strategies, encompassing the before, during, and after reading experie[¬e]""']", Tutor log   semistructured interviews with students at the end of the 8-month tutoring projec,"['Page 6:\n[¬s]""Finally, we conducted semistructured interviews with students at the end of the 8-month tutoring projec[¬e]""']",NA,NA,NA,NA,NA,NA
37671565,Teaching assistants,NA,NA,"Socioeconmic Status (SEV The familys SES was classified accordingto Hollingsheads Four Factor Index of Social Status (Hollingshead, 1975).  Stressors,  Sandler and Blocks (1 979) scale was administered as part of the Parent Questionnaire and used as a measure of life stress.  Sociomeirics. A short, 9-item form of the Pupil evaluation Inventory (Pekarik, Prinz, Leibert, Weintraub, & Neale, 1976) was used to assess the sociometric status of the children.  A second sociometricused was the Roster-Rater (Oden & Asher, 1977). The Roster- Rater method is a peer rating that consists of a five-point Likert scale.","['Page 5:\n[¬s]""Socioeconmic Status (SEV The family\x92s SES was classified accordingto Hollingshead\x92s Four Factor Index of Social Status (Hollingshead, 1975). Lower income families included those with scores within the lower 33% of this range. SES was used as part of the criteria to determine risk status. Stressors, Sandler and Block\x92s (1 979) scale was administered as part of the Parent Questionnaire and used as a measure of life stress. The measure is comprised of several items of stressful childhood events. For each of the items, the parents indicated whether their child had experienced the event within the last 12 months. The scale has been found to be related both to teacher and parent ratings of child adjustment problems.[¬e]""', 'Page 6:\n[¬s]""Sociomeirics. A short, 9-item form of the Pupil evaluation Inventory (Pekarik, Prinz, Leibert, Weintraub, & Neale, 1976) was used to assess the sociometric status of the chil- dren. Testing was completed at the end of the first year after the school transition and a t the follow-up point for both Cohort One and Cohort Two. The measure assesses three domains of social competence: aggression, likability, and withdrawal. This short form has been validated elsewhere (Lardon & Jason, 1992). A second sociometricused was the Roster-Rater (Oden & Asher, 1977). The Roster- Rater method is a peer rating that consists of a five-point Likert scale. The score for each child consists of the average rating they have received fiom their peers as playmates and work partners. Scores were obtained at each follow-up point for both Cohort. Test-retest reliabilities for the work and play ratings are .84 and 3 2 , respectively (Oden & Asher, 1977). The Roster-Rater scales were only administered at the follow-up.[¬e]""']",Parent Questionnaire. Phone interviews were conducted at the beginning of the year with parents (or guardians) by project personnel.,"['Page 5:\n[¬s]""Parent Questionnaire. Phone interviews were conducted at the beginning of the year with parents (or guardians) by project personnel. Parents indicated the dates of each school move and the reason for the move. Parents\x92 occupation, education, age, and race were also obtained.[¬e]""']","Academic Data.  Data from students report cards were collected before the transfer, and at the beginning and end of the first year after the transfer.","['Page 5:\n[¬s]""Academic Data. Data from students\x92 report cards were collected before the transfer, and at the beginning and end of the first year after the transfer. Spelling grades before the transfer were not available for Cohort One children. Grades were also collected for the last quarter of the follow-up year. The grades (math, reading, spelling) were converted into points for statistical analysis: A = 4, B = 3, C = 2, D = 1 , F = 0.[¬e]""']",NA,NA,NA,NA
40294914,Peer Tutoring,NA,NA,NA,"['Page 2:\n[¬s]""The Gates-MacGinitie Reading Test (MacGinitie, Kamons, Kowalski, Mac\xad Ginitie, & McKay, 1978),[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117256,NA,NA,NA,NA,"['Page 2:\n[¬s]""Iowa Test of Basic Skills; ITBS[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092585,Feedback,NA,NA,NA,NA,NA,"['Page 2:\n[¬s]"" Students’ writing samples were scored using production-dependent (Total Words Written, Words Spelled Correctly, and Correct Writing Sequences), production-independent (Percentage o f Words Spelled Correctly and Percentage o f Correct Writing Sequences), and accurate-production (Correct Minus Incorrect Writing Sequences) CBM indices, and an analytic scoring system.[¬e]""', 'Page 34:\n[¬s]""The first external writing criterion used was an analytic scoring system described by Tindal and Hasbrouck (1991). As opposed to a holistic rating that yields one overall score, an analytic rating system identifies separable writing subskills with which to score students’ writing samples. Furthermore, holistic ratings make inter-individual comparisons, whereas analytic scoring systems utilize intraindividual comparisons across subskills (Moran, 1987).[¬e]""', 'Page 56:\n[¬s]"" teachers provided information regarding students’ demographic information and filled out three surveys: an Instructional Practices Questionnaire, a Writing Skill Survey, and a Procedural Integrity Form.[¬e]""']",NA,NA,NA,"['Page 2:\n[¬s]""Illinois Standards Achievement Test[¬e]""', 'Page 35:\n[¬s]""The Illinois Standards Achievement Test (ISAT; Illinois State Board of Education [ISBE], 2001) was used as a second external criterion of students’ writing performance. The ISAT is a standardized test given to third-, fifth-, and eighth-grade[¬e]""', 'Page 36:\n[¬s]""students in the state o f Illinois to measure their achievement in the academic areas of reading, writing, and mathematics. The present study determined the type o f relationship that exists between students’ scores on the writing portion o f the ISAT and their scores on the CBM writing indices.[¬e]""', 'Page 62:\n[¬s]""The Illinois Standards Achievement Test (ISAT; ISBE, 2001) was also used as an external criterion of students’ writing performance. The ISAT is a standardized test given to students in the state of Illinois in Grades 3, 5, and 8 in the academic areas o f reading, writing, and mathematics. In the area o f writing, students are given 40 minutes to write on a topic that is either narrative, persuasive, or expository in nature.[¬e]""']",NA,NA
40117137,NA,NA,NA,NA,"['Page 87:\n[¬s]"" C o m p r ehensive Tests of Basic Skills (CTBS),[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671627,Teaching assistants,NA,NA,NA,"['Page 3:\n[¬s]""Kaufman Test of Educational Achievement II, Brief Form (KTEA-II BFR)[¬e]""', 'Page 40:\n[¬s]""The primary instrument used in the study was the KTEA-II BFR. This instrument was divided into four subtests: (a) Reading Part 1 (Recognition), (b) Reading Part 2 (Comprehension), (c) Math, and (d) Writing. The reading subtests were combined in the scoring to form a reading composite score. Because the scope of the study was limited to reading achievement, only Reading Parts 1 and 2 (comprising the reading composite score) were used. The reading subtest included 67 items, split into 46 word recognition items and 27 comprehension items.[¬e]""']",NA,"['Page 38:\n[¬s]""mastery test, students must read the words with 100% accuracy, one word per second, and spell the words with 100% accuracy.[¬e]""']",NA,NA,NA,NA,NA,NA
37093568,Peer Tutoring,NA,NA,NA,NA,NA,"['Page 5:\n[¬s]""Students\x92 learning was assessed via a free recall task and three associative matching tasks (immediate, 30-day, and 60-day). For free recall, students were provided with a response sheet containing the names of the six animals, with the name of the last animal studied never appearing first on the sheet. Students were instructed to write as many of the study facts as possible for each animal using their own words and point form. Students were given unlimited time to complete this task, with most students requiring approximately 15-20 minutes.[¬e]""']",NA,NA,NA,NA,NA,NA
37116222,Peer Tutoring,NA,NA,NA,"['Page 105:\n[¬s]""Wide Range Achievement Test-3 (Wilkinson, 1993). The WRAT-3 is a standardised academic achievement measure which consists of three sub-tests: (a) Reading, which measures the ability to name letters and pronounce words of increasing phonological and orthographic difficulty; (b) Spelling, which assesses the ability to write letters of the alphabet, their name, and single words from dictation; and (c) Arithmetic, which assesses mathematical calculation skills such as counting, reading number symbols, and performing written computations, which is timed.[¬e]""']",NA,"['Page 105:\n[¬s]""Academic Achievement: Weekly Scores in Spelling and Mathematics. Teachers administered weekly pre-tests and post-tests of the spelling and mathematics material assigned during the peer tutoring sessions. The tests were constructed using the procedures described in the CWPT manual (Greenwood et al., 1997) and were administered on each Friday for 12 weeks. For example, spelling tests included 10 of the 20 words learned during the tutoring sessions that week (post-test) and 20 words learned the following week (pre-test). The same principles were applied to the construction of mathematics tests.[¬e]""']",NA,NA,NA,NA,NA,NA
40117257,Extending school time,NA,NA,NA,NA,NA,"['Page 19:\n[¬s]""outh Surveys—Youth surveys were completed three times: in November 2008, May 2009 and May 2010. Each survey collected information on youth background characteristics, including[¬e]""', 'Page 20:\n[¬s]"" MIS Participation Dat[¬e]""', 'Page 20:\n[¬s]""demographics, parental/guardian supervision during the after-school hours, prevalence of life stressors, frequency with which youth must be home after school to care for younger siblings or attend to other responsibilities, and youth’s par- ticipation in after-school programming.[¬e]""']",NA,"['Page 20:\n[¬s]""Administrative School Records[¬e]""']",NA,NA,NA,NA
37091034,Feedback,NA,NA,Stanford Diagnostic Reading Test (SDRT) was used to measure achievement. (p.7),"['Page 12:\n[¬s]"" four subtests of the Stanford \' » Diagnostic Reading Test (SORT)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092606,Feedback,NA,NA,NA,NA,NA,"['Page 97:\n[¬s]""In collaboration with the fifth-grade teachers, a summative assessment to measure student understanding o f target science content was developed. The end-of-unit test was a combination o f items selected from assessments provided in the adopted science program and original items to assess specific content introduced during this unit. The purpose o f the test was to determine student understanding o f science concepts (Virginia SOL 5.6) introduced during the intervention period. The end-of-unit test appears in Appendix F.[¬e]""']",NA,NA,NA,NA,NA,NA
38296632,Small Group Tuition,NA,NA,NA,"['Page 10:\n[¬s]""the GL New Group Reading Test (NGRT), the GL Single Word Reading Test (SWRT) and the GL Phonological Assessment Battery (PhAB[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117138,NA,NA,NA,NA,"['Page 64:\n[¬s]"" N o rm -re fe re n c e d A sse ssm e nt P ro g ra m f o r Texas (NAPT) (N o rm -re fe re n c e d A sse ssm e nt P ro g ra m f o r Texas, 1 9 9 3 ) o f th e Io w a T e s t o f Basic S k ills i n th e s p rin g o f 1992 a n d 1 9 9 3 .[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117141,Small Group Tuition,NA,NA,Reading and Math scores from the District Level Test (Northwest Evaluation Association),NA,NA,NA,NA,NA,NA,NA,NA,NA
39253322,NA,NA,NA,NA,"['Page 129:\n[¬s]""C a l i f o r n i a Achievement T e s t s[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092607,Feedback,NA,NA,Massachusetts Comprehensive Assessment System (MCAS) - 6th and 7th Grade Version,"['Page 10:\n[¬s]""the MCAS test is designed to differentiate students from quite a broad range of potential ability, perhaps 2-3 grade levels above and below the target grade. As a con- sequence, many of the items on the 7th grade test are either above or below the level of the content addressed in 7th grade and so we might well expect that the 7th grade instruction will yield improvement on only a fraction of the items on the test.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40294919,NA,NA,NA,NA,"['Page 4:\n[¬s]""Reading fluency score from the Furlan\'s Aloud Reading Test (Furlan, 1975)[¬e]""']",NA,"['Page 4:\n[¬s]""Reading accuracy. The text of 70 words from a reading book for the second grade students was used to measure reading accuracy. ""\n"" The measure of reading accuracy was the number of errors made during reading.[¬e]""']",NA,NA,NA,NA,NA,NA
37092586,Feedback,NA,NA,NA,NA,"Student achievement in writing was measured by having students write on assigned prompts to produce narrative, descriptive or persuasive pieces of writing.","['Page 8:\n[¬s]""The research question on student achievement was examined independently at four grade levels (grades 3, 4, 5, and 6).[¬e]""']",NA,NA,NA,NA,NA,NA
40294920,Feedback,NA,NA,NA,NA,NA,"['Page 11:\n[¬s]""Pre-knowledge mathematical test""\n"" a 10-item pretest adapted from Kramarski and Mizrachi (2006).[¬e]""', 'Page 12:\n[¬s]""uthentic mathematical inquiry task: Problem solving and explanations\x97An authentic mathematical inquiry task was adapted from PISA (2003)""\n""Mathematical feedback during online inquiry discussion of the authentic task""\n""mathematical feedback was coded according to the following five categories (NCTM, 2000): mathematical terms (e.g., bigger than), mathematical representations (e.g., tables, graphs), mathe- matical explanations, final solution accuracy, and non-mathematical statements (e.g., social communication like \x93we enjoyed working with you\x94)""\n""Mathematical transfer test""\n""18-item paper-and-pencil test examined all student groups\x92 (GFG, SEG, CONT) posttest ability to transfer the mathematical[¬e]""', 'Page 13:\n[¬s]""knowledge and skills learned in the instructional unit to the more formal, less authentic tasks typifying their usual math tasks in school.""\n"" The test addressed three kinds of skills: procedural (9 items), problem-solving (8 items), and constructing a mathematical problem using a given formula (1 item)[¬e]""']",NA,NA,NA,NA,NA,NA
40117142,NA,NA,NA,"Intervention: California Achievement Test (grade 3), Cooperative School and College Ability Tests (grade 7, language arts and reading), and the Stanford Achievement Test (grade 7, mathematics)  Control: Iowa Tests of Basic Skills","['Page 13:\n[¬s]"" The year round school district administered the California Achievement Test (grade 3), Cooperative School and College Ability Tests (grade 7, language arts and reading), and the Stanford Achievement Test (grade 7, mathematics). The traditional year school district administered the Iowa Tests of Basic Skills.[¬e]""']",NA,NA,"teacher grades in language arts, mathematics and reading","['Page 82:\n[¬s]"" teacher grades in languge arts 2. teacher grades in mathematics 3. teacher grades in reading[¬e]""']",NA,NA,NA,NA
37092670,Feedback,NA,NA,Peabody Picture Vocabulary Test.,"['Page 3:\n[¬s]""Both pretest and posttest consisted of 10 trials of ordered recall of three out of six pictures from the Peabody Picture Vocabulary Test. Essentially following Flavell et al.’s (7) procedure, children were pretrained to point to the same pictures in the same order as the E. On each trial, the E shuffled the six pictures, laid them out before the child, and pointed to a random series of three. The child then closed his or her eyes. After a delay of approximately 15 seconds during which the E reshuffled the pictures and recorded their order of presentation, the recall signal was given. The child then opened his or her eyes and tried to point to the same pictures in the same order as had the E. A second E, lip-reading, recorded overt repetition of labels during the delay between presentation and recall on each trial; these were scored as overt rehearsal.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093356,Peer Tutoring,NA,NA,NA,"['Page 11:\n[¬s]""Stanford Diagnostic Reading Test (SDRT), Form A-1976 (Karlsen, Madden, and Gardner, 1977).""\n""Comprehension Subscale on SDRT, [¬e]""', 'Page 12:\n[¬s]""Auditory Vocabulary Subtest on the SDRT""\n""consists of words which represent the different parts of speech and are sampled from three general content areas: reading and literature, mathematics and science, and social studies and the arts. A word or words are selected that best fit the meaning of a sentence when both the item stem and the three options are dictated.""\n""Phonetic Analysis Subtest on the SDRT""\n""Particular sounds in words are determined, and then each sound is related to a common or variant spelling of that sound. Words or sounds with various regional pronunciations are not included.[¬e]""', 'Page 35:\n[¬s]""1. The SDRT (Karlsen et al., 1977), Form A-1976, was utilized to measure the reading achievement of tutors and tutees. The test content was designed for use with pupils in grades one through 12. Four skill domains are sampled by the SDRT: decoding, vocabulary, comprehension, and rate. (Rate is only assessed for children in grade five and above.) The SDRT is a group-administered device which is both norm- referenced and criterion-referenced. [¬e]""']",NA,"['Page 11:\n[¬s]""Instructional reading level:""\n""(Lerner, 1980)[¬e]""', 'Page 36:\n[¬s]""2. The Quality of School Life Scale (QSL) (Epstein et al., 1978) was utilized as a multi-dimensional measure of student reactions to school in general, to their classwork, and to their teachers. The QSL consists of 27 items based on three dimensions of the concept of the quality of school life. The total QSL scale score is the broadest gauge of student reactions to school life. [¬e]""', 'Page 38:\n[¬s]""3. The Devereaux Elementary School Behavior Rating Scale (DESB) (Spivack and Swift, 1966; Spivack and Swift, 1967; Spivack and Swift, 1968) was utilized to measure classroom behavior. The DESB is a sophisticated and carefully developed rating scale. The behaviors to be rated are clearly described, and instructions for rating are care\xad fully given. A child is rated on 47 different items in terms of the[¬e]""', 'Page 39:\n[¬s]""relative frequency with which the described behavior occurs. The behavior rating scale can be reliably and validly used in grades one through six to rate classroom behaviors that relate to academic success or failure.[¬e]""']",NA,NA,NA,NA,NA,NA
40117259,Extending school time,NA,NA,"Palmetto Achievement Challenge Test (PACT), an end-of year test in South Carolina, was used for selecting participants",NA,NA,"['Page 2:\n[¬s]"" Parent and teacher ratings of behavioral and academic functioning[¬e]""']",NA,"['Page 9:\n[¬s]""Academic Grades and Discipline Records.[¬e]""']",NA,NA,NA,NA
40117258,Extending school time,NA,NA,NA,"['Page 6:\n[¬s]""Homework Problem Checklist. (HPC; Anesko, Schoiock, Ramirez, & Levine, 1987): The HPC is a parent report instrument consist- ing of 20 items. It is commonly used as a screening tool and outcome measure to assess homework problems.""\n""Academic performance rating scale. (APRS; DuPaul, Rapport, & Perriello, 1991): The primary purpose of this scale is to measure how well the child is performing academically. The APRS is a 19-item scale that is completed by the teacher.""\n""Organization Checklist. The Organization Checklist has been utilized as an outcome mea- sure in previous studies (Evans, Langberg et al.,[¬e]""', 'Page 7:\n[¬s]""2005; Langberg et al., 2006). This checklist consists of 14 operationalized criteria for binder, book bag, and locker organization. [¬e]""']",NA,"['Page 6:\n[¬s]""Class grades. Core class grades (math, sci- ence, language arts, and history) were collected for all participants involved in the study.[¬e]""', 'Page 7:\n[¬s]""Homework Management Checklist. The Homework Management Checklist was devel- oped for this study.[¬e]""']",NA,NA,NA,NA,NA,NA
40117206,Extending school time,NA,NA,NA,NA,NA,NA,Academic grade point average (during 3rd and 4th marking periods) Report card behaviour score (January-June 2000),"['Page 87:\n[¬s]""Academic grade point average (during 3rd and 4th marking periods); (10) Report card behavior score (January - June, 2000).[¬e]""']",NA,NA,NA,NA
39253323,NA,NA,NA,NA,"['Page 54:\n[¬s]""Reading tests were taken from the Random House AChieY-?men£_PrQgrgm_.in Comprehension with permission granted from the publisher.[¬e]""']",NA,"['Page 54:\n[¬s]""The math portion of the test was developed by the researcher[¬e]""']",NA,NA,NA,NA,NA,NA
40117260,Extending school time,NA,NA,NA,NA,NA,"['Page 19:\n[¬s]"" children were indi- vidually administered adaptive and untimed cognitive assessments of skills in literacy, mathematics, and general knowledge. [¬e]""']",NA,NA,NA,NA,NA,NA
37671606,Teaching assistants,NA,NA,NA,"['Page 4:\n[¬s]""Bus Story (Renfrew, 1997a) and the Renfrew Action Picture Test (RAPT; Renfrew, 1997b)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117283,NA,NA,NA,Metropolitan Achievement Test score,"['Page 48:\n[¬s]""1) standardized te s t scores,""\n""M e tro p o lita n Achievement T e st score[¬e]""']",NA,NA,NA,"['Page 48:\n[¬s]"" final m athem atics an d read in g grades,[¬e]""']",NA,NA,NA,NA
38878267,NA,NA,NA,NA,"['Page 5:\n[¬s]""Yopp-Singer Test of Phoneme Segmentation (Yopp, 1995)""\n"" decoding test (Scanlon & Vellutino, 1995)""\n""Concepts of Print Test (Clay, 1985)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117284,NA,NA,NA,Iowa Tests of Basic Skills (ITBS),NA,NA,NA,NA,NA,NA,NA,NA,NA
39253220,Summer schools,NA,NA,"'Pretest measures of reading vocabulary and reading comprehension were obtained from the Metropolitan Achievement Test, 1970 edition...Posttest and transfer-test measures were obtained by use of the Gates MacGinitie Reading Tests, 1965 edition (page 46 -47). 'The arithmetic problem solving subtest of the Metropolitan Achievement Test...was used for the pretest measure ...Posttest and transfer-test measures were obtained by the arithmetic problem solving subtest of the Jastak Wide Range Achievement Test.' (page 48)",NA,NA,NA,NA,NA,NA,NA,NA,NA
39253291,Summer schools,NA,NA,screening eligibility to Duke TIP’s seventh-grade Talent Search Program:  1) score at the 95th percentile or higher on at least one subscale of a fifth- or sixth-grade standardized achievement test in their state.  2) take the SAT  3) the qualification criteria for 7th-grade students at Center level is SAT-V (verbal)/SAT-M (math) score of at least 570. Score between 500 and 570 qualify for Academy level programs. ,NA,NA,NA,NA,NA,"End of Course (EOC) scores from grades 9-12 in  Algebra I and II Geometry Chemistry Physics Biology ELP (English, law and poiltical science) English U.S. History","['Page 8:\n[¬s]"" Te DPI records we used for this study were end of course (EOC) scores from grades 9–12. High school students in North Caro[¬e]""', 'Page 8:\n[¬s]""he North Carolina Department of Public Instruction (DPI). Te DPI records we used for this study were end of course (EOC) scores from grades 9–12. High school stud[¬e]""']",NA,NA
40117261,Summer schools,NA,NA,"FCAT standardized reading test to screen participants (bottom percentile) GRADE (Pearson Education Inc., 2008). for pre test and post test","['Page 90:\n[¬s]""bottom percentile of the FCAT standardized reading test.[¬e]""']",NA,NA,"pre-existing attendance records, grade reports (GPA = grade point average) and discipline referral reports",NA,NA,NA,NA,NA
39253292,Summer schools,NA,NA,"The screening tool to measure students’ oral reading fluency (reading rate and accuracy) (ORF), expressed as correct words read per minute (CWPM).  On a separate but identical form, test administrators kept track of all words read in one minute, recording the following errors: (a) omissions, (b) mispronunciations, (c) substitutions, and (d) word hesitations longer than three seconds.  easy and medium passages from the district Reading Kit assessments (Tedesco, 2002)","['Page 80:\n[¬s]""On a separate but identical form, test administrators kept track o f all words read in one minute, recording the following errors: (a) omissions, (b) mispronunciations, (c) substitutions, and (d) word hesitations longer than three seconds.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38296633,Peer Tutoring,NA,NA,New Group Reading Test,"['Page 12:\n[¬s]"" New Group Reading Test[¬e]""', 'Page 16:\n[¬s]""The New Group Reading Test (NGRT), which was developed by GL Assessment and the National Foundation for Educational Research (NFER) was used to measure the outcomes of interest.[¬e]""', 'Page 6:\n[¬s]""At the end of the intervention period all pupils were asked to complete the New Group Reading Test, as a standardised measure of general reading ability[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38296634,Peer Tutoring,NA,NA,NA,"['Page 16:\n[¬s]""All Year 3 and Year 5 pupils in participating schools undertook the pre-test in September 2012 to November 2012 and the follow-up test between February and March 2014. The InCAS assessment was completed on computers and administered to pupils in groups or as a class[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40294923,NA,NA,NA,NA,"['Page 1:\n[¬s]"" Preschool Lan\xad guage Scale (PLS) (Zimmerman, Steiner, & Pond, 1969),""\n"" Peabody Picture Vocabulary Test (PPV[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253327,NA,NA,NA,NA,"['Page 6:\n[¬s]"" Summer Success Reading Test.[¬e]""', 'Page 7:\n[¬s]""Gates-McGinitie Reading Test[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
43090171,Summer schools,NA,NA,1st grade: Summer Success Reading Test  2nd -4th grade: Gates-McGinitie Reading Test,"['Page 6:\n[¬s]"" Summer Success Reading Test.[¬e]""', 'Page 7:\n[¬s]""The test has been developed and standardized by the school district and has been used district-wide for all Kindergarten students for over ten years.""\n""Grades two through four. Children in all groups were given pre and post tests of the Gates-McGinitie Reading Test.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092587,Feedback,NA,NA,NA,NA,Writing Ability Test and Revision Ability Test,"['Page 11:\n[¬s]""2.3.1. The writing ability test""\n""Both for the pre-test and for the post-test, all the subjects listened to two texts, selected from stories and scienti®c games for children, being read: a short narrative text and an expository one, which consisted of the description of a simple physics experiment. All four texts (two short stories and two descriptions of experiments) were adjusted in order to make every critical consequential relation as clear and apparent as possible. A set of corresponding pictures was also shown in order to support the text comprehension by the subjects. Then they were asked to tell in writing the information just acquired to an absent classmate, carefully explaining how and why the facts happened in order for him/her to fully understand it.[¬e]""', 'Page 12:\n[¬s]""2.3.2. The revision ability post-test""\n"" In our opinion, this condition should avoid the risk of passive imitation of the cognitive processes experienced during the treat- ment sessions. In any case, the instructions for the test task were obviously different from the instructions for the educational treatment.: during the post-test no help through recorded verbal protocols was provided to the groups[¬e]""', 'Page 13:\n[¬s]""2.4.1. The writing ability test[¬e]""', 'Page 14:\n[¬s]""Subjects\' written texts were analysed in order to ascertain how many consequential connections had been reproduced completely, that is how many times both the ante- cedent and the consequence were mentioned.[¬e]""', 'Page 15:\n[¬s]""2.4.2. The revision ability post-test""\n""Subject\'s annotations (questions or integrations) were compared with the list of critical points mentioned above. As these points were 5, each subject received a score ranging from 0 to 5, independently of the subjects showing the detection by writing the corresponding question or by inserting the integration required.[¬e]""', 'Page 7:\n[¬s]""the results on comprehensible writing as within subjects variable""\n""A further comparison between subjects was based on the scores on a test aimed at evaluating that kind of revising ability which the treatment was designed to stimu- late.[¬e]""']",NA,NA,NA,NA,NA,NA
37092588,Feedback,NA,NA,NA,NA,Pre-test and post-test Writing Samples,"['Page 4:\n[¬s]""Two measures of quality were used. First, the final drafts of the pretest and posttest writing samples were rated for overall quality using holistic evaluation pro\xad cedures.""\n""Second, the change in quality from the first to the second draft and from the first to the third draft were rated.[¬e]""']",NA,NA,NA,NA,NA,NA
37671566,NA,NA,NA,NA,"['Page 9:\n[¬s]""Boder Test of Reading- Spelling Patterns (Boder and Jarrico, 1982) and The Neale Analysis of Reading, 3rd edn (Neale, 1999).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253391,Summer schools,NA,NA,NA,NA,NA,NA,NA,NA,Report only specifies that these were NYCDOE assessments - no further information given ,"['Page 6:\n[¬s]""In the spring of 2006, the NYCDOE assess ments in third, fifth, sixth, and seventh grades were replaced with the statewide assessment (which also replaced prior state assessments in fourth and eighth gra[¬e]""']",NA,NA
37093622,Peer Tutoring,NA,NA,NA,"['Page 20:\n[¬s]""Reading achievement was measured using the Comprehensive Reading Assessment Battery (CRAB) (Fuchs, Fuchs, & Hamlett, 1989) (see Appendix D).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093577,Peer Tutoring,NA,NA,NA,"['Page 13:\n[¬s]""Woodcock Reading Mastery Tests- Revised (1987), the Test of Early Reading Ability-2 (1989), and the Comprehensive Reading Assessment Battery (Fuchs, Fuchs, & Maxwell, 1988)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37116235,Peer Tutoring,NA,NA,"Pre and post-test reading achievement measured using the Woodcock Reading Mastery Test - Revised (Woodcock, 1987).   Wood Attack, Word Identification, and Passage Comprehension sub-tests were provided. ",NA,Adapted phonological awareness test from Kaminski & Good (1996). ,NA,NA,NA,NA,NA,NA,NA
46325689,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
37116234,Peer Tutoring,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
38878258,Small Group Tuition,NA,NA,NA,"['Page 13:\n[¬s]"" First Sound Comparison, Blending Onset-Rime, Blending Words, Blending Nonwords, and Phoneme Elision subtests from the Comprehensive Test of Phonological Processes (CTOPP)[¬e]""', 'Page 14:\n[¬s]"" Sight Word Efficiency and Phonemic Decoding Efficiency sub\xad tests from the Test of Word Reading Efficiency (TOWRE).""\n""Teachers Continuous Assessment for Reading Excellence soft\xad ware (TCARE; Mathes, Torgesen, & Heron, 2004).""\n""WJ-III, the Comprehensive Assessment of Reading Battery Revised for First-Grade (CRAB-R; see Mathes et al., 1998), and the Vocabulary subtest of the Wechsler Abbreviated Scale of Intelligence (WASI).[¬e]""']",NA,"['Page 14:\n[¬s]""Untimed word reading entailed reading words from an IRT-based list of increasingly more difficult words developed by our research team.""\n"" (see Foorman et al., 1998)[¬e]""']",NA,NA,NA,NA,NA,NA
40294924,Small Group Tuition,NA,NA,NA,"['Page 13:\n[¬s]""First Sound Comparison, Blending Onset-Rime, Blending Words, Blending Nonwords, and Phoneme Elision subtests from the Comprehensive Test of Phonological Processes (CTOPP)[¬e]""', 'Page 14:\n[¬s]""Sight Word Efficiency and Phonemic Decoding Efficiency sub\xad tests from the Test of Word Reading Efficiency (TOWRE).""\n""Teachers Continuous Assessment for Reading Excellence soft\xad ware (TCARE; Mathes, Torgesen, & Heron, 2004).""\n""WJ-III, the Comprehensive Assessment of Reading Battery Revised for First-Grade (CRAB-R; see Mathes et al., 1998), and the Vocabulary subtest of the Wechsler Abbreviated Scale of Intelligence (WASI).[¬e]""']",NA,"['Page 14:\n[¬s]""Untimed word reading entailed reading words from an IRT-based list of increasingly more difficult words developed by our research team.""\n"" (see Foorman et al., 1998).[¬e]""']",NA,NA,NA,NA,NA,NA
39253392,Summer schools,NA,NA,Standardised maths test (TSLS) Standardised reading test (TSLS),"['Page 12:\n[¬s]"" Math (TSLS) Reading (TSLS)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117146,Extending school time,NA,NA,"Cooperative Mathematics Test, Form A  Stanford Achievement Test of Reading and Mathematics","['Page 12:\n[¬s]""Cooperative Mathematics Test, Form A,[¬e]""', 'Page 54:\n[¬s]"" Stanford Achievement Test of Reading and Mathematics[¬e]""']",NA,NA,algebra achievement as measured by a teacher-constructed multiple choice test. ,"['Page 12:\n[¬s]"" algebra achievement as measured by a teacher-constructed multiple choice test. [¬e]""']",NA,NA,NA,NA
38296644,Summer schools,NA,NA,NA,"['Page 14:\n[¬s]"" The New Group reading test was administered online through the GL online testing software.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092684,Feedback,NA,NA,NA,NA,NA,"['Page 9:\n[¬s]""Simple performance task 1""\n""Simple performance task 2""\n""Learning task[¬e]""']",NA,NA,NA,NA,NA,NA
37093360,Peer Tutoring,NA,NA,Slosson Oral Reading test (SORT) for word recognition,NA,teacher-made comprehension test employing the words from the SORT ,NA,NA,NA,NA,NA,NA,NA
40117357,NA,NA,NA,"Stanford Achievement Test (SESAT II, Primary I, Primary II) pre and post treatment","['Page 6:\n[¬s]"" Stanford Achievement Tests[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671568,Teaching assistants,NA,NA,NA,"['Page 11:\n[¬s]""The primary outcome was measured (pre- and post-treatment) by the Progress in Reading Assessment (PIRA) test. This is a test that evaluates the general reading ability of pupils. 8 In particular, it assesses reading ability in the following areas: phonics, literal comprehension, and reading for meaning.[¬e]""', 'Page 12:\n[¬s]""The secondary outcomes that have been measured are as follows: 9 • DTWRP (the Diagnostic Test of Word Reading Processes). ""\n""• BPVS (the British Picture Vocabulary Scales, Third edition).""\n""• PSS (the Phoneme Segmentation Subtest) and LK (the letter sound subtest)\x97subtests from the Primary Inventory of Phonological Awareness (PIPA) test.""\n""• LEST (the Letter Sound Test). This tests a person\x92s ability to sound out single letters and letter combinations.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253295,Summer schools,NA,NA,NA,"['Page 52:\n[¬s]"" Comprehensive Test o f Basic Skills (CTBS) reading test""\n"" Elementary School Proficiency Assessment (ESPA)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117358,NA,NA,NA,"Selection to the programme by the Phonological Awareness Literacy Screening (PALS) (Invernizzi, Meier, Swank, & Juel, 1998): rhyme, beginning sound, alphabet name, letter sound, spelling, preperimer  Wide Range Achievement Test-3 Reading Subtest (WRAT-R)","['Page 6:\n[¬s]""Title I re- ferral process and by the children\x92s summed scored on the Phonological Aware- ness Literacy Screening (PALS) (Invernizzi, Meier, Swank, & Juel, 1998)[¬e]""']",Reading in context: number of words read correctly in a minute,"['Page 10:\n[¬s]""The students read a passage from Little Bear (Minarik, 1978) for 1 min.[¬e]""']",NA,NA,NA,NA,NA,NA
39253296,Summer schools,NA,NA,NA,"['Page 68:\n[¬s]"" the Scholastic Reading Inventory (Scholastic, 1999), the San Diego Grade Word List, and the Oral Reading Assessment o f Fluency (Meiosfc, 2002).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37133945,Peer Tutoring,NA,NA,NA,NA,Curriculum-based measurement (CBM) math probes based on nationally assigned curriculum features were used to identify students for data analyses who performed below average.,"['Page 3:\n[¬s]""CBM probes were used to measure each par- ticipantÕs ßuency level in mathematics by scor- ing the number of digits correctly produced within two minutes. CBM was chosen because of extensive research establishing its psycho- metric properties, as well as its ability to mon- itor progress (Foegen, Jiban, & Deno, 2007; Thurber, Shinn, & Smolkowski, 2004). The probes were administered immediately before and after the intervention to determine the ac- quisition of math facts, as well as 3 weeks after termination of the intervention to assess main- tenance of facts.[¬e]""']",NA,NA,NA,NA,NA,NA
38296647,Extending school time,NA,NA,NA,"['Page 16:\n[¬s]""The total raw score on the Progress in English 12 (PIE 12) GL assessment was the primary outcome measure. This test is a general measure of literacy skill; the exercises included are divided between editing exercises and reading exercises. In the editing tasks pupils are asked to correct errors present in a text including spelling, grammatical and stylistic errors. The reading tasks assess text comprehension and understanding of language in context.""\n"" The total raw score on the Progress in Maths 12 (PIM 12) GL assessment was used as a secondary outcome as the intervention aims to improve numeracy achievement through a core focus on numeracy. This test is split into two sections, calculator and non-calculator, and lasts one hour in total. The questions addressed Levels 3 to 6 of the National Curriculum and covered number, algebra, shape and space, measures, data handling and probability. This test again provided a standardised measure of maths achievement appropriate to the age and curriculum stage of the students involved.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671570,Teaching assistants,NA,NA,NA,"['Page 13:\n[¬s]""The primary outcome measure was the age-standardised score from the New Group Reading Test (NGRT; Burge et al., 2010)[¬e]""', 'Page 14:\n[¬s]""The PhAB non-word reading test was administered pre- and post-testing.[¬e]""', 'Page 15:\n[¬s]"" It is important, then, to assess ability in the reading of single words. The test chosen for this was the Single Word Reading Test (SWRT6-16; Foster, 2007).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40294926,Feedback,NA,NA,NA,"['Page 5:\n[¬s]"" Macmillan Group Reading Test (Vincent & de la Mare, 1987).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37133947,Peer Tutoring,NA,NA,NA,NA,"Word Recognition Measure retrieved from QRI II (Leslie & Caldwell, 1995) - post intervention test.","['Page 71:\n[¬s]""The word recognition measure was assessed w ith the word recognition section o f the QRI II (Leslie & Caldwell, 1995), a specific form o f an IRI, o r Individual Reading Inventory, which is a criterion-referenced instrum ent that provides diagnostic information about the way the reader reads words. The results o f this word recognition section correlate highly with students’ overall ability in reading.[¬e]""']",Biology Grades from end of year class test were used as a post-intervention measure.,"['Page 73:\n[¬s]""Biology Grades. Biology grades to m easure academic perform ance w ere collected at the end o f the year from stud ents’ biology class and coded by an assistant researcher after the biology teacher put them on the stud ents’ report cards. The low est possible grade was a zero and the highest w as a 100%. [¬e]""']",The State of Virginia exit exam for biology assessing Standards of Learning (SOL) was used post-intervention.,"['Page 72:\n[¬s]""Biology State Test Results. The State o f Virginia exit exam for biology, the SOL (Standards o f Learning) is a state developed criterion referenced test designed to measure student mastery o f the academic content and skills. They specify the skills and content that students at each grade level should learn from a biology course. Results from the spring testing are reported as the num ber o f questions answered correctly. [¬e]""']",NA,NA
37093581,Peer Tutoring,NA,NA,NA,NA,NA,"['Page 4:\n[¬s]""TOAM average scores over all strands were used to evaluate students\x92 mathematics achievement.[¬e]""']",NA,NA,NA,NA,NA,NA
37093579,Peer Tutoring,NA,NA,NA,NA,NA,"['Page 4:\n[¬s]"" The paper-administered test, entitled: Arithmetic Achievement Test (AAT), was developed by the Israeli Ministry of Education (1985)[¬e]""']",NA,NA,NA,NA,NA,NA
37092589,Feedback,NA,NA,NA,"['Page 1:\n[¬s]"" a standardized literacy measure (i.e., the constructed response subtest of the Canadian Achievement Test-4th ed.) and certain metacognitive skills measured via student self-report.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671572,Teaching assistants,NA,NA,NA,"['Page 7:\n[¬s]""Wordrecogni ti onanddevel opmentalspel l i ngassessments.""\n""developmental spelling test from the Howard Street Training Manual (Morris, 1992)[¬e]""']",NA,NA,NA,NA,NA,"['Page 8:\n[¬s]""Norm-ref erencedachi evementassessmentsandretenti ons. The Met- ropolitan Achievement Test for reading and language arts was administered by dis- trict officials to all students at the end of the second grade.[¬e]""']",NA,NA
37091036,Feedback,NA,NA,NA,"['Page 4:\n[¬s]""A measure of each student\'s reading comprehension was obtained using the Stanford Diagnostic Reading Test Level I, Forms W and X (1968) and the comprehension subtest of the Stanford Diagnostic Reading Test, Level II, Forms W and X (1966).[¬e]""']",NA,"['Page 4:\n[¬s]""Four types of data were used to analyze treatment effects. Measures of oral reading rate correct, oral reading rate incorrect, vocabulary meaning, and comprehension were obtained for all students both prior to and following treatment. The first three measures were derived from stories randomly selected from Levels lb, lib, and Illb of the Power Builder Kits (SRA, 1963, 1969).""\n"" Daily measures of oral reading correct and incorrect and vocabulary meaning in the SRA Power Builder Stories also were obtained for students in the daily measurement and data decision rule groups (N = 26).[¬e]""']",NA,NA,NA,NA,NA,NA
40117150,Extending school time,NA,NA,"Stanford Achievement Test (Version 9, the California STAR test)","['Page 14:\n[¬s]"" The Stanford Achievement Test, Version 9 or SAT-9 (the California STAR test),[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117264,Extending school time,NA,NA,NA,NA,NA,NA,Grades (Student report card records from school): before and after treatment,NA,NA,NA,NA,NA
40117289,Extending school time,NA,NA,Gate-MacGinitie Reading tests - Level D - Form 2 was administered for vocabulary and comprehension. ,"['Page 7:\n[¬s]"" Gat11-JlacGinitit Rlading Teat• - Level D - Porm 2 was adllinistered tor vocabulary and comprehension[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
43090186,NA,NA,NA,NA,"['Page 3:\n[¬s]"" Gate \x7f -llaoGinitie Reading Teat\x95[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37061123,Feedback,NA,NA,NA,"['Page 2:\n[¬s]""Metropolitan Spelling Achievement Test, Form R[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40294931,Feedback,NA,NA,NA,NA,NA,"['Page 5:\n[¬s]""On the Monday following the 4-wk. experimental period, a post-test was given to both groups. It was composed of 50 words selected randomly from the programmed units.[¬e]""']",NA,NA,NA,NA,NA,NA
40294930,Peer Tutoring,NA,NA,NA,"['Page 67:\n[¬s]""reading achievement was measured at Time 1 and Time 3 in a pre-/posttest fashion using the Comprehensive Reading Assessment Battery (CRAB) (Fuchs, Fuchs, & Maxwell, 1988)[¬e]""', 'Page 69:\n[¬s]""Stanford Achievement Test - Reading Comprehension Subtest (Fuchs et al., 1988).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117359,NA,NA,NA,"See p.139 and 140 for full explanation. Summarised below: * word recognition from Basic Reading Vocabularies (HAriis & Jacobson, 1982) * Spelling from the Qualitative Inventory of Word Knowledge (Schlagal, 1989) * Basal passage reading accuracy from the school basal reader (Ginn, 1983)",NA,"The Basal passage reading accuracy from the school basal reader (Ginn, 1983) has also been listed under standardised tests, but a special scoring system was devised for this task. See p.140",NA,NA,NA,NA,NA,NA,NA
40117214,Extending school time,NA,NA,NA,"['Page 3:\n[¬s]"" Individual resilience/cooperation and self-control""\n""The individual protective factor index (IPFI; Springer & Phillips, 1995)""\n""The self description questionnaire (SDQ; Marsh & Smith, 1987) was used to assess academic self-concept""\n""To assess students\' social problem-solving approach, the children\'s action tendency scale (Deluty, 1979) was administered.""\n""To measure school bonding, the psychological sense of school membership scale (PSSM) was used (Goode- now, 1993)""\n""Student and teacher perceptions of student partici- pation in the classroom were measured.[¬e]""', 'Page 4:\n[¬s]"" by completing a classroom readi- ness survey (Berndt & Keefe, 1995)""\n""Questions regarding student perceptions of the extent to which parents supervised their activities at home were taken from the National Educational Longitudinal Study Survey (NCES, 1988)""\n""Teacher perceptions of student problem behavior was derived from the acting-out scale from the tea- cher- child rating scale (TCRS; Hightower et al., 1986).[¬e]""']",NA,NA,NA,"['Page 4:\n[¬s]""Student academic performance was conceptualized as student grades in math, which was calculated for each student by examining report cards for their cur- rent academic year.[¬e]""']",NA,NA,NA,NA
37671607,Teaching assistants,NA,NA,NA,"['Page 6:\n[¬s]""a standardized mathematics test used for measuring progress in the whole of the project evaluation""\n""The test used was originally designed by the University of Leeds for the evaluation of the National Numeracy Project, and covers all elements of the English National Curriculum in mathematics.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37116214,Peer Tutoring,NA,NA,NA,NA,NA,"['Page 4:\n[¬s]""Achievement test in Physics prepared and validated by the investigator[¬e]""']",NA,NA,NA,NA,NA,NA
37092701,Feedback,NA,NA,NA,"['Page 5:\n[¬s]""The Original series of the Porteus Maze Test was administered as a pretest, and the Extension series of the Porteus Maze Test was administered as apostte[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671575,Teaching assistants,NA,NA,NA,"['Page 13:\n[¬s]""Peabody Picture Vocabulary Test\x96IIIA (PPVT; Dunn & Dunn, 2006).[¬e]""', 'Page 14:\n[¬s]"" Test of Preschool Early Literacy (TOPEL; Lonigan, Wagner, & Torgesen, 2007) Print Knowledge subtest""\n""Sections B and C from the TOPEL Print Knowledge subtest""\n""TOPEL Phonological Awareness subtest[¬e]""', 'Page 15:\n[¬s]""OPEL De\x1enitional Vocabulary subtest[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117215,NA,NA,NA,NA,"['Page 3:\n[¬s]""The Nowicki-Strickland Locus of Control instrument is designed to assess the degree to which children connect their actions to the outcomes which result from them (Nowicki & Strickland, 1973)[¬e]""']",NA,"['Page 3:\n[¬s]""Classroom teacher observations were used to evaluate student attitude toward school.""\n"" Observations were recorded in a note\xad book and qualitatively analyzed[¬e]""']",NA,"['Page 3:\n[¬s]""Grades for participating students were av\xad eraged for two semesters to measure aca\xad demic achievement.[¬e]""']",NA,NA,NA,NA
37133954,Peer Tutoring,NA,NA,NA,NA,NA,"['Page 52:\n[¬s]""The Test of Achievement and Proficiency, Level 15, Form T, Test 2: Mathematics,[¬e]""']",NA,NA,NA,NA,NA,NA
38296657,Teaching assistants,NA,NA,NA,"['Page 7:\n[¬s]""the Quantitative Reasoning Test,[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093585,Peer Tutoring,NA,NA,NA,"['Page 2:\n[¬s]""the Metropolitan Achievement Test[¬e]""', 'Page 3:\n[¬s]""M A T subtests of Word Knowledge and Comprehension [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092590,Feedback,NA,NA,NA,NA,NA,"['Page 4:\n[¬s]""Data collection. Data consisted of the rough drafts of lesson 6, collected and copied before and after the formal revising session and the final drafts of the same lesson. Those drafts were used in the analysis of revision behav\xad ior and writing quality. [¬e]""', 'Page 5:\n[¬s]""Quality of writing. The scale used in this study to ana\xad lyze writing quality was an adaptation of Cooper’s (1977) Personal Narrative Writing Scale.[¬e]""', 'Page 5:\n[¬s]""Revision behavior. The revision category system in this study was adapted from a system used by Bridwell (1980). That system considered the syntactic levels of revision behavior affecting content of text: • Single-word level (“Run” is changed to “race.”) • Multiple-word level (“In front of my house” is de\xad leted from a sentence.) • Sentence level (“I loved my horse very much” is ad\xad ded to a paragraph.) • Multiple-sentence level (“Grandma and Grandpa were waiting for us when we arrived. They had supper ready and our beds all made. Boy were we glad to see them” are rearranged from the beginning of the story to a spot near the middle.) That system also considered types of revision behav\xad ior—mechanics, spelling, additions, deletions, substitu\xad tions, and rearrangements (referred to as an “order shift” by Bridwell, 1980)[¬e]""']",NA,NA,NA,NA,NA,NA
37092703,Feedback,NA,NA,NA,NA,NA,"['Page 4:\n[¬s]""Achievement Skill Test This test contains 45 items and covers addition, subtraction, division, multiplication of decimals, rounding of decimals, and changing fractions to percentages. It was designed by the investi\xad gator to measure the amount of instructional material that was learned during this experiment, and was used as the criterion measure for both immediate and delayed retention.[¬e]""']",NA,NA,NA,NA,NA,NA
37092704,Feedback,NA,NA,NA,NA,NA,"['Page 4:\n[¬s]""n. Piagetian criterion tasks adapted from those used by Le- febvre and Pinard (1972) were employed in this study. The same tasks have also been successfully used by Charbonneau, Robert, Bourassa, and Gladu- Bissonnette, (1976) in measuring the attainment of conservation by white French-speaking children through observation of a model performing the tasks.""\n""ity. Two comparable tests, each consisting of four tasks on substance and four tasks on volume, were constructed for the pretest and posttest respectively. The two parallel forms were critically reviewed and validated by a panel of experts drawn from the academic staff of the Faculty of Education of the Universi""\n"" Piaget. The approved four in each test con- sisted of two tasks on quantity and two on substance, and both forms were rated equivale[¬e]""']",NA,NA,NA,NA,NA,NA
39253393,Summer schools,NA,NA,NA,"['Page 64:\n[¬s]""CAT 6/TerraNova second edition for seventh grade students""\n""Gates MacGinitie Reading assessment[¬e]""']",NA,NA,NA,NA,NA,"['Page 64:\n[¬s]""the eighth grade Alaska Benchmark Examinations[¬e]""', 'Page 66:\n[¬s]""CTB/McGraw Hill developed the benchmark exams for the state o f Alaska for Grades 3, 6, and 8 and the Alaska High School Graduation Qualifying Exam.[¬e]""']",NA,NA
40294937,Peer Tutoring,NA,NA,NA,"['Page 60:\n[¬s]"" one standardized reading achievement test (Woodcock-Johnson Reading Test Subtests #13, #14 and #15), one standardized self-attitude test (Student Perceptions of Ability Scale), and three measures of attitude toward school or classmates (Student Attitudes Questionnaire, Attitudes About School, and the Who\'s On Your Team Test).[¬e]""']",NA,"['Page 60:\n[¬s]""Observation data were collected by an assistant researcher on a daily basis throughout the study for purposes of treatment verification.[¬e]""']",NA,NA,NA,NA,NA,NA
40117154,Extending school time,NA,NA,NA,NA,NA,NA,NA,NA,Texas Learning Index scores (TLI) as collected from the Texas Assessment of Academic Skills,"['Page 18:\n[¬s]""Texas Assessment o f A cadem ic Skills (TAAS): A state-mandated test m easuring a range o f skills, from basic knowledge to the use o f higher-order thinking and[¬e]""', 'Page 19:\n[¬s]""problem-solving skills in grades 3 ,4 , and 5 (elementary). Skills tested by the TAAS represent curricula in schools across the state o f Texas in the subject areas o f reading, mathematics, and writing (grade 4). T exas Learning Index (T LD : The mean value o f comparable improvement in reading and m athem atics on the Texas Assessment o f Academic Skills (TAAS) test.[¬e]""']",NA,NA
37133956,Peer Tutoring,NA,NA,NA,NA,6+1 Trait writing assessment model used to grade essays by treatment and non-treatment groups in February and May (pretest and posttest).  Knudson Writing Attitude Surveys were also used pretest and posttest.,"['Page 14:\n[¬s]""Pretest and posttest writing prompts were used and evaluated by three trained raters using the 6+1 traits writing assessment rubric as the outcome measure.[¬e]""', 'Page 70:\n[¬s]""All students from the treatment and non-treatment groups wrote essays to writing prompts in February and again in May. Each essay was graded by three raters using the 6+1 Trait writing assessment model developed by the Northwest Regional Educational Laboratory, Portland, Oregon (Spandel and Stiggins, 1990). Raters o f student papers, according to the rubric, were assigned a numerical value from 1 (lowest score) to 5 (highest score) for each o f six traits including ideas, organization, voice, word choice, sentence fluency and conventions. The scores o f all three raters were then averaged in order to determine a fined score for each student.[¬e]""']",NA,NA,NA,NA,NA,NA
37092591,Peer Tutoring,NA,NA,NA,"['Page 4:\n[¬s]""Students wrote essays to writing prompts in February and in May. Each essay was graded by three raters using the 6+1 traits writing assessment model (Culham, D""\n""7[¬e]""', 'Page 5:\n[¬s]"" 2003; Spandel, 2000; Spandel & Culham, 1997; Spandel & Stiggens, 1990). [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40294939,Peer Tutoring,NA,NA,NA,"['Page 2:\n[¬s]"" 6+1 traits writing assessment rubric.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37133957,Peer Tutoring,NA,NA,NA,NA,"The Orleans-Hanna Algebra Prognosis Test was used to collect data for the pretest, posttest and post-posttest of the subjects (the control group did not complete both posttest and post-posttest but tutees and tutors did). ","['Page 68:\n[¬s]""Developed by Joseph B. Orleans and Gerald S. Hanna for the Psychological Corporation, this test is used to predict how well a student can learn algebra. The authors identify three factors that the test measures, which they believe are crucial to the study of algebra. These are aptitude, previous achievement, and interest and motivation.[¬e]""']",NA,NA,NA,NA,NA,NA
39253299,Summer schools,NA,NA,"Study 2: Basic Reading Inventory (BRI, Johns 1997)  Study 2: 3 data points, pretest, posttest and follow-up in 12 months  Study 2: Gts-MacGinitie Reading Test (GMRT): Level PRE and R with their four subtests each","['Page 6:\n[¬s]"" Basic Read ing Invento ry (BRI; Johns, 1997)[¬e]""', 'Page 7:\n[¬s]""G t s -Ma c Ginitie Reading Te st GMR T). The GM RT is a g roup\xad adrn iniste red, no rm-re fe renced , re ading test. The lo west leve l is PRE and it inc ludes fou r subtests: Lite racy Con cepts, Read ing Instruction Re l tion al Conc epts, Ora l Languag e Concepts (Lingu istic A wa reness), and Lette rs and Lette r-Sound Correspondences.[¬e]""', 'Page 8:\n[¬s]"" Leve l R also inc ludes four subtests: Let\xad ter-Sound Co rrespondences (Init ia l Consonants and Consonant Clusters ), Letter-Sound Co rrespondences (Fina l Consonants and Consonant Ous\xad ters), Lette r-Sound Correspondences (Vo we ls), and Use of Sentenc e Con \xad te xt.[¬e]""']","Study 1: Informal reading inventory (IRI: graded word lists) adapted from the Qualitative Reading Inventory II (QRI; Leslie & Caldwell, 1995); 2 data points, at the beginning and end of summer school   Study 2: Literacy Habits Interview (Daily reading and writing habits)  Study 2: Students' Opinions About Reading (SOAR) using a Likert-type response scale.","['Page 5:\n[¬s]"" in forma l re ading invento ry (IRI) adapted fo r our resea rch pu r\xad poses. All ch ild ren in th e study were init ia lly g iven the graded word lists from the Qualitative Reading Inventory II (QRI; Leslie & Caldwell, 1995)[¬e]""', 'Page 5:\n[¬s]""The eva lu ation o f the su mme r read ing p rogra ms was p lanned in thre e phases: p retest data co llect ion in spring of 1999, posttest data co llect ion in the fa ll o f 1999, and follo w -up testing in spring o f 2000.[¬e]""', 'Page 6:\n[¬s]"" da ily re ading and writ ing hab its with a survey entit led "" Lit eracy Hab its,"" and we sur\xad veyed Students\' Op in ions About Read ing (SOA R) us ing a Like rt-typ e re\xad sponse scale.[¬e]""', 'Page 8:\n[¬s]""Literac y Habit[¬e]""', 'Page 8:\n[¬s]""Students\' Opinion s About Reading (S OAR).[¬e]""']",NA,NA,"Study 1: Michigan Literacy Progress Profile (MLPP): phonemic awareness and concepts of print (for those children who were unable to read at least 14 words on the preprimer list).  Study 2: MLPP, 2nd version: Concepts of Print, Sight Word and Decodable Word List, Phonemic Awareness, Oral Reading and Miscue Analysis","['Page 7:\n[¬s]""MLPP""\n""Concepts of P rin""\n""Sight Word and Decodable Word List""\n""Phonemi Awareness.""\n""Oral Reading and Mi scue Analyses.[¬e]""']",NA,NA
38296659,Teaching assistants,NA,NA,NA,"['Page 5:\n[¬s]"" Hodder Group Reading Test 2A.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37061141,Feedback,NA,NA,NA,NA,NA,"['Page 2:\n[¬s]""or this text 36 multiple-choice questions were constructed: 12 fact ques\xad tions requiring the recall of factual information, 12 inference questions requiring subjects to make inferences from the literal message contained in the text, and 12 guess questions which were related to text contents but could not be answered on the basis of the information derived from the text (Example: ""How old do you think the owner of the camping site was?”)[¬e]""']",NA,NA,NA,NA,NA,NA
37061139,Feedback,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]"" For this text, two sets of 13 multiple-choice questions (4 alternatives) were constructed. [¬e]""']",NA,NA,NA,NA,NA,NA
40294942,Feedback,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]""For this text, two sets of 13 multiple-choice questions (4 alternatives) were constructed. One set (factual questions) required the recall of specific factual infor- mation. The other set (guess questions) consisted of questions which dealt with elements from the story, but could not be answered on the basis of information derived from the text;[¬e]""']",NA,NA,NA,NA,NA,NA
37092708,Feedback,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]""A posttest on the transfer word list immediately followed the test trial on the experimental words. All subjects read each transfer trigram once and no feedback was given.[¬e]""']",NA,NA,NA,NA,NA,NA
40294947,Small Group Tuition,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
37093590,Peer Tutoring,NA,NA,NA,NA,Researcher-developed pre-test and post-test,"['Page 3:\n[¬s]""Pretests Math Spatial Peer training Math Spatial Posttests Math Spatial""\n""For Year 1, materials were developed for a mathematics and a spatial reasoning series, ""\n""Two sessions""\n"" problems that required rote learning or copying models, ""\n"" four sessions were devoted to tasks that required formal reasoning""\n""During the development of these ma- terials, a sample of 10 fourth graders provided feedback on their adequacy. On the basis of this experience, some tasks were discarded or revised, and the pretests and posttests were shortened.""\n""Mathematics tasks.""\n""Spatial reasoning task[¬e]""']",NA,NA,NA,NA,NA,NA
37092592,Feedback,NA,NA,NA,NA,NA,"['Page 124:\n[¬s]""Stage 4 At this stage, students were asked to revise the papers written at pretest. The first group of research assistants returned to the classrooms and asked the students to revise the papers they had written on the first and second days of the study. The students were given 40 minutes to complete their revisions and rewrite their papers[¬e]""', 'Page 127:\n[¬s]""At pretest, posttest, delayed transfer task, and maintenance task, students responded to persuasive prompts. There were four persuasive prompts.[¬e]""']",NA,NA,NA,NA,NA,NA
38878269,Small Group Tuition,NA,NA,NA,"['Page 12:\n[¬s]""Dictation tests 1 ,2, and 3. First graders were administered two forms of a dictation task (see Clay, 1985). In October, when subjects were in second grade, they were administered a third dictation task constructed by DeFord (DeFord, Pinnell, Lyons, & Place, 1990). In all dictation tasks, administrators read the sentences and ask the children to write the words. Children are given credit for every sound represented accurately.[¬e]""', 'Page 13:\n[¬s]""Mason Early Reading Test. The Early Reading Test, devised by Mason (see Mason, 1984; Mason & McCormick, 1984) is an individually administered test of concepts related to emergent literacy""\n""Woodcock Reading Mastery Test-Revised (1987). The Woodcock Reading Mastery Test is an individually administered comprehensive battery of tests measuring aspects of reading ability such as visual/auditory learn\xad ing, letter identification, word attack, word identification, word comprehension, and passage comprehension.""\n""Gates-MacGinitie (1978). The Gates-MacGinitie Reading Test is a group-administered, comprehensive, standardized test of skills and knowledge related to read\xad ing. The test covers vocabulary and comprehension exercises.[¬e]""']",NA,"['Page 13:\n[¬s]""Text reading level. Measures of text reading level were obtained by constructing a gradient of difficulty for texts drawn originally from a basal reading series (see Scott, Foresman & Co., 1979). The scale was constructed by selecting and then testing difficulty levels with groups of children over time (see Peterson, 1991; Pinnell, Deford, & Lyons, 1988). There are 26 levels in all, the highest level indicating approximately sixth-grade level according to the published basal system. The texts used for this testing procedure are not used for instruction; children are asked to read them without previous review of the text, moving progressively up the levels of diffi\xad culty. The texts vary in length from approximately 50 to 500 words. Individually, children are asked to read selec\xad tions while the tester records reading behavior using Clay\'s running record technique (Clay, 1985) and calcu\xad lates an accuracy level. Children continue reading higher levels of text until they score below 90%,accuracy on two successive levels of text. The test yields a difficulty score (the highest level read above 9()0/4accuracy).[¬e]""']",NA,NA,NA,NA,NA,NA
40117157,Extending school time,NA,NA,Fourth-graders: - School and College Ability Test (SCAT) to measure aptitude  - Sequential Test of Educational Progress (STEP) to measure achievement  First-graders pre-test: Metropolitan Readiness TEST (MRT): - word meaning - listening - matching - alphabet - numbers - copying,NA,NA,NA,NA,NA,Fourth-graders: SRA Assessment Survey Edition of the Iowa Tests of Education Development (ITED) for measuring achievement,NA,NA,NA
37092593,Feedback,NA,NA,NA,NA,NA,NA,Students provided a writing sample as pre-test measure. Writing composition was tested throughout the study through the assessment of student essays using the typical scoring rubric teachers used in conventional composition instruction. ,"['Page 5:\n[¬s]""A writing sample was collected from all subjects in the study to be used as a pretest. Students were asked to do personal writing on the topic ""An Interesting Trip"".[¬e]""']",NA,NA,NA,NA
40117291,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 72:\n[¬s]"" Spring 2000 Stanford Achievement Test, Ninth Edition (SAT-9), for both reading and mathematics.[¬e]""']",NA,NA
38878270,Small Group Tuition,NA,NA,NA,"['Page 24:\n[¬s]""The Fountas & Pinnell Benchmark Assessment System was used to measure the following literacy skills: phonemic awareness, letter-sound relationships (decoding), vocabulary, comprehension, fluency, and writing. Both treatment and control students in the study were tested by LLI teachers at the beginning and the end of LLI. This data was used to measure individual student gains as well as the composition of the groups in respect to homogeneity of student needs.[¬e]""', 'Page 25:\n[¬s]""Dynamic Indicators of Basic Early Literacy Skills (DIBELS)""\n"" assess student development of phonological awareness, alphabetic understanding, and automaticity and fluency with the code.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38878271,Small Group Tuition,NA,NA,NA,"['Page 6:\n[¬s]""Word identification. The letter-word identification test from the Woodcock Diagnostic Reading Battery (Woodcock, 1998) required students to name individu\xad ally presented letters and words""\n""Text reading accuracy. Students in grades 2 through 6 were asked to read a series of short paragraphs that increased in difficulty level on the Gray Oral Reading Test (GORT-3) (Wiederholt & Bryant, 1992). The num\xad ber of word errors that occurred at each level deter\xad mined their word accuracy score.""\n""Word analysis. The word attack test from the Woodcock Diagnostic Reading Battery (Woodcock, 1998) required students to name individually presented non\xad words.""\n""Word efficiency. The sight word efficiency subtest from the Test of Word Reading Efficiency (TOWRE) (Torgesen, Wagner, & Rashotte, 1999) required stu\xad dents to read as many printed real words as they could within 45 seconds. The words were presented in verti\xad cal lists.""\n""Phonetic decoding efficiency. The phonemic decoding efficiency subtest from the TOWRE (Torgesen""\n""et al., 1999) required students to read as many pro\xad nounceable printed nonwords as they could decode within 45 seconds. Nonwords were presented in verti\xad cal lists.""\n""Text reading rate. Students in grades 2 through 6 were asked to read a series of short paragraphs that increased in difficulty level on the GORT-3 (Wiederholt & Bryant, 1992). Amount of time taken to read each paragraph was recorded to provide a rate measure.""\n""Passage comprehension. The Passage Compre\xad hension subtest of the Woodcock Diagnostic Reading Battery (Woodcock, 1998) asked students to read silent\xad ly a series of paragraphs and supply the key missing word in each paragraph.""\n""Comprehension. The GORT-3 (Wiederholt & Bryant, 1992) required students in grades 2 through 6 to answer five comprehension questions after reading each paragraph. The questions and four multiple\xad choice answers were read to the student by the tester.""\n""Pseudo-spelling. This 15-item spelling test from the Spell Read test battery (MacPhee, 1990) required stu\xad dents to write the spelling of nonwords that were repeated twice by the examiner. ""\n""Schonell spelling. This 100-item spelling test (Schonell & Schonell, 1950) required students to cor\xad rectly spell each word given orally by the tester. Answers were scored either right or wrong.""\n""Stanford-Binet vocabulary. Students were asked to give the meaning of words from the Vocabulary subtest of the Stanford-Binet Intelligence Scale, 4th ed. (Thorndike et al., 1986). This subtest was used to give an estimate of the student’s verbal ability (Sattler, 1988).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671611,Teaching assistants,NA,NA,NA,"['Page 5:\n[¬s]""The measuring instrument used was Dynamic Indicators of Basic Early Literacy Skills (DJBELS). There were four subtests of the DIB ELS used in this study. These subtests were: (a) Letter Naming Fluency (LNF), (b) Phoneme Segmentation Fluency (PSF), (c) Nonsense Word Fluency (NWF), and (d) Oral Reading Fluency (ORF).[¬e]""']",NA,NA,NA,NA,NA,"['Page 12:\n[¬s]""In addition to DIBELS, two Louisiana mandated assessment programs were examined in the longitudinal study: (a) the grade 3 integrated Louisiana Educational Assessment Program (/LEAP), and (b) the grade 4 Louisiana Educational Assessment Program (LEAP). This study examined the student performance in the English Language Arts assessment for 2006, 2007, and 2008.[¬e]""']",NA,NA
39253229,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
39253334,Summer schools,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 51:\n[¬s]"" Reading portion o f the CTB/McGraw-Hill Terra Nova achievement test[¬e]""', 'Page 54:\n[¬s]""Terra Nova Level 11 was administered to all district first grade students in May 1999 (pretest). Terra Nova Level 12 was administered to all district second grade students in August 1999 (posttest). Terra Nova Level 13 was administered to all district second grade students in February 2000 (posttest).[¬e]""']",NA,NA
37092715,Feedback,NA,NA,NA,"['Page 4:\n[¬s]""The role-taking task (Task 2) was taken from Lefebvre-Pinard and Reid (1980) and included two items. In this task, the child served as a speaker, and a confederate was the listener.[¬e]""']",NA,"['Page 3:\n[¬s]""The speaking task (Task 1) included three items targeting each on one of the three major abilities required to communicate effectively: that is, (l) to engage in comparison activity (Sonnenschein & Whitehurst, 1984a, 1984b;[¬e]""', 'Page 4:\n[¬s]""Whitehurst & Sonnenschein, 1981), (2) to be aware of the instrumental nature of a message in recognizing that the discriminating attributes of a given referent vary with the particular set of nonreferents and that the comparison activity is not done once for all (Garmiza & Anisfeld, 1976; Robinson & Robinson, 1982), (3) to take into account the perspective of the listener (Garmiza & Anisfeld, 1976; Roberts & Patterson, 1983; Whitehurst & Sonnenschein, 1984a).[¬e]""', 'Page 5:\n[¬s]""The listening task (Task 3) was adapted from Ironsmith and Whitehurst (1978) and induded two items. The speaker and the listener received the same set of pictures constructed by crossing two two-valued attributes; a down was either sad or smiling and had full or spotted cheeks. Children were told that the confederate would try to help them find the target card. The children were to choose the target card if they thought they knew which one it was; bur, if they were not sure, they were to ask a question.""\n""The evaluation task (Task 4) was used to assess children’s comprehension of the causes of communication failure by using the ""whose fault?” technique developed by Robinson and Robinson (1976). Children observed a communi\xad cation game between two puppets and were asked to comment upon their communication failures.[¬e]""', 'Page 6:\n[¬s]""The concept-formation task (Task 5) included two items adapted from Denney and Turner’s (1979) ""twenry-questions game” and was used to evaluate if children could transfer some of the skills needed for referential communica\xad tion into a nonreferential communication context.[¬e]""']",NA,NA,NA,NA,NA,NA
40117178,NA,NA,NA,Educational attainment was collected through 1) the Regents Test performance in English and Maths and 2) school grades (collected from NY city's department of education) ,NA,NA,NA,See details for code above,NA,NA,NA,NA,NA
39253335,NA,NA,NA,NA,"['Page 5:\n[¬s]""Compre/rensive Tests of Ba.sic Skills (CTBS). The CTBS was given statewide to all South Carolina students. The CTBS is one of the most frequently used edu\xad cational achievement tests designed spc\xad cificaJly lo measure a broad array of basic[¬e]""', 'Page 6:\n[¬s]""skills: Reading, Language, Math, Science. and Total score. Scores arc reported as percentile r~nks within grades, as grade equivalents, ,as stanines, and as a ""scale score"" systerri.""\n""Woodcock-Johnson Psyclw-Ed11cario11al Bauery. Experimental , subjects were tested for within group Idifferences using the Woodcock-Johnson Psycho-Educa\xad tional Battery, Tests for Achievement and Tests of Interest. These tests served two purposes. First, subtest scores were used as diagnostic means for matching SCAD students with educational curriculum. Finally, Woodcock-Johnson achievement and interest scores were collectively com\xad puted to test for within group differences.""\n""The Woodcock-Johnson Interest In\xad ventory (School Intercst Cluster and Nonschool Jntcrcst Cluster) was used to measure changes in student interest. The School Interest Test is divided into three school interest clusters (Reading. Math, and Written language Interests) and two nonschoo! interest clusters ( Principal an<l Social interest). The School Interest Tests arc scored as continuous data.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092594,Feedback,NA,NA,NA,"['Page 3:\n[¬s]""Immediately following one revision strategy instruction, the ex\xad perimental groups applied the strategy to the other two rough drafts.""\n""These final two paragraphs were evaluated as posttests. The paragraphs were rated using the Diederich (1974) analytic scale, which evaluates writing in two overall areas: general merit and mechanics. General merit includes four factors: ideas, organization, wording, andflavor,while mechanics is broken down into usage, punctuation, spelling, and handwriting.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092778,Feedback,NA,NA,NA,NA,NA,"['Page 8:\n[¬s]""The test. The test given after the passage reading was a completion test which consisted of 4 pages—each with 1 item from each of the 16 paragraphs in the passage. In this way, all 64 sentences comprising the passage were covered. Some were covered by using the actual sentence, an important word or phrase deleted. For others, a question based on the sentence was followed by a blank for the answer to the question. The last page of the test contained the items associated with the main ideas of the passage as expressed in the topic sentences of each paragraph. The children completed the test 1 page at a time and were not allowed to turn back to a page after having turned it.[¬e]""']",NA,NA,NA,NA,NA,NA
38296661,Feedback,NA,NA,NA,"['Page 15:\n[¬s]""Progress in English Test (PiE)""\n""Access Maths Test (AMT)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253336,Summer schools,NA,NA,NA,NA,NA,"['Page 55:\n[¬s]""S tudent achievement in mathematics was measured using a score from th e Mathematics Achievem ent T e s t, a multiple choice examination designed by the researcher. T e s t items were based on the school d is tric t’s m athem atics curriculum. Ten points were awarded for each of the 10 questions th a t were answered correctly. Thus, the scores ranged from 0 to 100, which is th e customary fo rm a t fo r presenting scores t o students.[¬e]""']",NA,NA,NA,"['Page 57:\n[¬s]""Additionally, school records were used to determ ine attendance, to ta l number o f credits earned, and to tal number of math credits earned during the first sem ester of the 1 9 9 5 / 9 6 school year.[¬e]""']",NA,NA
40117295,Extending school time,NA,NA,NA,NA,NA,"['Page 9:\n[¬s]"" th e M athem atics A c h ie v e m e n t T e s t, a multiple choice examination designed by th e researcher.""\n""th e M athem atics A ttitu d e T e st,[¬e]""']",NA,NA,NA,NA,NA,NA
40117160,Extending school time,NA,NA,NA,NA,NA,NA,NA,"['Page 1:\n[¬s]"" mid-year competency test and an end- of-year competency test.[¬e]""']",NA,NA,NA,NA
37671612,Teaching assistants,NA,NA,NA,NA,NA,"['Page 82:\n[¬s]""Measurements of baseline performance and progress for students\x92 sight-word reading skills in all groups were taken against the NLS Reception (45 words), Years 1 to 2 (163 words) which includes the names of the days of the week, the twelve months, numbers from zero to twenty and ten common colour names, and Years 4 and 5 (124 words) high- frequency word lists taken directly from The National Literacy Strategy: framework for teaching (DfEE, 1998; pp. 60-63). These lists were split up into three corresponding sections for administration during the study (Lists 1, 2 and 3). In total 332 words make up these lists [¬e]""', 'Page 83:\n[¬s]""These words formed the content of what is termed as the \x91reading accuracy measure\x92 (RAM) assessment throughout the research. Each RAM took place individually with each participating student during school site visits by the researcher at specified periods across the school terms (see Table 4 and Table 5 below). During every RAM assessment each participant was asked to read the words from an A4 printed booklet (see Appendix 3.1.5) while the researcher marked their responses as either correct or incorrect. These measures were not only used to demonstrate skill levels (i.e. number of words read correctly) before and after PT intervention, but also formed the basis of the curriculum (a \x91PT programme plan\x92) to be undertaken through PT sessions[¬e]""']",NA,NA,NA,NA,NA,NA
38878272,Small Group Tuition,NA,NA,NA,"['Page 52:\n[¬s]""Test of Early Mathematics Ability–Third Edition The TEMA–3, an individually administered mathematics test, was used as the primary outcome measure.[¬e]""', 'Page 53:\n[¬s]""Woodcock-Johnson–Third Edition Letter/Word subtest To examine the possible influence on reading proficiency of reducing the classroom time devoted to reading instruction, data were collected at posttest using the WJ–III Letter/Word subtest (Woodcock, McGrew, and Mather 2001).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092595,Feedback,NA,NA,NA,"['Page 39:\n[¬s]""Broad Written Language Cluster of the Woodcock Johnson Test of Achievement- Third-Edition. The Woodcock Johnson Test of Achievement-Third Edition (Woodcock, McGrew & Mather, 2001) is a standardized, norm-referenced test designed to measure children\x92s achievement in the areas of reading, mathematics and writing. [¬e]""', 'Page 41:\n[¬s]""Test of Word Reading Efficiency. The Test of Word Reading Efficiency (Torgensen, Wagner, & Rashotte, 2005) is a brief reading measure containing two subtests: Sight Word Efficiency and Phonemic Decoding Efficiency. The Sight Word Efficiency subtest measures the student\x92s accuracy in reading real words, and the[¬e]""', 'Page 42:\n[¬s]""Phonemic Decoding Efficiency subtest measures the student\x92s accuracy with pronounceable non-words.[¬e]""']",NA,"['Page 42:\n[¬s]""Curriculum-Based Measurement probes in written expression. Twenty-four curriculum-based measurement probes in written expression (CBM-WE) were developed using standard procedures (Shapiro, 1996). The probes were used to measure students\x92 writing fluency growth over time.[¬e]""']",NA,NA,NA,NA,NA,NA
40294951,NA,NA,NA,NA,NA,1) Number of attempts (1 and 2-3) entered in order to find the solution. 2) Mean Number of successes on first attempt. 3) Mean Number of failures after three attempts. 4) Degree of success (from 0 to 3).   The dyad condition also reported whether topological indications had or didn't have a justification ,NA,NA,NA,NA,NA,NA,NA
40398944,Teaching assistants,NA,NA,NA,"['Page 12:\n[¬s]""Salford Sentence Reading Test (SSRT)[¬e]""', 'Page 5:\n[¬s]""Hodder Group Reading Test (HGRT)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092719,Feedback,NA,NA,NA,"['Page 2:\n[¬s]"" the Science section, Form A, of the Sequential Test of Educational[¬e]""', 'Page 3:\n[¬s]""Progress (STEP). The test was given in two parts on con\xad secutive days. Part 1 included the first thirty items from Form A, Series 1 of the STEP test. Part 2 was the first 40 items on Form A, Series 2 of the STEP test.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38296668,Teaching assistants,NA,NA,NA,"['Page 11:\n[¬s]"" Salford Sentence Reading Test""\n""Non- Reading Intelligence Tests 1-3[¬e]""', 'Page 6:\n[¬s]"" Basic Number Screening test.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38296667,Teaching assistants,NA,NA,NA,"['Page 12:\n[¬s]""New Group Reading Test[¬e]""']",NA,"['Page 12:\n[¬s]"" Secondary outcome data was collected by NFER through a pupil questionnaire[¬e]""']",NA,NA,NA,NA,NA,NA
37133962,Peer Tutoring,NA,NA,NA,NA,NA,NA,"Pretest was a combination of Salters' Science Units (Science Education Group, University of York) and CLISP (Children's Learning in Science Project, University of Leeds).  ","['Page 6:\n[¬s]""At the end of each intervention, all the tutors and tutees were set the same (teacher devised) test as the members of the appropriate Year 9 science class. The tests were for the most part, made up of Salters\' Science items, although 30 per cent of the Plant Nutrition test comprised items based on the CLISP project.[¬e]""']",NA,NA,NA,NA
39253394,NA,NA,NA,9 & Gates Leverl 2 were post-tests,"['Page 5:\n[¬s]""Gates-MacGinitie Word Decoding Levels 1 and 2 Form S. ""\n""Gates-MacGinitie Comprehension Level 1 and 2 Form S.[¬e]""', 'Page 6:\n[¬s]""Stanford 9 Decoding and Comprehension tests Primary 2, Form T.""\n"" Pre-test: Gates Level 1 ""\n"" Post-test: Gates Level 1 ""\n"" Post-test: Gates Level 2 ""\n"" Stanford 9[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117223,Extending school time,NA,NA,NA,"['Page 3:\n[¬s]""Knowledge test\x97Subjects answered questions about the health and social effects of substance abuse (Getting et al., 1980)""\n""Attitude scale\x97Subjects were asked for their agreement with statements about substance use in American-Indian culture (Getting et al., 1983)""\n""Substance use reports\x97On 35 multiple-choice items, subjects anonymously reported their smoked and smokeless tobacco; beer, wine, and spirit; and marijuana, inhalant, amphetamine, barbituate, cocaine, and nonmedical drug use for the last 14 days (Botvin, Baker, Renick, Filazzola, & Botvin, 1984; Getting etal., 1980).[¬e]""']",NA,"['Page 3:\n[¬s]""Interactive behavior test\x97In interactive vignettes, subjects were asked to respond to culture-relevant peer influences on tobacco, alcohol, and drug use. Subjects\' responses were independently scored by two assistants for frequency counts of self-control statements, alternative suggestions to substance-use opportunities, and positive assertion statements. [¬e]""']",NA,NA,NA,NA,NA,NA
40117180,Extending school time,NA,NA,NA,"['Page 3:\n[¬s]""From schools, research assistants gathered data on youthsÕ grades in mathematics, English grammar, composition, reading, spelling, history, science, social studies, geography, and overall averages.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092597,Feedback,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]""The pretest comprised self-efficacy, writing skill, strategy use, and goal ori- entation, and was administered by a tester from outside the school. [¬e]""', 'Page 4:\n[¬s]""At the start of the first session, a tester administrated a self-efficacy for skill improvement measure which was identical to that of the pretest except that children judged their capabilities for improving their skills at the five tasks for the paragraph type to be covered during the next five sessions.""\n"" feedback was given contingent on the child using the strategy properly.[¬e]""', 'Page 5:\n[¬s]""The posttest included the pretest measures except a parallel form of the skill test was used. The posttest also in- cluded measures of progress in strategy learning and strategy value. For the progress measure, children judged how well they could use the strategy to write paragraphs now compared with when the project began. [¬e]""']",NA,NA,NA,NA,NA,NA
37092598,Feedback,NA,NA,NA,NA,It is implied that the tests were researcher developed.,"['Page 5:\n[¬s]""The pretest, which comprised measures of self-reported strategy use, self-efficacy and achievement, was administered by a tester from outside the school.[¬e]""', 'Page 6:\n[¬s]""The reliability of the self-efficacy instrument was assessed using 12 children who did not participate in this study but completed the efficacy test twice (two weeks apart)""\n""Three different forms of the skill test were developed[¬e]""']",NA,NA,NA,NA,NA,NA
43090192,NA,NA,NA,NA,NA,"Writing achievement test. The quality of children's written paragraphs was assessed with four holistic scales:  - organization,  - sentence structure and word choice,  - creativity, - style to fit purpose.  ","['Page 6:\n[¬s]""The writing achievement test was administered after the efficacy assessment. Children were given six paragraph topics, each of which represented one of the six paragraph types. The quality of subjects’ paragraphs was assessed with four holistic scales that included the following categories drawn from different sources (Hillerich, 1985; Odell, 1981; Shell et al., 1989): organization, sentence structure and word choice, creativity, style to fit purpose. [¬e]""']",NA,NA,NA,NA,NA,NA
40294954,Peer Tutoring,NA,NA,NA,"['Page 2:\n[¬s]""Woodcock-Johnson Pretest""\n"" reading subtests from the Woodcock-Johnson Psycho-Educational Battery (Woodcock, 1978)""\n""The Attitude Toward School Measure developed by Marascuilo and Levin (1968) was employed as measures of attitude change for the experimental study. [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40294955,Peer Tutoring,NA,NA,NA,NA,does not provide details about what these tests were so assume researcher developed,"['Page 3:\n[¬s]""Students took one of two criterion tests, depending on whether they were at the Beginning Reading I (grade level K-3) or Beginning Reading I1 (grade level 4-6) level. On these criterion tests, percentage of words correctly read was computed on pre- and posttest scores. The pretest score was subtracted from the posttest score to evalute gain score on the diagnostic measure.[¬e]""']",NA,NA,NA,NA,NA,NA
38296671,Teaching assistants,NA,NA,NA,"['Page 14:\n[¬s]""CEM InCAS assessment[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253304,Summer schools,NA,NA,NA,"['Page 51:\n[¬s]""Peabody Picture Vocabulary III (Dunn & Dunn, 1997). The PPVT-III is a commonly used measure of receptive vocabulary. The tester presents a slide with four pictures then reads a target word. The child is asked to identify which picture best depicts the target word. The task is stopped when children make eight or more errors in a set. Form A was used for pre-tests and form B was used for post-tests.""\n""Rhyme Oddity (Bradley & Bryant, 1983; Stanovich et al., 1984): The tester names three pictures presented on a card, and asks the child to choose the one that does not rhyme or \'that doesn\'t end with the same sound\'. The tester points to each picture as the word is spoken to reduce memory load. Example - hat, cat, bed. The experimenter provides feedback and guidance during three practice items. Children complete all 14 items in the rhyme oddity task. Phoneme Oddity (Stanovich et al., 1984): In this task children identify which word, from 3 choices, differs in the initial phoneme. For each trial, the tester points to the picture while the word is being spoken. Children are asked to choose the one \'that begins with a different sound\'. Example - bag, nine, butterfly. The experimenter provides feedback for three practice items. There are 14 items in this task; children complete all trials.""\n""Syllable Deletion (Rosner & Simon, 1971): Deletion tasks require the child to say a word minus a specific sound, to form a new word. In the syllable deletion task, children are[¬e]""', 'Page 52:\n[¬s]""asked to say a word without either the first or final syllable. For example, say cowboy without the \'boy\' part (initial syllable) or say hotdog without the \'dog\' part (final syllable). All remaining syllables formed a real word. Children completed all 10 items. Phoneme Deletion (Rosner & Simon, 1971): In the phoneme deletion task, children are asked to say a word without the initial phoneme. For example, say bus without the \'b\' sound (phoneme). For each item, the remaining part of the word formed a real word. The task was stopped when children made four consecutive errors.""\n""Woodcock Reading Mastery Test - Revised (Woodcock, 1987). Children are asked to read the first 28 words from the WRMT-R. If the child indicated that he/she does not know the word, they were encouraged to \'try and figure it out\' and \'make a guess\'. The tester recorded the child\'s pronunciation of each word, including errors. Word reading was discontinued when the child made 6 consecutive errors.""\n""Non-verbal reasoning Matrix Analogies Test-Pattern Completion (Naglieri, 1985): One subtest of the MAT was administered. Children were presented with a series of pictures, each missing a square shaped, portion of the picture. Children were asked to select the square that would complete the pattern from 5 available choices (6 choices as difficulty increases).[¬e]""']",NA,"['Page 52:\n[¬s]""General information survey: This one page survey collected demographic information about the families who participated in the project (income, parental education, occupation) and was created by the researcher for the purposes of this project. The survey was distributed to parents with the summer activities survey and satisfaction survey[¬e]""', 'Page 53:\n[¬s]""(intervention group only), at the start of grade one, after the completion of the post-test assessments.""\n""Summer activities survey: This parent completed survey asked about the literacy activities that children completed over the summer months. It was created by the researcher for the purposes of this project. Open-ended questions were used to collect information about the frequency and type of parent-child and child alone literacy activities that occurred in the home after the summer intervention.""\n""Satisfaction survey: Our community partner requested a satisfaction survey be added to the program evaluation. It was based on other satisfaction surveys used by the community partner to collect feedback about parent training workshops. The satisfaction survey was distributed only to families of children from the intervention group. The survey asked parents to complete four general, open-ended questions about their experience with the summer reading program. Comments from the satisfaction survey are reported as parent perceptions about the influence of the intervention program.[¬e]""']",NA,NA,NA,NA,NA,NA
37093595,Peer Tutoring,NA,NA,NA,"['Page 4:\n[¬s]""At the outset of the study, a mathematics achievement test was adminis- tered to all subject[¬e]""', 'Page 5:\n[¬s]"" Each test consisted of 30 multiple-choice items (15 involving the four basic operations; 15 involving other areas of the mathematics curriculum-estimation, geometry, fractions, time)""\n"" Yardsticks Criterion Referenced Tests in Mathematics (1975). T""\n""Self-esteem of tutors and nontutors was measured by a shorter form of the Coopersmith Self-Esteem Inventory (Coopersmith, 1967). T[¬e]""']",NA,"['Page 5:\n[¬s]""Reactions of tutors, tutees, parents of tutors, and teachers to various aspects of the program were assessed using ""reactionnaires.""[¬e]""']",NA,"['Page 5:\n[¬s]""Tutee weekly mathematics tests constructed on the basis of daily practice sheets were administered and scored by tutors in the fourth tutoring session each week. Results were recorded on the Tutor\'s Report Sheet.[¬e]""']",NA,NA,NA,NA
38296672,Teaching assistants,NA,NA,NA,"['Page 11:\n[¬s]""Students completed the online NGRT (produced by GL Assessment) at pre-test (NGRTA) and post- test (NGRTB)""\n""As an additional post-test measure, students completed the Single Word Spelling Test (digital) (SWST) produced by GL Assessment, which produces students’ results by standardised age scores, spelling ages, percentile ranks, and analysis by word level against national scores. [¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117166,NA,NA,NA,NA,"['Page 7:\n[¬s]""Stanford Achievement Test[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
43090193,Teaching assistants,NA,NA,"Subtests 13,14 and 15 of the Woodcock-Johnson Psycho-Educational Battery, Part 2: Tests of Achievement (p.103)",NA,NA,NA,NA,NA,NA,NA,NA,NA
37671584,Teaching assistants,NA,NA,NA,"['Page 12:\n[¬s]""Single Word Reading Test (SWRT) 7[¬e]""', 'Page 13:\n[¬s]""New Group Reading Test (NGRT)""\n""The secondary outcomes are: \uf0b7 a composite reading comprehension score based on the reading comprehension component of the York Assessment of Reading Comprehension test (YARC-RC), 12 and WIAT II reading comprehension test scores; 13 and \uf0b7 a composite reading accuracy score based on the YARC Single Word Reading Test (SWRT), and the TOWRE measure of word reading efficiency.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671585,Teaching assistants,NA,NA,NA,"['Page 14:\n[¬s]""The primary outcome for this evaluation is a language skills score which is a composite score of four different externally-valid measures of language skill: • Renfrew Action Picture Test (APT) (revised Renfrew, 2010). In this test, the child is asked to describe the actions shown in a set of pictures. Two scores are recorded, one for the level of information they provide (for example nouns and verbs) and one for the grammar they use (such as use of tenses). We use both components. • CELF-Preschool 2 UK: Expressive Vocabulary. 6 In this test, children are asked to name pictures. • Listening Comprehension (based on the York Assessment of Reading Comprehension test, YARC). Children listen to recordings of four short stories and answer questions about them""\n""In addition, we define a secondary composite outcome of word-level literacy skills based on the following three measures: • YARC: Letter Knowledge. 8 This requires children to say the sounds of letters. • YARC: Early Word Reading. This requires children to say the sounds of simple words aloud. • Spelling: children are asked to write a series of simple words.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38296673,Teaching assistants,NA,NA,"York Assessment of Reading Comprehension test (YARC-RC, Snowling et al, 2009)  YARC Single Word Reading Test (SWRT)  WIAT II reading comprehension test scores (Wechsler, 2005)  TOWRE measure of word reading efficiency (Rashotte et al. 1999)",NA,"Single Word Reading Test (SWRT, by Foster and NFER, 2008)","['Page 7:\n[¬s]""Single Word Reading Test (SWRT) 1 [¬e]""']",NA,NA,"New Group Reading Test (NGRT) score (used in all EEF ‘Literacy Catch Up’ projects) *3 (pre, 10 wk, 20 wk) - 20 sentence completion items - comprehension questions based on three passages",NA,NA,NA
38296676,Summer schools,NA,NA,NA,NA,NA,"['Page 15:\n[¬s]"" post-test raw score results of the GL Assessment Progress in English (PiE) and Progress in Maths (PiM) test, contextualised by pupils’ prior KS fine point scores in reading, writing and maths.[¬e]""']",NA,NA,NA,"['Page 11:\n[¬s]""The prior attainment scores consisted of KS2 fine point scores from summer term 2013.[¬e]""']",NA,NA
38296677,Feedback,NA,NA,NA,NA,"used existing data, focus on general progress rather than a particular subject ","['Page 11:\n[¬s]""a teacher-developed Pupil Learner Effectiveness survey[¬e]""']",NA,"['Page 15:\n[¬s]""The primary outcome measure for all pupils was the fine points scores for teacher assessment or Test in the appropriate Key Stage for all relevant year cohorts (such as Year 6), and progress from the equivalent scores from the previous year.[¬e]""']",NA,NA,NA,NA
37133964,Peer Tutoring,NA,NA,NA,NA,NA,"['Page 78:\n[¬s]""Indicators used in the study were from chapter tests. The chapter tests were composed o f fifty percent knowledge level questions, twenty-five percent comprehension questions and twenty-five percent application level questions.[¬e]""']",NA,NA,NA,NA,NA,NA
37093596,Peer Tutoring,NA,NA,NA,"['Page 10:\n[¬s]""The commercial global test was Form E of the Primary 2, Primary 3, and Interme\xad diate 1 levels of the reading comprehension subtest of the Standford Achievement Test (SAT; Gardner, Rudman, Karlsen, & Mer- win, 1982).[¬e]""', 'Page 9:\n[¬s]""Two types of measures were employed: a standardized, multi\xad dimensional battery and a commercial stan\xad dardized test of reading comprehension. The Comprehensive Reading Assessment Battery[¬e]""']",NA,"['Page 9:\n[¬s]""For pre- and postintervention measurement, the following occurred. On one passage, pupils read orally for 3 min\xad utes, had 5 minutes to retell the story in writing, then answered 10 questions. On a second passage, students had 2 minutes to complete a maze, read orally for 3 minutes, and answered 10 questions. At delayed posttest, pupils read orally for 3 minutes and then answered 10 questions from one passage. The questions, developed by Jen\xad kins et al. (1986), require short answers, re\xad flecting recall of information contained in idea units of high thematic importance.""\n""For number of correct comprehension questions, the examiner asks questions and records the student\'s oral responses.[¬e]""']",NA,NA,NA,NA,NA,NA
38878122,Small Group Tuition,NA,NA,NA,"['Page 3:\n[¬s]"" comprehension as measured by the paragraph Meaning Subtest of the Stanford Achievement Test[¬e]""']",NA,"['Page 3:\n[¬s]"" nonstandardized measures of WR, OR fluency, and cloze comprehension,""\n""The WR measure consisted of 70-word lists of random selections from the Dale List of 769 Easy Words (Dale, 1931). Each child read from three lists during both pretesting and posttesting. Scores were expressed as words read correctly per minute; the median number of words read correctly served as the dependent measure.""\n""For measuring OR fluency, six 100-word passages were identified from the materials immediately following the instructional material in the Sullivan Pro- grammed Reading Series (Buchanan, 1968). The students read for 1 minute from each of the three passages during both pretesting and posttesting. The median number of words read correctly per minute served as the dependent measure.""\n""Two 250-word passages were also identified for use as cloze tests. In these passages, every fifth word was deleted and replaced with a 10-space blank. The children read one passage aloud as a pretest and the other as a posttest, guessing words at each blank.[¬e]""']",NA,NA,NA,NA,NA,NA
37093365,Peer Tutoring,NA,NA,A locator test 2 (grades 6-12) to determine the appropriate level of California Achievement Test,"['Page 46:\n[¬s]""Form C of Level 15 was used for the pre-test, and Form D was used for the post-test.[¬e]""', 'Page 7:\n[¬s]""The California Achievement math sub-tests of Math Computation and Math Concepts/Applications was used as a measure to deter\xad mine pre- and post-test results.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117298,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 18:\n[¬s]"" All grades were calculated by teachers according to school system policies. \x95 Homework grades (HWEng, HWSocSt, HWMath, and HWSci) \x95 Classwork grades (CWEng, CWSocSt, CWMath, and CWSci) \x95 Test grades (fSTEng, TSTSocSt, TSTMath, and TSTSci) \x95 Composite grades (CMPEng. CMPSocSt, C:MPMath, and CMPSci).[¬e]""', 'Page 19:\n[¬s]""Academic composite, an average of CMPEng, CMPSocSt, CMPMath. and CMPSci (ACAvg)[¬e]""']",NA,NA,NA,NA
37133968,Peer Tutoring,NA,NA,NA,NA,NA,"['Page 74:\n[¬s]"" 2-minute paper and pencil test with all single-digit multiplication facts presented[¬e]""']",NA,NA,NA,NA,NA,NA
37092727,Feedback,NA,NA,NA,NA,NA,"['Page 2:\n[¬s]""Transfer task. The stimuli used in Session 2 were adapted from the checkerboard task used in Pratt et al. (1984). The checkerboard con\xad sisted of six squares (two blues, two greens, two reds) arranged in a 2 x 3 matrix. Each of the rows contained one square of each color. There were six different chessmen (black and white knights, queens, and kings) .[¬e]""']",NA,NA,NA,NA,NA,NA
40117168,Feedback,NA,NA,NA,"['Page 18:\n[¬s]"" Stanford Achievement scaled scores[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38296682,Feedback,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 11:\n[¬s]""Both primary and secondary outcomes are GCSE scores [¬e]""', 'Page 5:\n[¬s]"" Attainment 8 GCSE[¬e]""']",NA,NA
37116236,Peer Tutoring,NA,NA,"Reading comprehension  At pretest and posttest, students’ performance in reading com- prehension was measured with both an experimenter-developed task and a standardized test.  Nauck and Otte’s (1980) reading comprehension test from the Diagnostischer Test Deutsch (Diagnostic Test of German Language). This standardized reading comprehension test consists of two par- allel forms, each of which presents to respondents two text mate- rials","['Page 5:\n[¬s]""2.5.1. Reading comprehension At pretest and posttest, students’ performance in reading com- prehension was measured with both an experimenter-developed task and a standardized test.""\n""Furthermore, at pretest and posttest all students completed Nauck and Otte’s (1980) reading comprehension test from the Diagnostischer Test Deutsch (Diagnostic Test of German Language).[¬e]""']","At pretest and posttest, students’ performance in reading com- prehension was measured with both an experimenter-developed task and a standardized test.  Both at pretest and at posttest, students’ knowledge about read- ing strategies was assessed with two open-ended questions.",NA,NA,NA,NA,NA,NA,NA
40117229,NA,NA,NA,TASS was standardised but edited by researchers (4 items were added),"['Page 9:\n[¬s]""Teacher Assessment of Student Skills (TASS).""\n"" The original TA SS ~Godin, GoWell, Dav is & Kay e, 1 990! c ontains a list of 1 2 personal and soc ial c ompetence skills on whic h c hildren were rated by their classroom teachers. The investigators added four items, three of whic h are ac ademically oriented. ""\n""Academic Records. Children’s quarterly grades were ac cessed from academic records at eac h sc hool. Grades were standardized within school and marking period[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093602,Peer Tutoring,NA,NA,NA,"['Page 2:\n[¬s]""The dependent vari\xad ables were arithmetic achievement as mea\xad sured by the California Arithmetic Test (CAT) and personal and social adjustment as measured by the California Test of Person\xad ality (CTP).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37116233,Peer Tutoring,NA,NA,NA,"['Page 7:\n[¬s]""Rapid Letter Naming and Rapid Letter Sounds (RLS).[¬e]""', 'Page 8:\n[¬s]"" Student reading achievement gains were calculated as the pre- to posttreatment gain on the RLS tes""\n""The RLS is based on a measure developed by Levy and Lysunchuk (1997) to assess the number of letter sounds a student can identify in 1 min.""\n""We consider the RLS as an appropriate indirect measure of K-PALS implementation because it measures knowledge (letter\x96sound correspon- dence) that is an important part of the K-PALS curriculum.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37133971,Peer Tutoring,NA,NA,NA,"['Page 95:\n[¬s]""The Metropolitan Achievement Test, eighth edition (MAT8) by Harcourt Educational Measurement (2001), is designed to assess achievement o f students in major skill and content areas o f curriculum. The M AT8 spans grades K.O to 12.9 and requires several hours to administer based upon the number o f subtests given. Subtests administered include sounds and print, reading vocabulary, reading comprehension, language, and spelling.[¬e]""']",NA,"['Page 102:\n[¬s]""W riting Samples In the study, the students were asked to produce a writing sample, which was then assessed by teachers using two separate measurements, a holistic writing assessment and T-units. The prompt was developed by the researcher and directions were given to each o f the teachers (Appendix B). The prompt was then administered by the classroom teachers. The teachers then scored each o f the samples using the two measurements.[¬e]""']",NA,NA,NA,NA,NA,NA
37093603,Peer Tutoring,NA,NA,NA,"['Page 10:\n[¬s]""At the end of the experiment, all students were administered the Reading Comprehension, Reading Vocabulary, Spelling, Language Expression, and Language Mechanics subtests of the California Achieve\xad ment Test, Form D. [¬e]""', 'Page 14:\n[¬s]""The scores used were the Total Reading and Total Language scaled scores from the California Achievement Test.[¬e]""']",NA,"['Page 10:\n[¬s]"" As pre- and posttests, stu\xad dents were also asked to complete writing sam\xad ples in response to probes designed to give them a specific audience and purpose for writing. The probes used were adapted from those devel\xad oped and field-tested for the California State Department of Education by a panel of writing experts led by Doris Prater of the University of Houston.[¬e]""']",NA,NA,NA,NA,NA,NA
38296685,Small Group Tuition,NA,NA,NA,"['Page 12:\n[¬s]"" New Group Reading Test (NGRT; GL Assessment[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671586,Teaching assistants,NA,NA,NA,"['Page 11:\n[¬s]""A Clinical Evaluation of Language Fundamentals (CELF), Pearson Clinical Recalling Sentences Test 5 was used as an additional secondary outcome.[¬e]""', 'Page 6:\n[¬s]""GL Assessment New Group Reading Test (NGRT)[¬e]""', 'Page 9:\n[¬s]""Hodder’s digital Access Reading Test[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093606,Peer Tutoring,NA,NA,NA,NA,Developed to gauge perceptions of pupils.,"['Page 15:\n[¬s]""A post-project subjective feedback questionnaire (based on Topping, 1995) was completed by experimental participants (see Appendix B). More recent affective measures such as the Writer Self-Perception Scale (Bottomley, Henk and Melnick, 1997) were not available at the time. Group discussions were also held with the participants after the questionnaire had been completed. Direct observations and informal discussions with the participants and class teachers took place throughout the project.[¬e]""']",To understand attitudes.,NA,The researcher test was developed from this criteria.,"['Page 15:\n[¬s]""After considering the literature on methods for analysing writing (see above), it was decided to use the 5±14 National Curriculum Guidelines for assessment of writing (Scottish Office Education Department, 1991).""\n""Analyses of individual writing were based on the piece of class individual writing completed immediately before and after the project.[¬e]""']",NA,NA
37671517,Teaching assistants,NA,NA,NA,"['Page 17:\n[¬s]""Phonological Sk ills: Pupils were assessed on their ability to comple te a number of oral phonologica l tasks including blending orally presented, phone mes , segmentin g words into phone mes and detecting non-rhym ing words from a choice of three, using the Sound Linkage Test of Phonolo gica l Awareness (Hatcher 2001).""\n""Word Recognition: Pupils were assessed on two measures. Firstly, the numbe r of words they were able to recognis e from the list of the first 45 high frequenc y words suggeste d by the Primary Nationa l Strategy (PNS) was noted. The Burt Graded Word Reading Test (1976) was used as a second measure of word recognitions kills[¬e]""']",NA,"['Page 17:\n[¬s]""Letter k nowledge: Pupils were assessed on their ability to supply the letter names and sounds commonly associated with all 26 letters of the alphabet. Both upper and lower case letters were assessed, giving a total of 104 possible responses.""\n""Spelling Sk ills: Pupils\' raw scores on the Schonell spelling test were used to note skills in this area.""\n""Text Reading Sk ills: During the Reading Intervention progra mme childre n read a range of childre n\'s books , graded according to an objective formula describe d by Hatcher (2000).[¬e]""']",NA,NA,NA,NA,NA,NA
37092790,Feedback,NA,NA,NA,NA,NA,"['Page 7:\n[¬s]""The data gathering instruments used were constructed by the in-*. ...vestigator[¬e]""']",NA,NA,NA,NA,NA,NA
37093367,Peer Tutoring,NA,NA,"The sociometric measure developed by Chaires (1966) was used (see Appendix A) Self-appraisal inventory. Instructional Objectives Exchange (IOX), directed by James Pophara (1970, Title III?)","['Page 27:\n[¬s]"" The sociometric measure developed by Chaires (1966) was used (see Appendix A)""\n""Self-esteem: Self-aonraisal inventory. In 1970, after searching for satisfactory self-esteem measures, Title III representatives coop\xad eratively pooled their financial resources and commissioned the In-[¬e]""', 'Page 28:\n[¬s]""19 structional Objectives Exchange (IOX), directed by James Pophara[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37061134,Feedback,NA,NA,NA,NA,"A paper-and-pencil test consisted of 20 multiplication problems: (1) half the problems the number being multiplied was two digits in length and that in half it was three digits in length, (2) half the problems the multiplier was a digit from 2 to 5, while in the other half a digit from 6 to 9.","['Page 3:\n[¬s]""The criterion measure consisted of 20 multiplication problems generated at random with the constraints (1), that in half the problems the number being multiplied was two digits in length and that in half it was three digits in length, and (2), that in half the problems the multiplier was a digit from 2 to 5, while in the other half a digit from 6 to 9. The same paper-and-pencil form of the criterion measure was used as the pre-test and the post-test. Each child received the pre-test about 20 hours before his first practice session and received the post-test about two hours after his last session.[¬e]""']",NA,NA,NA,NA,NA,NA
40294957,Feedback,NA,NA,NA,NA,Test 1: Critierion measure. Test 2: Test on the 'tables'. ,"['Page 4:\n[¬s]""Under every condition, the pupils took two pre-tests, received 12 computer-controlled practice sessions, and then took two post-tests. The criterion measure consisted of 24 multiplication problems.""\n""The same paper-and-pencil form of the criterion measure was used as a pre\xad test and a post-test.""\n""The second and subsidiary measure required writing the products of all possible pairs of one-digit numbers. For convenience this will be called the test on the ‘ tables,’ though we do not wish to imply that the children had literally learned tables.[¬e]""']",NA,NA,NA,NA,NA,NA
37093607,Peer Tutoring,NA,NA,NA,"['Page 5:\n[¬s]""ified 31 children whose mean score on the fall M[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37133974,Peer Tutoring,NA,NA,NA,"['Page 43:\n[¬s]""The reading pretest and posttest used standard Reading Assessment Passages (RAPs). T h e RAPs provided a short reading assessment that is standardized, measured oral reading rate, and had generic third grade reading passages (Appendix E). [¬e]""', 'Page 44:\n[¬s]""assessed each student with the RAPs individually. The students orally read the passages to the experimenter. For the first 3 minutes the number of errors (substitution, omissions, additions, hesitations) were recorded by the experimenter. When the student finished reading, the experimenter recorded the number of words read correctly during the first 3 minutes and divided by 3 to get the correct number of words read per minute. The experimenter provided no positive or corrective feedback during the reading fluency assessment. Upon completion of the reading passage, the experimenter asked the student 5 comprehension questions beginning with the words who, what, where, why, and how. The questions were m arked with a plus if correct and a minus if incorrect.[¬e]""']",NA,"['Page 43:\n[¬s]""The spelling pretest and posttest consisted of a random sampling of words taught during the 8-week implementation period. Each class used the same spelling words. The words to be learned each week during implementation were put in eight separate piles and three words from each of the eight piles were randomly picked for use in the testing. This provided a total of 2 4 words to be given to each class as a group at the beginning of the project and at the end of the project (Appendix D). The experimenter chose to test the spelling words in isolation because this was the way the students w ere tested weekly by their classroom teachers.[¬e]""']",NA,NA,NA,NA,NA,NA
45336793,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
45336794,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
40294958,Feedback,NA,NA,NA,"['Page 4:\n[¬s]""Metropolitan Achievement Test (MAT), Form F for mathematics[¬e]""']",NA,NA,NA,"['Page 4:\n[¬s]""Science prior achievement was operationalizedin terms of science grades submitted to the students by their teachers before the study was conducted.[¬e]""']",NA,NA,NA,NA
37133976,Peer Tutoring,NA,NA,"Tests used were: * the Iowa Test of Basic Skills (ITBS) to test reading and maths performance * The Wechsler Individual subtects (WIAT) to measure achievement in basic reading and math computation.  * The Self-Perception Profile for Children (SPPC) to measure social gains * the social skills rating system (SSRS) to rate social behavours that can affect teacher-student relations, peer acceptance and academic performance ","['Page 65:\n[¬s]"" the Iowa Test o f Basic Skills (ITBS); the Wechsler Individual Achievement Test (WIAT); the Self-Perception Profile for Children (SPPC); and the Social Skills Rating System(SSRS).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37061135,Feedback,NA,NA,NA,"['Page 6:\n[¬s]""Reading Test,""\n""scales from""\n""Questionnaire.""\n""Emotionality instrument""\n""Sarason’s""\n""Weinstein""\n""Morris,""\n"" The Nelson-Denny""\n""(1980) Test Anxiety Scale,""\n"" five""\n""\' s (1983) Learning and Study Skills""\n""Davis & Hutching\'s (1981) Worry and[¬e]""']",NA,"['Page 6:\n[¬s]""a constructed response""\n""posttest was administered.[¬e]""']",NA,NA,NA,NA,NA,NA
37092791,Feedback,NA,NA,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]"" locally developed objective referenced test item, bank and a computer feedback system,""\n""Items from the item bank were used to construct two types of tests. Monitor tests measured a large number of either reading or arithmetic\'objectives, one item per objective. Teachers were / ■ » • able to detect changes in group performance on all objectives. Unit tegts were designed to measure each pupil\'s competency on a particular objective. As each objective was measure^ by five items, ^teachers were able to\'determine whether a student had- ; mastered a specific objective.[¬e]""']",NA,NA,NA,NA
37092612,Feedback,NA,NA,NA,NA,NA,"['Page 51:\n[¬s]""Achievement Multiple-Choice Items Forty-five multiple-choice items were designed to measure students’ general achievement regarding sinking and floating and related material. These items were designed to measure students’ declarative knowledge and paper-and-pencil procedural knowledge as it related to the content of the unit. [¬e]""', 'Page 52:\n[¬s]""Performance Assessment. The PA was designed to measure students’ procedural and schematic knowledge related to sinking and floating. Part 1 was more procedure-intensive than Part 2, whereas Part 2 required more conceptual understanding of sinking and floating and measurement. Students were given a set of supplies that included four blocks of different unknown densities, graduated cylinder, ruler, overflow can, water, mystery liquid, and supplies for manipulating objects such as tongs and paper towels. Part 1 of the PA asked students to find the density of a block, given its mass and materials to measure its volume; this task required procedural knowledge covered specifically in the instructional unit to complete. [¬e]""']",NA,NA,NA,NA,NA,NA
43090197,Peer Tutoring,NA,NA,NA,"['Page 5:\n[¬s]""Subtests 13,14, and 15 of the Woodcock-Johnson Psycho-Educational Batte,y, Part 2: Tests of Achjeyement.[¬e]""', 'Page 6:\n[¬s]""The Beginning Readjng I criterion diagnos~lc test[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
43090198,NA,NA,NA,NA,"['Page 4:\n[¬s]""ng-achievement test utilized in this study was the Woodcock- Johnson Psycho-Educational Battery, part 2 (Tests of Achievement, subtests 13-15) (Woodcock & Johnson, 19[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37133980,Peer Tutoring,NA,NA,"Attitude to reading was measured using 'The Elementary reasing Attitude Survey (ERAS)', developed by McKenna & Kear, 1990","['Page 18:\n[¬s]""Attitude to reading. The Elementary Reading Attitude Survey (ERAS) (McKenna & Kear, 1990) was used to measure the students\' attitudes towards reading.[¬e]""']","The researchers develope their own measure of thinking skills by following the test of critical thinking by Norris and Emmos (1989). They developed a table of specifications of aspects of thinking that could be tested using PT questions. Students were given a written text and answer grid containing questions. The researcher read the story aloud to the class, stopping to ask questions and allow children to answer on their grid.   Subjective Participant Feedback was collected through discussion meetinsg where participants were selected by dividing by gender, ranked by reading score, then every 4th student asked to join the discussin group.   ","['Page 16:\n[¬s]""Thinking skills. Despite an extensive search, no norm-referenced tests of thinking skills (as distinct from general cognitive abilities) suitable for this age range and sensitive enough for this application were found. Accordingly, a curriculum-based criterion-referenced test to assess thinking skills was developed by the researchers, following the guidelines for an open-ended test on critical thinking proposed by Norris and Ennis (1989). Following their recommendations, a table of speci®cations of aspects of thinking that might be tested using the PT questions was developed (see Table 3). Ten related questions each demanding a different aspect of thinking based upon a short ®ctional story were selected from the during and after Level 3 PT framework, to avoid any ceiling effect that might otherwise occur at post-test (see Appendix 1). Some of these questions related quite speci®cally to the content of the test story, but the majority required more abstract and generalized thinking skills[¬e]""', 'Page 18:\n[¬s]"" A researcher then read the story aloud to the whole class, pausing at pre- determined places during the reading to ask the questions orally and allow the children time to record their answers on the answer grid. Many of the tutees found some of the questions dif®cult to understand and several requested help. Encouragement was given to try hard, but they were instructed to write ``I don\'t know\'\' next to any questions they did not understand. Of course, it might be argued that this procedure was to some extent testing listening and memory skills as much as thinking skills, but it was at least seeking to minimize testing of reading skills, and this would apply equally to both groups.""\n""The same procedure for testing thinking skills was repeated at post-test with a different ®ctional story (``The Bulb Grower\'\'). There was concern that the post-test should not suffer from a ceiling effect. The chosen post-test was accordingly considerably more dif®cult and required more inference (as demonstrated crudely by differences in Flesch-Kincaid readability indices, and more subtly by conference and consensus among the research and teacher teams). This was thought likely to impact tutees particularly. Also, the tutors from the experimental group had experienced a change of teacher towards the end of the program and at the time of post-testing they were still adapting to this. During the post-test, their concentration was markedly poorer than during the pre-test[¬e]""', 'Page 19:\n[¬s]""Subjective participant feedback. Two discussion meetings were held for samples of experimental tutors and tutees (separately) at the end of Phase 2. PT tutors were divided by gender, ranked by pre-Phase 1 reading score, then every fourth student selected to join the discussion group. The same was done for PT tutees. The children were very forthcoming in expressing their opinions. The class teachers\' impressions of the project were gained through a questionnaire at the end of Phase 2.[¬e]""']",NA,NA,NA,NA,NA,NA
37133982,Peer Tutoring,NA,NA,NA,NA,Curriculum-based criterion-referenced test was developed  This was administered individually to each participating child in a quiet area by a researcher. Each child was asked to respond to two general questions and then to tell all they knew about 10 high frequency scientific keywords chosen from the paired science activity pack  Questionnaire for Children,"['Page 10:\n[¬s]""Locating tests of scienti\x1ec knowledge with appropriate focus and adequate short-term sensitivity proved to be problematic, so a curriculum-based crite- rion-referenced test was developed (see Appendix 2).""\n""This was administered individually to each participating child in a quiet area by a researcher. Each child was asked to respond to two general questions and then to tell all they knew about 10 high frequency scienti\x1ec keywords chosen from the paired science activity pack. Each child\x92s verbal responses were audio recorded. The keywords were chosen to provide a mixture of words speci\x1ec to science and some more widely applicable words.[¬e]""']",NA,NA,NA,NA,NA,NA
37116207,Peer Tutoring,NA,NA,NA,"['Page 2:\n[¬s]""A macro-evaluation tested and retested using Performance Indicators in Primary Schools over a two- year period. A micro-evaluation tested and retested within each year using a criterion-referenced test of mathematical problem solving.[¬e]""', 'Page 8:\n[¬s]"" The Performance Indicators in Primary Schools (PIPS) (Centre for Evaluation and Monitoring 2009a) were used to collect data on children at age seven years, nine years and 11 years. These were group pencil and paper tests of mathematics and non-verbal ability, although the mathematics part included a good deal of numeracy and relatively little problem solving.[¬e]""']",NA,"['Page 8:\n[¬s]"" A criterion-referenced test of attainment in mathematical problem solving was developed, based upon items from the Fife Council (2007) Common-Order Framework in Mathematics.[¬e]""']",NA,NA,NA,NA,NA,NA
38296692,NA,NA,NA,NA,"['Page 11:\n[¬s]""Progress in English (PiE) 11: Second Edition Long Form (LF) Test, GL Assessment[¬e]""']",NA,NA,NA,NA,NA,"['Page 11:\n[¬s]""The pre-test was pupils’ performance in Key Stage 2 English at the end of Year 6, obtained through the national pupil database (NPD).[¬e]""']",NA,NA
38296693,Small Group Tuition,NA,NA,NA,"['Page 12:\n[¬s]""The Progress in English (PiE) test (PiE 11: Second Edition Long Form (LF) Test, GL Assessment), was the main test used to determine literacy outcome. The test includes both narrative and non- narrative exercises and assesses both reading and writing skills including areas such as spelling, grammar and comprehension. The Progress in English test was the only test available to the evaluation team (in order to comply with EEF testing policy) which included a writing component. Tests were marked by GL Assessment blind to allocation (i.e. markers did not know whether test papers were from either the intervention or control pupils).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38296689,Small Group Tuition,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 16:\n[¬s]""KS2 standard assessment tests (SATs) scores in maths and English (reading, grammar, punctuation and spelling—GPS), which are mandatory national tests, were used as the outcome measures in this trial, with maths being the primary outcome and English being a secondary outcome.[¬e]""']",NA,NA
38878260,Small Group Tuition,NA,NA,NA,"['Page 11:\n[¬s]""Phonemic Decoding • Word Attack (WA) subtest from the Woodcock Reading Mastery Test-Revised (WRMT-R) • Phonemic Decoding Efficiency (PDE) subtest from the Test of Word Reading Efficiency (TOWRE)""\n""Word Reading Accuracy and Fluency • Word Identification (WI) subtest from the WRMT-R • Sight Word Efficiency (SWE) subtest from the TOWRE • Oral Reading Fluency subtest from Edformation, Inc. The text of this report refers to the reading passages as \x93Aimsweb\x94 passages, which is the term used broadly in the reading practice community. Reading Comprehension • Passage Comprehension (PC) subtest from the WRMT-R • Passage Comprehension from the Group Reading Assessment and Diagnostic Evaluation (GRADE)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
38878273,Small Group Tuition,NA,NA,NA,"['Page 8:\n[¬s]""part of the prenorm version of the Comprehensive Test of Phonological Processing""\n""TOWRE""\n""Gray Oral Reading Test (GORT-3;""\n"" passage comprehension subtest of the WRMT""\n"" reading comprehension score from the GORT-3[¬e]""', 'Page 9:\n[¬s]"" Stanford- Binet Intelligence Scale, 4th ed.[¬e]""']",NA,"['Page 9:\n[¬s]""A developmental spelling analysis[¬e]""']",NA,NA,NA,NA,NA,NA
40398947,Small Group Tuition,NA,NA,NA,NA,NA,"['Page 5:\n[¬s]""The primary outcome was writing skills, measured using a bespoke test based on previous Key Stage 2 (KS2) assessment papers.""\n""an implementation and process evaluation was conducted which involved a teacher survey and a visit to a sample of schools to conduct lesson observations and teacher interviews.[¬e]""']",NA,NA,NA,NA,NA,NA
37093368,Peer Tutoring,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
40117231,NA,NA,NA,NA,NA,NA,NA,NA,NA,GPAs were collected from the school district and used to measure academic improvement,NA,NA,NA
37092613,Feedback,NA,NA,NA,NA,NA,NA,NA,"['Page 56:\n[¬s]""Student achievement in mathematics was assessed primarily through common benchmark assessments given at the beginning, the middle, and at the end of the trimester. These tests were designed by the middle school math teachers who used the tests (see Figure 4.) ""\n""Tests were designed by the middle school math teachers during a district sponsored summer workshop. According to the teacher test developers, items on the tests corresponded directly with expectations of what the students should learn during the first [¬e]""', 'Page 57:\n[¬s]""trimester consistent with the California State Standards.""\n""student assessments were part of an on-line assessment system for those classroom sections in the treatment group (T)[¬e]""']",NA,NA,NA,NA
39253235,NA,NA,NA,NA,"['Page 32:\n[¬s]""The California Achievement Test[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37133983,Peer Tutoring,NA,NA,NA,NA,A test was needed to check the relative progress of the tutors and the comparison or control group before and after the exercise. A satisfactory test was not in existence. It was therefore decided to write a test taking care to make each question as discriminating as possible.,"['Page 1:\n[¬s]""A test was needed to check the relative progress of the tutors and the comparison or control group before and after the exercise. A satisfactory test was not in existence. It was therefore decided to write a test taking care to make each question as discriminating as possible.""\n""The test was checked before use by asking a very good candidate from another group to do it. Two Chemistry teachers were also asked to make their comments. Changes were made to the test in response to the answers and suggestions. A time limit of 50 minutes was chosen so that all the candidates might be expected to finish all the questions. The test contained two subtests. One corresponded to the subject matter that was to be taught and the other to the remaining part of the syllabus which included mechanisms in organic chemistry. The reason for including the second part of the test was that if the tutoring had made certain concepts basic to the understanding of mechanism clearer, then the tutors should be able to perform better on questions which they had not taught.[¬e]""']",NA,NA,NA,NA,NA,NA
37116208,Peer Tutoring,NA,NA,NA,"['Page 13:\n[¬s]""Prior to the project and for its duration, the district had an assessment system in place (the Performance Indicators in Primary Schools [PIPS] project) provided by CEM that enabled the progress of students to be monitored on a regular basis. At the time of the study, PIPS assessments were used by all schools in one third of Scottish districts. Schools and districts paid an annual registration fee. CEM provided the assessments, marked and analyzed the data, and fed back standardized pupil-level results (see www.pipsproject.org). This system was used to evaluate the impact of the interventions. The assessments were group pencil-and-paper tests of mathematics, reading, science (Primary 7 only), vocabulary, nonverbal ability, and attitudes to mathematics and reading. They were administered by the school staﬀ and took approximately three half-hour sessions to complete (four for Primary 7, which included an assessment of science). The curriculum-based assessments of maths, reading, and science were aligned to the Scottish 5–14 Curriculum, which was in use across all elementary schools involved the study. The assessments had good psychometric properties (Tymms, 1999). The PIPS system administers assessments at ﬁxed times. The timing of the assessments in relation to the implementation of the interventions is shown in Table 3.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117363,NA,NA,NA,"SAT-9 used in elementary school.   Additionally, school grades were used to measure academic impact. These were collected from student records","['Page 13:\n[¬s]"" rea ding test scores a nd grades in most s ubjects[¬e]""', 'Page 137:\n[¬s]""We again adminis tered the reading component of the SAT- 9 in school to stude nts in kindergarte n through s ixth grade[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253306,Summer schools,NA,NA,NA,"['Page 11:\n[¬s]""Gray Oral Reading Test-Third Edition (GORT-III; Wiederholt & Bryant, 1992)""\n""Woodcock Reading Mastery Tests-Revised (WRMT-R; Woodcock, 1987)[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40117360,NA,NA,NA,NA,"['Page 3:\n[¬s]""Wide Range Achievement Test-Revised (WRAT-R) Reading and Spelling Subtests (Jas\xad tak & Wilkinson, 1984).[¬e]""', 'Page 4:\n[¬s]""The WRAT-R reading and spelling subtests were readministered at posttest.""\n""Woodcock-Johnson Psychoeduca\xad tional Battery-Revised (WJ-R) Word At\xad tack subtest""\n""Bryant Pseudoword (Bryant, 1975).""\n""Pseudoword List.""\n"" Olson, Forsberg, Wise, and Rack (1994)""\n""Dolch word recognition test (Dolch, 1939).""\n""Analytical Reading Inventory (Woods & Moe, 1977).""\n""Yopp-Singer segmentation task (Yopp, 1988).[¬e]""']",NA,"['Page 4:\n[¬s]""Curriculum-based spelling list.""\n""Writing sample. [¬e]""']",NA,NA,NA,NA,NA,NA
37671592,Teaching assistants,NA,NA,NA,"['Page 6:\n[¬s]""Receptive language was measured at pretest with the standardized Peabody Picture Vocabulary Test\x97IIIA (Dunn, Dunn, & Dunn, 1997). Students select a picture that best illustrates the meaning of an orally presented stimulus word. Testing is discontinued after the student misses 8 out of 12 items.""\n""Alphabetic knowledge was measured at pretest and posttest using the DIBELS (Good & Kaminski, 2002) Letter Name Fluency subtest, which uses a letter card showing upper- and lowercase letters in random order. Students are asked to name as many letters on the page as they can in 1 min. The score is the number of correctly named letters.""\n""Phonological awareness was measured at pretest and posttest using the standardized Comprehensive Test of Phonological Processing (Wagner, Torgesen, & Rashotte, 1999) Phonological Awareness composite score. This score comprises three subtests: Blending Words, Elision, and Sound Matching. During the Blending Words subtest, the student is asked to listen to parts of words and blend them together to make a whole word. This subtest has 20 items, and testing is discontinued after the student misses three items in a row or when the student completes all items.""\n""Reading accuracy was measured (pretest, posttest, and follow-up) as the composite average of the Word Attack and Word Identification subtests of the standardized Woodcock Reading Mastery Test\x97Revised/Normative Update (WRMT-R/NU; Woodcock, 1987\x961998). The Word Attack subtest includes 50 nonwords that increase in difficulty. Testing is discontinued after six consecutive incorrect responses.""\n"" Reading efficiency was measured (posttest and follow-up) as the composite average of the Phonemic Decoding and Sight Word Efficiency subtests of the standardized Test of Word Reading Efficiency (Torgesen, Wagner, & Rashotte, 1999). The Phonemic Decoding subtest requires the student to read orally as many nonwords as possible in 45 s. Items in the list increase in difficulty from 2 to 10 phonemes. For students who were under the age of 7 at kindergarten posttest, standard scores were computed using age 7 (the youngest age category).[¬e]""', 'Page 7:\n[¬s]"" Oral reading fluency rate was assessed at posttest and follow-up with a beginning first-grade decodable reading passage entitled \x93Mac Gets Well\x94 (Makar, 1995). Students read the passage aloud for 1 min. Words omitted, words substituted, and hesitations of more than 3 s were scored as errors. Words self-corrected within 3 s were scored as accurate. Fluency rate is calculated as the number of words correctly read in 1 min.""\n"" Developmental spelling was assessed at posttest and follow-up using developmental scoring of the Wide Range Achievement Test\x97Revised (Jastak & Wilkinson, 1984) Spelling subtest. Normally, this subtest re- quires the student to copy marks\x96symbols, print his or her name, and print a list of dictated words, and testing is discontinued after 10 consecutive incorrect responses.""\n""Comprehension was assessed at posttest and follow-up using the WRMT-R/NU Passage Comprehension subtest. The student is asked to silently read a short passage and orally provide the missing keyword. (For each blank, the student is asked to supply a word appropriate in the context of the passage.) Acceptable responses are listed on the examiner\x92s easel page, and testing is discontinued after six consecutive incorrect responses. The student\x92s raw score is the total number of correct responses.""\n"" Growth measures were chosen to monitor the development of critical early literacy skills targeted in the intervention. Two widely used measures that describe growth of foundational reading skills are the DIBELS Pho- neme Segmentation Fluency and Nonsense Word Fluency subtests. These two measures were administered at pretest, midtest, and posttest to assess phonemic awareness and phonological recoding and blending of sounds.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671636,Teaching assistants,NA,NA,NA,"['Page 7:\n[¬s]""Word Attack and Word Identification subtests of the WRMT-R/NU (Wood- cock, 1998""\n""Dy- namic Indicators of Basic Early Literacy Skills (DIBELS; Good & Kaminski, 2002).""\n""Wide Range Achieve- ment TestÐRevised (WRAT-R; Jastak & Wilkinson, 1984) Spelling subtest, Level 1[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671638,NA,NA,NA,"RAN = Rapid Automatized Naming, letter naming test  PRF = words per minute performance  WR accuracy = Word Identification subtest from the norm-referenced, standardized Woodcock Reading Mastery Test - Revised/Normative Update, Form H (Woodcock, 1987/1998).   Word reading (WR) efficiency , Sight Word subtest from the norm-referenced, standardized Test of Word Reading Efficiency, Form B (Torgesen, Wagner, & Rashotte, 1999).  Our second, norm-referenced, assessment framework for measuring fluency included the Rate subtest from the Gray Oral Reading Tests - 4 Form B (GORT; Wiederholt & Bryant, 2001).  Comprehension was assessed at pretest and posttest with the GORT Comprehension subtest","['Page 6:\n[¬s]""Word Iden- tification subtest from the norm-referenced, standardized Wood- cock Reading Mastery Test\x97Revised/Normative Update, Form H (Woodcock, 1987/1998).""\n""Word reading efficiency was measured using the Sight Word subtest from the norm-referenced, standardized Test of Word Reading Efficiency, Form B (Torgesen, Wagner, & Rashotte, 1999).[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
40294961,Small Group Tuition,NA,NA,NA,NA,NA,"['Page 11:\n[¬s]""Abilities hypothesized to contribute to or correlate with early word reading skills were assessed at the beginning of the intervention (December of kindergarten) using measures of classroom behavior, receptive vocabulary, rapid automatized naming, alphabetic knowledge, phonological awareness, and reading accuracy""\n"" Students were posttested at the end of the intervention on measures of alphabetic knowledge, phonological skills, word reading accuracy, word reading efÞciency, oral reading ßuency, spelling, and comprehension[¬e]""']",NA,NA,NA,NA,NA,NA
37671637,Teaching assistants,NA,NA,NA,"['Page 12:\n[¬s]""2. Receptive vocabulary (Receptive Vocab) was measured at pretest only, for the purpose of describing sample characteristics, with the standardized Peabody Picture Vocabulary Test-IIIA (PPVT-IIIA; Dunn & Dunn, 1997). Students select a picture that best illustrates the meaning of an orally presented stimulus word. Testing is discontinued after the student misses 8 out of 12 items. [¬e]""', 'Page 13:\n[¬s]""4. Alphabetics was measured at pretest and posttest using the DIBELS (Good & Kaminski, 2002) Letter Name Fluency subtest, which employs a letter card showing upper- and lower-case letters in random order. Students are asked to name as many letters on the page as they can in 1 min. The score is the number of correctly named letters. ""\n""5. Phonological awareness (Phono Aware) was measured at pretest and posttest using the standardized Comprehensive Test of Phonological Processing (CTOPP; Wagner, Torgesen, & Rashotte, 1999) Phonological Awareness composite score. This score comprises three subtests: Blending Words, Elision, and Sound Matching. During the Blending Words subtest, the student is asked to listen to parts of words and blend them together to make a whole word. This subtest has 20 items, and testing is discontinued after the student misses three items in a row or when the student completes all items. ""\n""6. Word reading accuracy (WR Accuracy) was measured (pretest and posttest) as the composite average of the Word Attack and Word IdentiÞcation subtests of the standardized Woodcock Reading Mastery Test-Revised/Normative Update (WRMT-R/NU; Woodcock, 1987, 1998). The Word Attack subtest includes 50 non-words that increase in difÞculty. Testing is discontinued after six consecutive incorrect responses.[¬e]""', 'Page 14:\n[¬s]""7. Word reading efÞciency (WR EfÞciency) was measured at posttest only as the composite average of the Phonemic Decoding and Sight Word EfÞciency subtests of the standardized Test of Word Reading EfÞciency (TOWRE; Torgesen, Wagner, & Rashotte, 1999a). The Phonemic Decoding subtest requires the student to read orally as many non-words as possible in 45 s. Items in the list increase in difÞculty from 2- to 10-phonemes. For students who were under the age of 7 at kindergarten posttest, standard scores were computed using standard scores based on 7-year-olds (the youngest age category). ""\n""9. Spelling was assessed at posttest only using developmental scores of the Wide Range Achievement Test-Revised (WRAT-R; Jastak & Wilkinson, 1984) Spelling subtest. Normally, this subtest requires the student to copy marks/ symbols, print his/her name, and print a list of dictated words, and testing is discontinued after 10 consecutive incorrect responses.""\n""10. Comprehension was assessed at posttest only using the WRMT-R/NU Passage Comprehension subtest. The student is asked to silently read a short passage, and orally provide the missing key word. (For each blank, the student is asked to supply a word appropriate in the context of the passage.)[¬e]""']",NA,"['Page 14:\n[¬s]""8. Oral reading ßuency (ORF) was assessed at posttest only with a beginning Þrst-grade decodable reading passage entitled ÔÔMac Gets WellÕÕ (Makar, 1995). Students read the passage aloud for 1 min. Words omitted, substituted, and hesitations of more than 3 s are scored as errors. Words self-corrected within 3 s are scored as accurate.[¬e]""']",NA,NA,NA,NA,NA,NA
43090199,NA,NA,NA,"1. 'Word Identification subtest...Woodcock Reading Mastery Test-Revised/Normative Update, Form H (1998)'; 2. 'Test of Word Reading Efficacy, Form B (Torgesen, Wagner & Rashotte, 1999)'; 3. 'WRMT/NU Word Comprehension subtest'; 4. 'WRMT-R/NU Passage Comprehension subtest' (p.241-2)",NA,"1. 'Vcabulary was assessed with a multiple-choice, curriculum-based measure of vocabulary developed by research staff in consultation with Dr Judith Scott'; 2. F'luency rate was assessed using students' mean WCPM on three grade-level passages drawn from DIBELS ORF benchmarks...' (p.241)",NA,NA,NA,NA,NA,NA,NA
37671588,Teaching assistants,NA,NA,"Receptive language was measured at pretest only with the standardized Peabody Picture Vocabulary Test - IIIA (Dunn & Dunn, 1997). RAN was measured at pretest only using the Letter Naming subtest of the Rapid Automatized Naming/Rapid Automatized Stimulus tests (Wolf & Denckla, 2005);  we also measured students on the Number Naming subtest  Word reading was measured using the Word Identification subtest from the norm-referenced, standardized Woodcock Reading Mastery Test - Revised/Normative Update Form H (WRMTR/NU; Woodcock, 1987/ 1998).  PRF using passages drawn from DIBELS Oral Reading Fluency Benchmark  fluency rate) employed the Rate subtest from the GORT - 4 Form B (Wiederholt & Bryant, 2001).   Comprehension was measured two ways: using a cloze-task measure (the WRMT - R/NU Passage Comprehension subtest) and using a multiple-choice measure (GORT - 4 Comprehension subtest).","['Page 21:\n[¬s]"" Norm-ref- erenced standard scores were used when available.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671589,NA,NA,NA,"Receptive vocabulary was measured at pretest only with the norm-referenced Peabody Picture Vocabulary Test IIIA (Dunn & Dunn, 1997) Phonological awareness was measured at screening/pretest and posttest with the composite standard score of three subtests from the Comprehensive Test of Phonological Processing (Wagner et al., 1999): Blending Words (pretest), Elision (pretest), and Sound Matching (screening) Word reading was measured at pretest and posttest with the mean standard score of the Word Attack and Word Identification subtests from the Woodcock Reading Mastery TestRevised/Normative Update (WRMTR/NU; Woodcock, 1998) Spelling was assessed at pretest and posttest with develop- mental raw scores of words correctly spelled on the Wide Range Achievement TestRevised (WRATR; Jastak & Wilkinson, 1984) Spelling subtes. Passage reading fluency was assessed at posttest only using the mean words correctly read in 1 min on two grade-level story passages. Both stories are from the Primary Phonics series (Makar, 1996) Comprehension was assessed at posttest only with the stan- dard score of the WRMTR/NU Passage Comprehension subtest.",NA,"Alphabetic knowledge was measured at screening and posttest as the mean of two naming measures: letter names and letter sounds correctly produced in 1 min. We developed our own measures of alphabetics; however, they are highly similar to the letter name task in Fuchs et al. (2001) and the letter name fluency subtest from the Dynamic Indicators of Basic Early Literacy Skills (Good & Kaminski, 2002)",NA,NA,NA,NA,NA,NA,NA
37671614,Teaching assistants,NA,NA,"Peabody Picture Vocabulary Test IIIA (Dunn, & Dunn, 2006) Woodcock Reading Mastery Test–Revised/Normative Update (WRMT-R/NU; Woodcock, 1987/1998) Word Comprehension cluster. Word Attack and Word Identification subtests from the WRMT-R/NU (Woodcock, 1987/ 1998)",NA,NA,NA,NA,NA,NA,NA,NA,NA
37133984,Peer Tutoring,NA,NA,"Reading Comprehension achievement - Dutch standradized and IRT-modelled test battery. At each measurement occasion a different test, increasing in level of difficulty was used to collect data",NA,NA,NA,NA,NA,NA,NA,NA,NA
37116237,Peer Tutoring,NA,NA,"Standardised reading comprehension tests (Staphorsius & Krom, 1996) ",NA,"Researcher supplied two questionnaires to assess student outcomes: 1.) The index of reading awareness (Jacobs & Pairs, 1987)  2.) The reading strategy use scale (Pereira-Laird & Deane, 1997)   Researcher-developed pretest and posttest",NA,NA,NA,NA,NA,NA,NA
37093609,Peer Tutoring,NA,NA,NA,NA,Implied that the tests were researcher developed as details to the contrary are not provided. ,"['Page 4:\n[¬s]""To answer the above questions we designed three conditions. ""\n"" In all three conditions a spelling and spelling rules test was administered at four points in time. Pupils\' effort was also measured four times by means of teachers’ ratings and observations in the classroom.[¬e]""']",NA,NA,NA,NA,NA,NA
40294962,Feedback,NA,NA,NA,NA,NA,"['Page 1:\n[¬s]""teachers were asked to rate students\' effort during spelling lessons""\n""Four parallel versions of a spelling test (dictation of words), each consisting of 45 typical spelling cases, were used as achievement measures.""\n""The reasoning strategy test,[¬e]""']",NA,NA,NA,NA,NA,NA
40117232,Extending school time,NA,NA,NA,NA,NA,"['Page 25:\n[¬s]""Students completed baseline and first-year follow-up measures of several intermediate and longer term outcomes addressed in this report, including work habits, self-efficacy, misconduct, and substance use[¬e]""', 'Page 32:\n[¬s]""Academic performance. Teachers completed the Academic Performance scale from the Mock Report Card (Pierce et al., 1999), a measure that was developed in order to obtain standardized information about students\x92 academic performance across school districts that utilize different grading systems.[¬e]""']",NA,"['Page 32:\n[¬s]""Academic performance. Teachers completed the Academic Performance scale from the Mock Report Card (Pierce et al., 1999), a measure that was developed in order to obtain standardized information about students\x92 academic performance across school districts that utilize different grading systems.[¬e]""']",NA,NA,NA,NA
37092614,Feedback,NA,NA,NA,NA,NA,"['Page 93:\n[¬s]""The content test was developed locally and adapted from the Physical Science textbook test bank (M cLaughlin, Rillero, Thom pson & Zike, 2002). The test was composed o f approximately 35 m ultiple choice questions taken directly from the corresponding learning objectives for each unit. The test questions were designed by the publisher to assess the content in the associated chapter in the book,[¬e]""']",NA,NA,NA,NA,NA,NA
37092599,NA,NA,NA,NA,"['Page 34:\n[¬s]""The Otis-Lennon School Ability[¬e]""', 'Page 5:\n[¬s]"" the Test of Written Spelling (Larsen & Hammill, 1986)[¬e]""']",NA,"['Page 34:\n[¬s]""The weekly tests utilized by the CBM groups were developed by the researcher[¬e]""']",NA,NA,NA,NA,NA,NA
37092600,Feedback,NA,NA,NA,NA,NA,NA,Teachers scored summaries by content and overall quality,"['Page 19:\n[¬s]""The summaries were scored in the same fashion by all three graders: They first provided a score for each section of the summary taking only the content adequacy into consideration, using a 3-point scale ranging from 0 (no information about this section) to 1 (some information but not enough) to 2 (adequate section coverage). Next, the teachers scored the summaries in their usual fashion, using a holistic score to evaluate the overall quality of the summary, and taking into account other[¬e]""', 'Page 20:\n[¬s]""factors in addition to the content adequacy (e.g., style, coherence, organization, and mechanics). This scale consisted of 5 points, corresponding to the convention\xad ally used A to F grades. [¬e]""']",NA,NA,NA,NA
40117182,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 11:\n[¬s]"" We collected information on academic performance and student characteristics through school records. Together, the MIS, surveys and school records permitted us to assess whether or not improvements in young people’s experiences and outcomes could be linked to participation in the Beacon centers.[¬e]""']",NA,NA,NA,NA
43090202,NA,NA,NA,"Dynamic Indicators of Basic Early Literacy Skills (DIBELS, Good & Kaminski, 2002, 2003) - letter anming - phonemic segmentation fluency (PSF) - nonsense word fluency (NWF)  Woodcock Reading Mastery Test-Revised (WRMT-R, Woodcock 1987) - Word Attack (WA) - Word Identification (WI) - Passage Comprehension (PC)",NA,NA,NA,NA,NA,NA,NA,NA,NA
39253308,Summer schools,NA,NA,NA,NA,NA,NA,NA,NA,Developmental Reading Assessment (Beaver 1997) is used in the district to assess reading achievement of primary students,NA,NA,NA
39253238,NA,NA,NA,NA,NA,NA,"['Page 8:\n[¬s]""Two dependent variables were used as preinterven\xad tion and postintervention measures. The first dependent variable consisted of a brief survey designed to assess students\' ability to (a) name the parts of a paragraph, (b) describe the function of each part of the paragraph, and (c) describe a metacognitive procedure used to plan and compose a paragraph as detailed in an earlier discussion on the informal assessment procedures. The videotape and accompanying instructional support manual provide specific definitive details and descriptions for these basic components of paragraph to allow for replication. The second dependent variable assessed the existence, cor\xad rect grammatical form, and correct function of the parts[¬e]""', 'Page 9:\n[¬s]""of a paragraph as described above in the discussion re\xad garding informal assessment procedures. Writing samples were scored separately by two graduate research assis\xad tants who were trained by the developers of the instruc\xad tional program. [¬e]""']",NA,NA,NA,NA,NA,NA
37671616,Teaching assistants,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 4:\n[¬s]""Criterion-Referenced Tests. Two criterion- referenced tests were used to assess student performance in reading and math.[¬e]""']",NA,NA
37092796,Feedback,NA,NA,NA,NA,NA,"['Page 1:\n[¬s]""The dependent variable in[¬e]""', 'Page 2:\n[¬s]""this study was achievement as measured by four 60-item unit exams and a comprehen- sive final examination.[¬e]""', 'Page 3:\n[¬s]""The textual material used in this study con- sisted of revised, published materials dealing with automobile ignition systems.[¬e]""', 'Page 4:\n[¬s]"" Immediate cognitive achievement and delayed cognitive achievement related to the composite instructional material were assessed with the same achievement test.[¬e]""']",NA,NA,NA,NA,NA,NA
37133987,Peer Tutoring,NA,NA,"Mathematics achievement was measured by the Mathematics Achievement Test-Grade 6 (MATH6) and the Mathematics Achievement Test-Grade 8 (MATH8).  The researcher selected items for all instruments from previously released Texas Assessment o f Academic Skills (TAAS) Tests for the 1997-1998 school year. The TAAS test is a criterion-referenced assessment o f the statewide curriculum.  Academic efficacy was measured by the Patterns o f Adaptive Learning Survey (PALS) (Midgley et al., 1997)  The Arlin (1984) Test o f Formal Reasoning (ATFR) (See Appendix G) was utilized to measure cognitive development.","['Page 46:\n[¬s]""Mathematics achievement was measured by the Mathematics Achievement Test-Grade 6 (MATH6) and the Mathematics Achievement Test-Grade 8 (MATH8).""\n"" The researcher selected items for all instruments from previously released Texas Assessment o f Academic Skills (TAAS) Tests for the 1997-1998 school year. The TAAS test is a criterion-referenced assessment o f the statewide curriculu[¬e]""', 'Page 47:\n[¬s]""Academic efficacy was measured by the Patterns o f Adaptive Learning Survey[¬e]""', 'Page 48:\n[¬s]""The Arlin (1984) Test o f Formal Reasoning (ATFR) (See Appendix G) was utilized to measure cognitive development.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37093610,NA,NA,NA,NA,NA,Not stated but implied by the lack of information that the test was researcher developed.,"['Page 6:\n[¬s]""A spelling test was administered at three points in time, with a nine week interval. In grade 6 an additional test of spelling of verbs was used.""\n""To determine knowledge of spelling rules an oral test was administered twice at grade 4 and once (at the end) at grade 6.[¬e]""', 'Page 7:\n[¬s]""For each grade level three parallel versions of a spelling test were used.[¬e]""']",NA,NA,NA,NA,NA,NA
38296697,Feedback,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 15:\n[¬s]"" KS2 maths""\n""KS2 Reading [¬e]""']",NA,NA
37092615,Feedback,NA,NA,NA,NA,NA,NA,School developed end of year tests and start of year tests were used for Year 7 and 8 student treatment effects. Year 7 CAT (Cognitive Abilities Test) used for some student treatment reference variables.,"['Page 9:\n[¬s]"" in some cases we made use of scores from school assessments (particularly in science, where modular approaches meant that scores on end-of-module tests were available)[¬e]""']",GCSE or KS3 SATS tests,"['Page 9:\n[¬s]""In many cases, these were the results on the national tests for 14-year-olds or the grades on the national school-leaving examination (the GCSE), [¬e]""']",NA,NA
39253240,Summer schools,NA,NA,NA,"['Page 12:\n[¬s]"" the sub\xad tests of Vocabulary, Reading Comprehension, and Total Reading of the SRA Achievement Series""\n""Gates- MacGinitie Reading Tests.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253241,Summer schools,NA,NA,Henmon-Nelson Test of Mental Maturity (Pre-test Table III)  SRA Reading Comprehension  SRA Arithmetic Reasoning  Sequential Tests of Educational Progress (STEP) in Science   Sequential Tests of Educational Progress (STEP) in Language Arts,NA,"Self-Description Form (SofEd, University of Buffalo) to measure: affiliation, dominance, autonomy, succorance, stimulation, nurturance, aggression, deference, achievement, compulsivity.",NA,Success Rating Scale (to rank experimental subjects): a) teacher preference b) independent functioning c) ability to work in academic areas: science and language arts d) student motivation ,NA,NA,NA,NA,NA
37092601,Feedback,NA,NA,NA,NA,NA,"['Page 88:\n[¬s]""Quality scores and total number/types of revisions were analyzed for all groups. Each essay, pre and post\xad treatment was scored[¬e]""', 'Page 97:\n[¬s]"" writing sample completed at the end of the treatments[¬e]""']",NA,NA,NA,NA,NA,NA
37092602,Feedback,NA,NA,NA,NA,Student self-evaluation form  1) Structural completeness of student narratives as measured by Lamberg 2) Development of student narratives as measured by Lamberg  (Student texts were anonymously judged by doctoral students in the English Education programme using Lamberg Scales of Completeness and Detail.)  3) Number of words in the student narrative ,NA,NA,NA,NA,NA,NA,NA
40294963,Feedback,NA,NA,NA,"['Page 37:\n[¬s]""The dependent variables were measured by scales •developed and validated by Lamberg[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
39253243,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
40117171,Feedback,NA,NA,NA,"['Page 62:\n[¬s]""Texas A ssessm en t of Academic Skills (TAAS) tests in read ing a n d m athem atics.[¬e]""', 'Page 65:\n[¬s]""Texas A ssessm ent of Academ ic Skills (TAAS) scaled scores in reading an d m athem atics w ere collected from th e 1992-93 school year w h en th e p o p u la tio n w as in fo u rth grade. These d a ta served as the pre-test scores. TAAS Texas L earning Index (TLI) scores in reading a n d m ath em atics w ere g ath ered for the 1993-94 school year w h en th e p o p u la tio n w as in fifth grade. These d ata served as the post-test scores.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37671591,Teaching assistants,NA,NA,"page 15 Stanford Achievement Test (SAT)  reading, maths, spelling, listening in higher grades also: science, social science",NA,NA,NA,NA,NA,Page 15 Modified Tennessee's Basic Skills First Test (BSF) to cover reading and math in grades 1 and 2 (3rd grade was already covered by the test) ,NA,NA,NA
37092800,Feedback,NA,NA,NA,"['Page 3:\n[¬s]""Metropolitan Achievement Test[¬e]""']",NA,"['Page 3:\n[¬s]""Walker Observation Scale[¬e]""']",NA,NA,NA,NA,NA,NA
37116218,Peer Tutoring,NA,NA,NA,"['Page 8:\n[¬s]""the mathematical communication assessment was used to assess the students’ mathematical communication abilities in terms of three sub-abilities: expressing their respective mathematical concepts, understanding others’ mathematical equations, and comprehending others’ mathematical thought (Lin & Lee, 2004). The assessment was consisted of multi-step word problems, including continuous addition, mixed addition and subtraction, mixed addition and multiplication, and mixed subtraction and multiplication. The pretest and posttest used the parallel problems all within the 2nd-grade mathematical curriculum (see Figure 4). These problems were collaboratively designed and developed by two educational technology experts and an elementary school teacher who has ten years teaching experience. Each question represented one mathematical communication sub-ability, and each sub-ability included two to three criteria to test different evaluative approaches.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37133992,Peer Tutoring,NA,NA,"The writing assessment scale was therefore based on the criteria used for the national tests of personal writing (Scottish Qualifications Authority, 1997). These comprise a total of 35 criteria relating to two 'aspects' of writing (Choice and Use of Language, and Selection and Organisation of Ideas) and their associated technical 'skills' (Spelling and Punctuation respectively), at five developmental levels labelled A (lowest) to E (highest)  Additionally, the Writer Self-Perception Scale (Bottomley, Henk, & Melnick, 1997) was used to measure the children's perception of themselves as writers at the end of the intervention (post only measure)",NA,NA,NA,NA,NA,NA,NA,NA,NA
37092616,Feedback,NA,NA,NA,NA,"Science Achievement Assessments in four parts - multiple choice (MC), short answer (SA), predict-observe-explain (POE) and performance assessment (PA)","['Page 91:\n[¬s]""Science Achievem ent Assessm ents""\n""Tw o goals were considered when we developed the achievement assessments: we wanted (1) to adequately evaluate whether students reached the curriculum instructional objectives, and (2) to comprehensively assess students’ achievement, in terms o f the type o f knowledge the assessment was intended to tap (L i & Shavelson, 2001, A p ril). To this end, we firs t id e n tifie d the im portant instructional objectives in the curriculum and the knowledge types that were to be measured fo r each instructional objective (Table 3.9). Based on the tw o dimensions, we developed fo u r assessments: m ultiple-choice (M C ), short answer (SA), predict-observe-explain (POE), and performance assessment (PA).[¬e]""', 'Page 97:\n[¬s]""A t the beginning o f the study, researchers administered the pretest, which included the""\n"" m ultiple-choice (M C ) test.[¬e]""', 'Page 98:\n[¬s]""In addition to the same""\n""M C test used at pretest, the posttest included the other three achievement assessments: Performance Assessment (P A ), Short A nsw er (SA), and Predict Observe and E xplain (POE).[¬e]""']",NA,NA,NA,NA,NA,NA
37092603,Feedback,NA,NA,NA,NA,NA,"['Page 47:\n[¬s]""three p retes ts and three posttests prompts[¬e]""']",NA,NA,NA,NA,NA,NA
39253343,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
40117237,NA,NA,NA,See Table 31 for a list of all measured outcomes,NA,NA,NA,NA,NA,NA,NA,NA,NA
40117361,NA,NA,NA,NA,"['Page 4:\n[¬s]""While the SES and EAP programs were not implemented until the 2004–2005 school year, our analysis tracks stu- dent achievement trajectories before, during, and after the students participated in these programs. Therefore, our analysis used data from the 2000–2001 to the 2005–2006 school year from Pittsburgh Public School’s “Real-Time Information” longitudinal database.""\n""In the period under examination, students in Pittsburgh took three kinds of annual achievement tests in reading and math[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
37092801,Feedback,NA,NA,NA,NA,NA,"['Page 3:\n[¬s]""Four sets were used for obtaining pretest scores and for giving training and four sets were used as a transfer task.[¬e]""']",NA,NA,NA,NA,NA,NA
39253395,Summer schools,NA,NA,NA,NA,NA,NA,NA,NA,NA,"['Page 10:\n[¬s]""Each academic year, the school district administers the TORF to first- and second-grade students in September, January, and May.[¬e]""', 'Page 9:\n[¬s]"" Test of Oral Reading Fluency (TORF; Children’s Educational Services, 1987)[¬e]""']",NA,NA
39253396,Summer schools,NA,NA,NA,"['Page 3:\n[¬s]"" In kindergarten and ﬁrst grade, the district administers select subtests of the Dynamic Indicators of Basic Early Literacy Skills (DIBELS; Good & Kaminski, 2002) and/or the Test of Oral Reading Fluency (TORF; Children’s Educational Services, 1987). ""\n""Both DIBELS’ NWF and the TORF are standardized, individually administered and age-appropriate early literacy skill assessments that have been developed to identify struggling readers and allow the monitoring of student progress over time.[¬e]""']",NA,NA,NA,NA,NA,NA,NA,NA
